{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "concate.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6515097fb8404c219d1ff3ec30073e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_82a9f839c4544944bedcb2fd112bc450",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_47b4b8e7a8a04938ac720a2122c5ab06",
              "IPY_MODEL_c3122383a0f5497f8851aa87690a0ad5"
            ]
          }
        },
        "82a9f839c4544944bedcb2fd112bc450": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47b4b8e7a8a04938ac720a2122c5ab06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_35182732fca34efcadc7a3ed2f6a4566",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 20,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af35d843a2fc48f5b3eb8bee9989b75c"
          }
        },
        "c3122383a0f5497f8851aa87690a0ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b65ad26e1e614c6f9227bc716d473d46",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  0% 0/20 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dec5c042a4a147999d01842e778e3bf0"
          }
        },
        "35182732fca34efcadc7a3ed2f6a4566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af35d843a2fc48f5b3eb8bee9989b75c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b65ad26e1e614c6f9227bc716d473d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dec5c042a4a147999d01842e778e3bf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da8dc2b32da941d8a860b5cb2eb3d545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d08c23897ba64163a3a657235fb739f4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8770b1c3da2a4d6092a234e99aba55c3",
              "IPY_MODEL_bea32c9d7d0342e5b7289c7d6c6bfd72"
            ]
          }
        },
        "d08c23897ba64163a3a657235fb739f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8770b1c3da2a4d6092a234e99aba55c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e17c4732e4cd432fae17f023586f3b87",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_77f3d02cfc0746e2b76be9013c07aaeb"
          }
        },
        "bea32c9d7d0342e5b7289c7d6c6bfd72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2ea17dc56fe447ceba45a7fc4a99bee4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "88/|/| 88/? [55:39&lt;00:00, 40.19s/it, loss=1.99]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aef158bd928241d6ad78547543466cf9"
          }
        },
        "e17c4732e4cd432fae17f023586f3b87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "77f3d02cfc0746e2b76be9013c07aaeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ea17dc56fe447ceba45a7fc4a99bee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aef158bd928241d6ad78547543466cf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0yrKo_hJk70",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3a75ed38-ae46-4bf4-a90b-d01e51beefdb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8FojmZYKFuv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "d066ca99-4432-42d7-f771-3b69b51cfe9a"
      },
      "source": [
        "%cd '/content/gdrive/My Drive/Colab Notebooks/odir-ivashnyov/ODIR/'\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1-WHOINXFZ4JSjL7g5g092rZ8rCZfdBPw/odir-ivashnyov/ODIR\n",
            "CrossValidationScore.py\t\t  Predictions.py\n",
            "cv_split.pickle\t\t\t  predict.py\n",
            "data\t\t\t\t  __pycache__\n",
            "EDA.ipynb\t\t\t  README.md\n",
            "initial_test_b3_fold3_clahe\t  split_folds.ipynb\n",
            "logs\t\t\t\t  submit\n",
            "logs_final\t\t\t  submit_final\n",
            "MNIST\t\t\t\t  submit_initial_test_b3.csv\n",
            "model_concate_10_no_epoch.txt\t  submit_oanh_initial_test_b3.csv\n",
            "model_concate_15epoch_weight.txt  submit_vessel_initial_test_b3.csv\n",
            "model_concate_19epoch.txt\t  train_1cycle.py\n",
            "model_concate_20epoch.txt\t  train_all_folds_args.sh\n",
            "model_concate_5_no_epoch.txt\t  train_all_folds.sh\n",
            "model_concate_6epoch.txt\t  train.py\n",
            "model_concate_epoch_20.txt\t  utils.py\n",
            "odir_submit.py\t\t\t  Visualization.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suTAV-P-KI2d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5ce1bd5d-1cfe-4989-d969-2853a448eee6"
      },
      "source": [
        "!pip install catalyst==20.2.4\n",
        "!pip install tqdm==4.33\n",
        "!pip install efficientnet_pytorch\n",
        "!pip install pytorch_toolbelt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catalyst==20.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/88/82ddb7cc19e8af8e4ec4023f43611a9627fe67c419981756f9339d0753b5/catalyst-20.2.4-py2.py3-none-any.whl (355kB)\n",
            "\r\u001b[K     |█                               | 10kB 21.9MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 4.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 30kB 5.8MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 6.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 61kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 81kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 92kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 102kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 112kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 122kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 153kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 163kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 174kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 184kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 194kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 204kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 215kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 225kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 235kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 245kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 256kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 266kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 276kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 286kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 296kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 307kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 317kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 327kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 337kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 348kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.2.4) (1.6.0+cu101)\n",
            "Collecting Pillow<7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/fd/bbbc569f98f47813c50a116b539d97b3b17a86ac7a309f83b2022d26caf2/Pillow-6.2.2-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 23.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.22 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.2.4) (1.0.5)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.2.4) (0.16.2)\n",
            "Collecting safitty>=1.2.3\n",
            "  Downloading https://files.pythonhosted.org/packages/37/ea/51fedb7c8802b09d557a04db13661939bb483f40e1450958961ce50f15d6/safitty-1.3-py3-none-any.whl\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from catalyst==20.2.4) (2.4.1)\n",
            "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.2.4) (4.41.1)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.2.4) (0.7.0+cu101)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from catalyst==20.2.4) (5.5.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from catalyst==20.2.4) (4.1.2.30)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.2.4) (0.22.2.post1)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 36.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.2.4) (2.3.0)\n",
            "Requirement already satisfied: plotly>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.2.4) (4.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catalyst==20.2.4) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.2.4) (1.18.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from catalyst==20.2.4) (3.13)\n",
            "Collecting GitPython>=2.1.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/1e/a45320cab182bf1c8656107b3d4c042e659742822fc6bff150d769a984dd/GitPython-3.1.7-py3-none-any.whl (158kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 38.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from catalyst==20.2.4) (20.4)\n",
            "Collecting crc32c>=1.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/ef/63dafd9e92fc6d03c7c5db893261d1304f8e67f187851eb486ede95bbec3/crc32c-2.0.1-cp36-cp36m-manylinux2010_x86_64.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from catalyst==20.2.4) (0.10.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->catalyst==20.2.4) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->catalyst==20.2.4) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->catalyst==20.2.4) (2.8.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->catalyst==20.2.4) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->catalyst==20.2.4) (2.4)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->catalyst==20.2.4) (1.4.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.2.4) (49.2.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.2.4) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.2.4) (4.3.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.2.4) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.2.4) (2.1.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.2.4) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.2.4) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.2.4) (0.7.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->catalyst==20.2.4) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX->catalyst==20.2.4) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->catalyst==20.2.4) (3.12.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.2.4) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.2.4) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.2.4) (3.2.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.2.4) (1.17.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.2.4) (0.9.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.2.4) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.2.4) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.2.4) (1.30.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.2.4) (1.7.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->catalyst==20.2.4) (1.3.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst==20.2.4) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst==20.2.4) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst==20.2.4) (2.4.7)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->catalyst==20.2.4) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->catalyst==20.2.4) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->catalyst==20.2.4) (0.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst==20.2.4) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst==20.2.4) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst==20.2.4) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst==20.2.4) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst==20.2.4) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=1.14.0->catalyst==20.2.4) (1.7.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst==20.2.4) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst==20.2.4) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst==20.2.4) (0.2.8)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst==20.2.4) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14.0->catalyst==20.2.4) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst==20.2.4) (0.4.8)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow, safitty, tensorboardX, smmap, gitdb, GitPython, crc32c, catalyst\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "Successfully installed GitPython-3.1.7 Pillow-6.2.2 catalyst-20.2.4 crc32c-2.0.1 gitdb-4.0.5 safitty-1.3 smmap-3.0.4 tensorboardX-2.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting tqdm==4.33\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/56/60a5b1c2e634d8e4ff89c7bab47645604e19658f448050a21facffd43796/tqdm-4.33.0-py2.py3-none-any.whl (50kB)\n",
            "\r\u001b[K     |██████▌                         | 10kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 30kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 40kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.2MB/s \n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.33.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed tqdm-4.33.0\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/cb/0309a6e3d404862ae4bc017f89645cf150ac94c14c88ef81d215c8e52925/efficientnet_pytorch-0.6.3.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.18.5)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-cp36-none-any.whl size=12422 sha256=f6c50bef23c68f6be4a0fac667e553f7b505157be7f4423cf5faedf9e28b42ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/1e/a9/2a578ba9ad04e776e80bf0f70d8a7f4c29ec0718b92d8f6ccd\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.6.3\n",
            "Collecting pytorch_toolbelt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/0d/90964571b4ddf71e455280395ed871cfeb29441d167c37a1ff21de5cf96c/pytorch_toolbelt-0.3.2.tar.gz (91kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.6/dist-packages (from pytorch_toolbelt) (1.6.0+cu101)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytorch_toolbelt) (0.7.0+cu101)\n",
            "Requirement already satisfied: opencv-python>=4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_toolbelt) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow<7.0,>=6.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_toolbelt) (6.2.2)\n",
            "Collecting torchnet>=0.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/b2/d7f70a85d3f6b0365517782632f150e3bbc2fb8e998cd69e27deba599aae/torchnet-0.0.4.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->pytorch_toolbelt) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->pytorch_toolbelt) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchnet>=0.0.4->pytorch_toolbelt) (1.15.0)\n",
            "Collecting visdom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/75/e078f5a2e1df7e0d3044749089fc2823e62d029cc027ed8ae5d71fafcbdc/visdom-0.1.8.9.tar.gz (676kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 12.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet>=0.0.4->pytorch_toolbelt) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet>=0.0.4->pytorch_toolbelt) (2.23.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet>=0.0.4->pytorch_toolbelt) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet>=0.0.4->pytorch_toolbelt) (19.0.2)\n",
            "Collecting jsonpatch\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/d0/34b0f59ac08de9c1e07876cfecd80aec650600177b4bd445124c755499a7/jsonpatch-1.26-py2.py3-none-any.whl\n",
            "Collecting torchfile\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Collecting websocket-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 35.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet>=0.0.4->pytorch_toolbelt) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet>=0.0.4->pytorch_toolbelt) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet>=0.0.4->pytorch_toolbelt) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet>=0.0.4->pytorch_toolbelt) (1.24.3)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading https://files.pythonhosted.org/packages/18/b0/a80d29577c08eea401659254dfaed87f1af45272899e1812d7e01b679bc5/jsonpointer-2.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pytorch-toolbelt, torchnet, visdom, torchfile\n",
            "  Building wheel for pytorch-toolbelt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-toolbelt: filename=pytorch_toolbelt-0.3.2-cp36-none-any.whl size=122683 sha256=b92dcca0a72a940523f1a71da7baada1932df5e95fed8a3670481147c7e99544\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/8c/02/3f1b734b39463a8b355bd0dc359a14f37ba434957dda0b71b6\n",
            "  Building wheel for torchnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchnet: filename=torchnet-0.0.4-cp36-none-any.whl size=29744 sha256=162585fef2af7965d010ff42dbc62d6504da193cb77dd8d195040a716e451026\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/03/fb/1c212c2f20905cdf97fe39022946cf16b8e66ed754a6663400\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-cp36-none-any.whl size=655250 sha256=c71f0246a13116c6a0e1d05d99bc02492af1d51a21b95024cb11738dbda090ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/19/a7/6d589ed967f4dfefd33bc166d081257bd4ed0cb618dccfd62a\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-cp36-none-any.whl size=5712 sha256=8c49ee9b26f4738044c3b0301f8376ae85ab2a6abe9dcdd07a0ce97498882244\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "Successfully built pytorch-toolbelt torchnet visdom torchfile\n",
            "Installing collected packages: jsonpointer, jsonpatch, torchfile, websocket-client, visdom, torchnet, pytorch-toolbelt\n",
            "Successfully installed jsonpatch-1.26 jsonpointer-2.0 pytorch-toolbelt-0.3.2 torchfile-0.1.0 torchnet-0.0.4 visdom-0.1.8.9 websocket-client-0.57.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtZ2WJmcvR_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "outputId": "18de09d5-2500-4245-a7e1-94bfd4c668d9"
      },
      "source": [
        "!pip install -U ipykernel"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipykernel\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/19/c2812690d8b340987eecd2cbc18549b1d130b94c5d97fcbe49f5f8710edf/ipykernel-5.3.4-py3-none-any.whl (120kB)\n",
            "\r\u001b[K     |██▊                             | 10kB 21.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 20kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 30kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 40kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 61kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 71kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 81kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 92kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 102kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 112kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tornado>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipykernel) (5.1.1)\n",
            "Requirement already satisfied, skipping upgrade: ipython>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel) (5.5.0)\n",
            "Requirement already satisfied, skipping upgrade: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel) (4.3.3)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel) (5.3.5)\n",
            "Requirement already satisfied, skipping upgrade: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (0.7.5)\n",
            "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (4.8.0)\n",
            "Requirement already satisfied, skipping upgrade: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (1.0.18)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (49.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (2.1.3)\n",
            "Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel) (19.0.2)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel) (4.6.3)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0.0->ipykernel) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0.0->ipykernel) (0.2.5)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.3.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: ipykernel\n",
            "  Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "Successfully installed ipykernel-5.3.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipykernel"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEO8HqWoJ99O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8d504112-36ac-48dc-8033-faf4a137778c"
      },
      "source": [
        "from sklearn import svm\n",
        "from keras.callbacks import CSVLogger\n",
        "from keras.callbacks import LambdaCallback\n",
        "from utils import *\n",
        "#from simple_model import *\n",
        "#from preprocess import *\n",
        "#from make_labels import *\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import asarray\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import collections\n",
        "from pytorch_toolbelt.inference import tta\n",
        "from catalyst.dl.callbacks import InferCallback\n",
        "from catalyst.dl.runner import SupervisedRunner\n",
        "from torch.nn.functional import softmax\n",
        "from catalyst.dl.callbacks import EarlyStoppingCallback, AccuracyCallback, F1ScoreCallback, ConfusionMatrixCallback, MixupCallback\n",
        "from catalyst.contrib.nn.schedulers import OneCycleLR, ReduceLROnPlateau, StepLR, MultiStepLR\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torchsummary import summary\n",
        "import pickle\n",
        "import time\n",
        "import copy\n",
        "from tqdm.auto import tqdm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alchemy not available, to install alchemy, run `pip install alchemy-catalyst`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trgaC5cJJzVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\n",
        "    '/content/gdrive/My Drive/Colab Notebooks/odir-ivashnyov/ODIR/data/splited_train_new.csv')\n",
        "splits = pickle.load(open(\n",
        "    '/content/gdrive/My Drive/Colab Notebooks/odir-ivashnyov/ODIR/cv_split.pickle', 'rb'))\n",
        "labels = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n",
        "image_size = 240\n",
        "fold_idx = 3\n",
        "batch_size = 32\n",
        "lr = 1e-5"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sybWfPJo5OWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CUDA for PyTorch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "num_wkr=0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-tHRoJ_K3Gb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0bafa3c3-8cc5-4894-9969-21c25899b8d5"
      },
      "source": [
        "train_path1 = '/content/gdrive/My Drive/Colab Notebooks/odir-ivashnyov/ODIR/data/clahe-train/'\n",
        "valid_path1 = '/content/gdrive/My Drive/Colab Notebooks/odir-ivashnyov/ODIR/data/clahe-train/'\n",
        "\n",
        "train_dataset1 = EyeDataset(dataset_path=train_path1,\n",
        "                           labels=data.loc[splits['train_idx'][fold_idx],labels].values,\n",
        "                           ids=data.loc[splits['train_idx'][fold_idx], 'id'].values,\n",
        "                           albumentations_tr=aug_train_heavy(image_size))\n",
        "\n",
        "train_loader1 = DataLoader(train_dataset1,\n",
        "                          num_workers=num_wkr,\n",
        "                          pin_memory=True,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=False)\n",
        "logdir = '/content/gdrive/My Drive/Colab Notebooks/odir-ivashnyov/ODIR/logs_final/initial_test_b3_fold3_clahe/'\n",
        "modelA = prepare_model('efficientnet-b3', 8)\n",
        "modelA.cuda()\n",
        "modelA.load_state_dict(torch.load(os.path.join(\n",
        "    logdir, '/content/gdrive/My Drive/Colab Notebooks/odir-ivashnyov/ODIR/logs_final/initial_test_b3_fold3_clahe/checkpoints/best.pth'))['model_state_dict'])\n",
        "modelA.eval()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Will load efficientnet-b3 with 8 classes\n",
            "Loaded pretrained weights for efficientnet-b3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (_conv_stem): Conv2dStaticSamePadding(\n",
              "    3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
              "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "  )\n",
              "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_blocks): ModuleList(\n",
              "    (0): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        40, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (1): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (2): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (3): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (4): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (5): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (6): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (7): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (8): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (9): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (10): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (11): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (12): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (13): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (14): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (15): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (16): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (17): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (18): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (19): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (20): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (21): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (22): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (23): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (24): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (25): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "  )\n",
              "  (_conv_head): Conv2dStaticSamePadding(\n",
              "    384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "    (static_padding): Identity()\n",
              "  )\n",
              "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
              "  (_dropout): Dropout(p=0.3, inplace=False)\n",
              "  (_fc): Linear(in_features=1536, out_features=8, bias=True)\n",
              "  (_swish): MemoryEfficientSwish()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx1pf7D4LDnx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a348d049-9a14-47d4-e4e8-9f39bce06318"
      },
      "source": [
        "train_path2 = '/content/gdrive/My Drive/Colab Notebooks/odir-ivashnyov/ODIR/data/vessel-train-full/'\n",
        "valid_path2 = '/content/gdrive/My Drive/Colab Notebooks/odir-ivashnyov/ODIR/data/vessel-train-full/'\n",
        "\n",
        "train_dataset2 = EyeDataset(dataset_path=train_path2,\n",
        "                           labels=data.loc[splits['train_idx'][fold_idx],labels].values,\n",
        "                           ids=data.loc[splits['train_idx'][fold_idx], 'id'].values,\n",
        "                           albumentations_tr=aug_train_heavy(image_size))\n",
        "train_loader2 = DataLoader(train_dataset2,\n",
        "                          num_workers=num_wkr,\n",
        "                          pin_memory=True,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=False)\n",
        "\n",
        "logdir = '/content/gdrive/My Drive/Colab Notebooks/odir-ivashnyov/ODIR/logs_final/initial_test_b3_fold3_vessel/'\n",
        "modelB = prepare_model('efficientnet-b3', 8)\n",
        "modelB.cuda()\n",
        "modelB.load_state_dict(torch.load(os.path.join(\n",
        "    logdir, '/content/gdrive/My Drive/Colab Notebooks/odir-ivashnyov/ODIR/logs_final/initial_test_b3_fold3_vessel/checkpoints/best.pth'))['model_state_dict'])\n",
        "modelB.eval()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Will load efficientnet-b3 with 8 classes\n",
            "Loaded pretrained weights for efficientnet-b3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (_conv_stem): Conv2dStaticSamePadding(\n",
              "    3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
              "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "  )\n",
              "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_blocks): ModuleList(\n",
              "    (0): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        40, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (1): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (2): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (3): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (4): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (5): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (6): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (7): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (8): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (9): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (10): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (11): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (12): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (13): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (14): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (15): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (16): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (17): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (18): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (19): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (20): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (21): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (22): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (23): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (24): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (25): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "  )\n",
              "  (_conv_head): Conv2dStaticSamePadding(\n",
              "    384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "    (static_padding): Identity()\n",
              "  )\n",
              "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
              "  (_dropout): Dropout(p=0.3, inplace=False)\n",
              "  (_fc): Linear(in_features=1536, out_features=8, bias=True)\n",
              "  (_swish): MemoryEfficientSwish()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyERGLennFXf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "e8dab899-1451-4f8d-8aab-03ec5ae35134"
      },
      "source": [
        "\n",
        "# x = modelA.extract_features(torch.ones((1,3,224,224)).cuda())\n",
        "# # feature ngộ nghĩnh vl\n",
        "\n",
        "# x1 = nn.functional.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
        "# x2 = x1.clone()\n",
        "\n",
        "# y = torch.cat((x1,x2), 1)\n",
        "\n",
        "# y_sigmoid = torch.sigmoid(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-148-a7ae076fb729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# feature ngộ nghĩnh vl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPNg7rijzqAA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "59d557ff-e57f-4183-d3cb-2a63ae07e8fd"
      },
      "source": [
        "n = nn.Linear(48, 24)\n",
        "a = n(torch.rand(55, 64, 48))\n",
        "\n",
        "a.flatten(start_dim=1).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([55, 1536])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfd8eaeMrK5n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "87982eba-2e2f-4aab-f5a7-4e1fd52caaf3"
      },
      "source": [
        "X = torch.rand((1,3072))\n",
        "\n",
        "W_x = nn.Parameter(torch.Tensor(48, 24))\n",
        "b_x = nn.Parameter(torch.Tensor(1, 1536))\n",
        "# print(W_x.shape)\n",
        "# print(type(W_x))\n",
        "# print(b_x.shape)\n",
        "\n",
        "gate = torch.sigmoid((X.view(64, 48) @ W_x).flatten() + b_x)\n",
        "# gate.shape\n",
        "# Sigmoid(X * W_x + b_x)\n",
        "\n",
        "# Sigmoid = 1x1536\n",
        "\n",
        "# X ==> 1 x 3072\n",
        "# X' => 64 x 48\n",
        "# W_X ==> 48 x 24\n",
        "# # b_x ==> 1x1536.\n",
        "\n",
        "# x2 ==> 1x1536\n",
        "# torch.arange(0, 1000).view(50, 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1536])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUx2KwIkqQXz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0eec0bec-9ba3-4f32-e791-28e566ccaa0e"
      },
      "source": [
        "m = nn.Softmax(dim=1)\n",
        "input = torch.randn(1,5)\n",
        "output = m(input)\n",
        "output.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lfXYDnVrjFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, modelA, modelB, nb_classes=8):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.modelA = modelA\n",
        "        self.modelB = modelB\n",
        "        self.drop = nn.Dropout(0.3)\n",
        "        self.out2 = nn.Linear(1536, 8)\n",
        "        self.modelA.fc = nn.Identity()\n",
        "        self.modelB.fc = nn.Identity()\n",
        "        # self.W_x = nn.Parameter(torch.Tensor(48, 24)).to(device)\n",
        "        # self.b_x = nn.Parameter(torch.Tensor(1, 1536)).to(device)\n",
        "        self.W_g = nn.Linear(48, 24)\n",
        "        # nn.init.xavier_uniform_(self.W_x.data)\n",
        "        # nn.init.xavier_uniform_(self.b_x.data)\n",
        "        nn.init.xavier_uniform_(self.W_g.weight)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.modelA.extract_features(x1)\n",
        "        x2 = self.modelB.extract_features(x2)\n",
        "        # print(x1.shape)\n",
        "        x1 = nn.functional.adaptive_avg_pool2d(x1, 1).squeeze(-1).squeeze(-1)\n",
        "        x2 = nn.functional.adaptive_avg_pool2d(x2, 1).squeeze(-1).squeeze(-1)\n",
        "        # print('shape of x1:',x1.shape)\n",
        "        # x1 = x1.view(1,1536)\n",
        "        # x1 = torch.Tensor.cpu(x1).detach().numpy()\n",
        "        # x2 = x2.view(1,1536)\n",
        "        # x2 = torch.Tensor.cpu(x2).detach().numpy()\n",
        "        x = torch.cat((x1, x2), 1)   \n",
        "        # print('shape of feature cat:',x.shape)  \n",
        "        # print(type(x))\n",
        "        # sigmoid = torch.sigmoid(x)\n",
        "        # multi = tf.math.multiply(sigmoid,x2)\n",
        "        # add = multi + x1\n",
        "        # add = add.numpy()\n",
        "        # x = torch.from_numpy(add)\n",
        "        # x = self.drop(x)\n",
        "        # x = x.flatten()\n",
        "        # x = self.out2(x)\n",
        "        \n",
        "        # gate = torch.sigmoid((x.view(64, 48) @ self.W_x).flatten() + self.b_x)\n",
        "        gate = torch.sigmoid(self.W_g(x.view(-1, 64, 48))).flatten(start_dim=1)\n",
        "        # print('value of gate:',gate)\n",
        "        # print('shape of gate:',gate.shape)  \n",
        "        features = gate * x2 + x1\n",
        "        \n",
        "        # print('value of features:',gate)\n",
        "        # print('shape of features:',features.shape)  \n",
        "        # features = features.cpu().detach().numpy()\n",
        "        # features = torch.from_numpy(features)\n",
        "        features = self.drop(features)\n",
        "        features = self.out2(features)\n",
        "        return features"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84nwHts-Sfpx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "0724cc6a-caa2-48ca-914c-6c4e5489d928"
      },
      "source": [
        "input1 = torch.rand([32, 3, 240, 240]).to(device)\n",
        "input2 = torch.rand([32, 3, 240, 240]).to(device)\n",
        "\n",
        "probabilities = []\n",
        "x_model = NeuralNet(modelA, modelB)\n",
        "x_model.to(device)\n",
        "y = x_model(input1,input2)\n",
        "print(y.shape)\n",
        "\n",
        "softmax(y, dim=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d200cf1ff5de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-b3663dd0235d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m# print(x1.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mdrop_connect_rate\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, drop_connect_rate)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_ratio\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bn0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expand_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depthwise_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# Squeeze and Excitation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2014\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   2015\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2016\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2017\u001b[0m     )\n\u001b[1;32m   2018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 11.17 GiB total capacity; 10.71 GiB already allocated; 5.81 MiB free; 10.80 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FhHi7zCpjcW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "08579547-502e-43b5-e48d-e85f2def07f5"
      },
      "source": [
        "x_model = NeuralNet(modelA, modelB)\n",
        "x_model.to(device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNet(\n",
              "  (modelA): EfficientNet(\n",
              "    (_conv_stem): Conv2dStaticSamePadding(\n",
              "      3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
              "      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "    )\n",
              "    (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "    (_blocks): ModuleList(\n",
              "      (0): MBConvBlock(\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          40, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          10, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (1): MBConvBlock(\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (2): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (3): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (4): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (5): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (6): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (7): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (8): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (9): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (10): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (11): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (12): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (13): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (14): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (15): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (16): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (17): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (18): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (19): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (20): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (21): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (22): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (23): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (24): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (25): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "    )\n",
              "    (_conv_head): Conv2dStaticSamePadding(\n",
              "      384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "      (static_padding): Identity()\n",
              "    )\n",
              "    (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
              "    (_dropout): Dropout(p=0.3, inplace=False)\n",
              "    (_fc): Linear(in_features=1536, out_features=8, bias=True)\n",
              "    (_swish): MemoryEfficientSwish()\n",
              "    (fc): Identity()\n",
              "  )\n",
              "  (modelB): EfficientNet(\n",
              "    (_conv_stem): Conv2dStaticSamePadding(\n",
              "      3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
              "      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "    )\n",
              "    (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "    (_blocks): ModuleList(\n",
              "      (0): MBConvBlock(\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          40, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          10, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (1): MBConvBlock(\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (2): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (3): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (4): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (5): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (6): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (7): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (8): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (9): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (10): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (11): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (12): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (13): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (14): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (15): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (16): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (17): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (18): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (19): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (20): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (21): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (22): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (23): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (24): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (25): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False\n",
              "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "    )\n",
              "    (_conv_head): Conv2dStaticSamePadding(\n",
              "      384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "      (static_padding): Identity()\n",
              "    )\n",
              "    (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
              "    (_dropout): Dropout(p=0.3, inplace=False)\n",
              "    (_fc): Linear(in_features=1536, out_features=8, bias=True)\n",
              "    (_swish): MemoryEfficientSwish()\n",
              "    (fc): Identity()\n",
              "  )\n",
              "  (drop): Dropout(p=0.3, inplace=False)\n",
              "  (out2): Linear(in_features=1536, out_features=8, bias=True)\n",
              "  (W_g): Linear(in_features=48, out_features=24, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N8vrNstpCde",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "41fd7086-7512-4b7a-954d-8842cde79670"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Aug  7 02:47:02 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P0    60W / 149W |    498MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f927df91jPRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# freeze params in model A, model B\n",
        "for param in x_model.modelA.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "for param in x_model.modelB.parameters():\n",
        "  param.requires_grad = False"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpadAu3cR2K4",
        "colab_type": "text"
      },
      "source": [
        "**TRAIN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MKM4WJHL0AJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "6515097fb8404c219d1ff3ec30073e17",
            "82a9f839c4544944bedcb2fd112bc450",
            "47b4b8e7a8a04938ac720a2122c5ab06",
            "c3122383a0f5497f8851aa87690a0ad5",
            "35182732fca34efcadc7a3ed2f6a4566",
            "af35d843a2fc48f5b3eb8bee9989b75c",
            "b65ad26e1e614c6f9227bc716d473d46",
            "dec5c042a4a147999d01842e778e3bf0",
            "da8dc2b32da941d8a860b5cb2eb3d545",
            "d08c23897ba64163a3a657235fb739f4",
            "8770b1c3da2a4d6092a234e99aba55c3",
            "bea32c9d7d0342e5b7289c7d6c6bfd72",
            "e17c4732e4cd432fae17f023586f3b87",
            "77f3d02cfc0746e2b76be9013c07aaeb",
            "2ea17dc56fe447ceba45a7fc4a99bee4",
            "aef158bd928241d6ad78547543466cf9"
          ]
        },
        "outputId": "499de013-f6af-4cb7-8288-0d416100e03e"
      },
      "source": [
        "optimizer = torch.optim.Adam(x_model.parameters(), lr=1e-5) ## em truyền params nó vào đây\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# scheduler = ReduceLROnPlateau(optimizer=optimizer, factor=0.75, patience=2)\n",
        "loss_log = []\n",
        "PATH_SAVE = '/content/gdrive/My Drive/Colab Notebooks/odir-ivashnyov/ODIR/logs_final/clahe_vessel_forgetgate_new/'\n",
        "if not os.path.exists(PATH_SAVE):\n",
        "       os.makedirs(PATH_SAVE)\n",
        "\n",
        "x_model.train()\n",
        "for epoch in tqdm(range(20)):\n",
        "  tqdm_iter = tqdm(zip(train_loader1,train_loader2))\n",
        "  for i1, i2 in tqdm_iter:\n",
        "    #print(i1)\n",
        "    # stt1, data1 = i1\n",
        "    input1,target1 = i1\n",
        "    #print(i2)\n",
        "    # stt2, data2 = i2\n",
        "    input2,target2 = i2\n",
        "\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    input1, target1 = input1.to(device), target1.to(device)\n",
        "    input2, target2 = input2.to(device), target2.to(device)\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    outputs = x_model(input1,input2)\n",
        "    #print(outputs)\n",
        "    #print(target1)\n",
        "    # outputs = outputs.view(1,8)\n",
        "\n",
        "    loss = criterion(outputs, target1)\n",
        "    loss.backward()\n",
        "    tqdm_iter.set_postfix(loss=loss.item())\n",
        "    optimizer.step() ## đây nó update đôn params kia. em muốn không train phần A hay B em phải chạy cái phần require_grad = false gì đấy, mà nhét cái đó vô chỗ nào? em muons làm gì, em muốn k train para trong model A,B\n",
        "  loss_log.append(loss)\n",
        "  torch.save(x_model.state_dict(), PATH_SAVE + 'clahe_vessel_forgetgate_new_epoch_'+str(epoch)+'.pth')\n",
        "\n",
        "with open(PATH_SAVE+\"clahe_vessel_forgetgate_new.txt\", \"w\") as output:\n",
        "    output.write(str(loss_log))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6515097fb8404c219d1ff3ec30073e17",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da8dc2b32da941d8a860b5cb2eb3d545",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcMgnjks0K69",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b15101b9-2397-407c-a386-066f62a4a6f9"
      },
      "source": [
        "for i1, i2 in zip(train_loader1,train_loader2):\n",
        "  print(i1,i2)\n",
        "  break"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([[[[-2.0494, -2.0837, -2.0323,  ..., -2.1008, -2.1179, -2.1008],\n",
            "          [-2.0837, -2.0494, -2.0837,  ..., -2.1179, -2.1008, -2.0837],\n",
            "          [-2.0837, -2.0494, -2.0494,  ..., -2.0494, -2.0837, -2.0837],\n",
            "          ...,\n",
            "          [-2.0837, -2.0494, -2.0494,  ..., -2.0837, -2.0152, -2.0494],\n",
            "          [-2.0494, -2.0837, -2.1008,  ..., -2.0494, -2.0837, -2.0837],\n",
            "          [-2.0837, -2.1179, -2.0837,  ..., -2.0152, -2.1179, -2.0152]],\n",
            "\n",
            "         [[-1.9657, -2.0007, -1.9482,  ..., -2.0182, -2.0357, -2.0182],\n",
            "          [-2.0007, -1.9657, -2.0007,  ..., -2.0357, -2.0182, -2.0007],\n",
            "          [-2.0007, -1.9657, -1.9657,  ..., -1.9657, -2.0007, -2.0007],\n",
            "          ...,\n",
            "          [-2.0007, -1.9657, -1.9657,  ..., -2.0007, -1.9307, -1.9657],\n",
            "          [-1.9657, -2.0007, -2.0182,  ..., -1.9657, -2.0007, -2.0007],\n",
            "          [-2.0007, -2.0357, -2.0007,  ..., -1.9307, -2.0357, -1.9307]],\n",
            "\n",
            "         [[-1.7347, -1.7696, -1.7173,  ..., -1.7870, -1.8044, -1.7870],\n",
            "          [-1.7696, -1.7347, -1.7696,  ..., -1.8044, -1.7870, -1.7696],\n",
            "          [-1.7696, -1.7347, -1.7347,  ..., -1.7347, -1.7696, -1.7696],\n",
            "          ...,\n",
            "          [-1.7696, -1.7347, -1.7347,  ..., -1.7696, -1.6999, -1.7347],\n",
            "          [-1.7347, -1.7696, -1.7870,  ..., -1.7347, -1.7696, -1.7696],\n",
            "          [-1.7696, -1.8044, -1.7696,  ..., -1.6999, -1.8044, -1.6999]]],\n",
            "\n",
            "\n",
            "        [[[-1.6555, -1.4500, -1.3987,  ..., -1.2788, -1.2959, -1.4843],\n",
            "          [-1.5185, -1.6042, -1.3987,  ..., -1.5185, -1.3815, -1.4500],\n",
            "          [-1.4329, -1.3815, -1.3130,  ..., -1.4329, -1.3987, -1.2959],\n",
            "          ...,\n",
            "          [-1.3302, -1.3473, -1.4500,  ..., -1.6042, -1.4672, -1.2617],\n",
            "          [-1.5870, -1.3130, -1.3987,  ..., -1.4500, -1.6384, -1.4158],\n",
            "          [-1.1760, -1.2445, -1.1589,  ..., -1.4672, -1.6384, -1.3987]],\n",
            "\n",
            "         [[-1.4580, -1.3354, -1.1604,  ..., -1.0728, -1.2829, -1.2829],\n",
            "          [-1.3354, -1.3354, -1.4580,  ..., -1.0728, -1.3529, -1.3179],\n",
            "          [-1.4055, -1.2129, -1.3004,  ..., -1.2129, -1.1429, -1.1253],\n",
            "          ...,\n",
            "          [-1.1954, -1.6506, -1.0553,  ..., -1.1429, -1.5630, -1.5280],\n",
            "          [-1.4055, -1.4055, -1.3354,  ..., -1.3004, -1.5630, -1.5980],\n",
            "          [-1.2304, -1.3004, -1.3529,  ..., -1.2304, -1.3004, -1.3354]],\n",
            "\n",
            "         [[-0.9156, -1.0724, -0.7936,  ..., -1.1596, -1.0201, -1.1247],\n",
            "          [-0.9156, -1.1770, -1.2467,  ..., -1.4559, -1.2293, -1.0550],\n",
            "          [-1.0550, -0.8807, -1.0724,  ..., -0.7936, -0.9853, -1.3339],\n",
            "          ...,\n",
            "          [-0.9678, -1.0027, -1.0724,  ..., -1.0898, -1.0027, -1.0027],\n",
            "          [-1.1421, -0.9156, -1.1247,  ..., -1.2816, -1.1247, -0.9678],\n",
            "          [-1.0027, -1.2467, -1.1944,  ..., -1.1247, -1.1770, -1.0550]]],\n",
            "\n",
            "\n",
            "        [[[-1.6213, -1.6727, -1.7069,  ..., -1.6555, -1.6898, -1.7240],\n",
            "          [-1.6213, -1.7583, -1.7240,  ..., -1.7240, -1.7069, -1.5185],\n",
            "          [-1.5870, -1.7925, -1.6213,  ..., -1.9295, -1.7412, -1.7754],\n",
            "          ...,\n",
            "          [-1.6898, -1.9809, -1.7412,  ..., -1.5357, -1.7583, -1.5870],\n",
            "          [-1.6213, -1.5528, -1.7240,  ..., -1.6898, -1.6727, -1.7583],\n",
            "          [-1.6384, -1.6384, -1.7412,  ..., -1.7240, -1.7412, -1.6384]],\n",
            "\n",
            "         [[-1.4930, -1.5980, -1.5805,  ..., -1.6506, -1.5980, -1.6331],\n",
            "          [-1.4405, -1.6331, -1.8782,  ..., -1.6155, -1.5455, -1.6856],\n",
            "          [-1.5805, -1.6155, -1.7381,  ..., -1.6506, -1.6331, -1.6856],\n",
            "          ...,\n",
            "          [-1.5805, -1.6506, -1.5805,  ..., -1.6331, -1.5105, -1.6506],\n",
            "          [-1.5455, -1.6331, -1.7381,  ..., -1.5980, -1.5280, -1.5805],\n",
            "          [-1.5980, -1.5105, -1.5980,  ..., -1.6681, -1.5980, -1.5105]],\n",
            "\n",
            "         [[-1.3513, -1.3513, -1.3513,  ..., -1.3339, -1.2641, -1.3861],\n",
            "          [-1.3687, -1.4907, -1.5081,  ..., -1.2467, -1.4907, -1.4907],\n",
            "          [-1.4036, -1.2816, -1.5430,  ..., -1.4384, -1.4210, -1.3513],\n",
            "          ...,\n",
            "          [-1.3339, -1.2641, -1.3339,  ..., -1.3339, -1.2816, -1.2119],\n",
            "          [-1.4210, -1.4036, -1.5081,  ..., -1.5081, -1.2641, -1.2990],\n",
            "          [-1.2641, -1.3861, -1.3513,  ..., -1.3861, -1.3687, -1.3164]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.7925, -2.1179, -1.9809,  ..., -2.1179, -1.9295, -1.9809],\n",
            "          [-2.1179, -2.1008, -1.8097,  ..., -2.1179, -1.9467, -1.9809],\n",
            "          [-2.0837, -2.1179, -2.0323,  ..., -1.9809, -1.9467, -2.0837],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -1.9980, -2.1179],\n",
            "          [-1.8953, -1.9638, -1.9980,  ..., -1.8268, -2.1179, -2.1179],\n",
            "          [-2.1179, -1.9638, -2.1179,  ..., -1.8439, -2.1179, -1.5870]],\n",
            "\n",
            "         [[-1.7031, -2.0357, -1.8957,  ..., -2.0357, -1.8431, -1.8957],\n",
            "          [-2.0357, -2.0182, -1.7206,  ..., -2.0357, -1.8606, -1.8957],\n",
            "          [-2.0007, -2.0357, -1.9482,  ..., -1.8957, -1.8606, -2.0007],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -1.9132, -2.0357],\n",
            "          [-1.8081, -1.8782, -1.9132,  ..., -1.7381, -2.0357, -2.0357],\n",
            "          [-2.0357, -1.8782, -2.0357,  ..., -1.7556, -2.0357, -1.4930]],\n",
            "\n",
            "         [[-1.4733, -1.8044, -1.6650,  ..., -1.8044, -1.6127, -1.6650],\n",
            "          [-1.8044, -1.7870, -1.4907,  ..., -1.8044, -1.6302, -1.6650],\n",
            "          [-1.7696, -1.8044, -1.7173,  ..., -1.6650, -1.6302, -1.7696],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.6824, -1.8044],\n",
            "          [-1.5779, -1.6476, -1.6824,  ..., -1.5081, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.6476, -1.8044,  ..., -1.5256, -1.8044, -1.2641]]],\n",
            "\n",
            "\n",
            "        [[[-1.5185, -1.6384, -1.6727,  ..., -1.6727, -1.6384, -1.6555],\n",
            "          [-1.5185, -1.4672, -1.7412,  ..., -1.4843, -1.6213, -1.7412],\n",
            "          [-1.6384, -1.4329, -1.5357,  ..., -1.6898, -1.7240, -1.6898],\n",
            "          ...,\n",
            "          [-1.6555, -1.6042, -1.6727,  ..., -1.6213, -1.4843, -1.6898],\n",
            "          [-1.6042, -1.5870, -1.5357,  ..., -1.6727, -1.5185, -1.6555],\n",
            "          [-1.6555, -1.6727, -1.7240,  ..., -1.5870, -1.6213, -1.5870]],\n",
            "\n",
            "         [[-1.3179, -1.4930, -1.5105,  ..., -1.5105, -1.4230, -1.6155],\n",
            "          [-1.5280, -1.3880, -1.5805,  ..., -1.4930, -1.4755, -1.5105],\n",
            "          [-1.3529, -1.5105, -1.4755,  ..., -1.7381, -1.3704, -1.5630],\n",
            "          ...,\n",
            "          [-1.2654, -1.4055, -1.4930,  ..., -1.4055, -1.4580, -1.4405],\n",
            "          [-1.5105, -1.5455, -1.6155,  ..., -1.4930, -1.4055, -1.6331],\n",
            "          [-1.3529, -1.3529, -1.5455,  ..., -1.3704, -1.5455, -1.5455]],\n",
            "\n",
            "         [[-1.1421, -1.5256, -1.1596,  ..., -1.2641, -1.2293, -1.1944],\n",
            "          [-1.3513, -1.1421, -1.2990,  ..., -1.0898, -1.2293, -1.2467],\n",
            "          [-1.2990, -1.3339, -1.2816,  ..., -1.1770, -1.2293, -1.1421],\n",
            "          ...,\n",
            "          [-1.2293, -1.2293, -1.1770,  ..., -1.2293, -1.3164, -1.4384],\n",
            "          [-1.2119, -1.3861, -1.4384,  ..., -1.2119, -1.2467, -1.2467],\n",
            "          [-1.2467, -1.2641, -1.2119,  ..., -1.3339, -1.2641, -1.1770]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1700,  1.2899,  1.4098,  ...,  0.3309,  0.3481,  0.1768],\n",
            "          [ 1.0844,  1.2728,  1.3070,  ...,  0.3994,  0.3309,  0.2967],\n",
            "          [ 1.0331,  1.0844,  1.1700,  ...,  0.5878,  0.7762,  0.5536],\n",
            "          ...,\n",
            "          [-0.1828, -0.0629, -0.1999,  ...,  0.2282,  0.1254, -0.0116],\n",
            "          [-0.2684, -0.1999, -0.1486,  ...,  0.1768,  0.0912,  0.1426],\n",
            "          [-0.5424, -0.2171, -0.2684,  ..., -0.2171, -0.3541, -0.3541]],\n",
            "\n",
            "         [[ 0.9755,  1.0455,  1.2031,  ..., -0.1099, -0.0224, -0.0924],\n",
            "          [ 0.8179,  0.9755,  1.0805,  ...,  0.0126,  0.0651,  0.0826],\n",
            "          [ 0.6954,  0.8004,  0.8880,  ...,  0.1877,  0.4153,  0.2927],\n",
            "          ...,\n",
            "          [-0.6001, -0.4601, -0.5476,  ..., -0.1975, -0.2850, -0.4951],\n",
            "          [-0.6702, -0.5301, -0.4251,  ..., -0.3725, -0.4251, -0.4426],\n",
            "          [-0.9328, -0.5126, -0.4951,  ..., -0.8102, -0.9678, -1.0203]],\n",
            "\n",
            "         [[ 0.2696,  0.3393,  0.4614,  ..., -0.3927, -0.4798, -0.6367],\n",
            "          [ 0.1999,  0.3393,  0.3742,  ..., -0.3578, -0.4798, -0.5321],\n",
            "          [ 0.1476,  0.2871,  0.3393,  ..., -0.3230, -0.0615, -0.2707],\n",
            "          ...,\n",
            "          [-0.7413, -0.6018, -0.6890,  ..., -0.5670, -0.6541, -0.6890],\n",
            "          [-0.7238, -0.6541, -0.5321,  ..., -0.5844, -0.6715, -0.5495],\n",
            "          [-0.8633, -0.5844, -0.6193,  ..., -0.9678, -1.0550, -1.0550]]]]), tensor([3, 0, 0, 0, 1, 1, 7, 1, 1, 1, 7, 1, 7, 1, 0, 0, 7, 0, 1, 1, 7, 7, 6, 6,\n",
            "        0, 7, 7, 7, 6, 6, 1, 1])] [tensor([[[[-1.8782, -1.8268, -1.7925,  ..., -1.8097, -1.7754, -1.8782],\n",
            "          [-1.8782, -1.8782, -1.8953,  ..., -1.8439, -1.8439, -1.9124],\n",
            "          [-1.9809, -1.8782, -1.8610,  ..., -1.7583, -1.8268, -1.7925],\n",
            "          ...,\n",
            "          [-1.9124, -1.8782, -1.8953,  ..., -1.8610, -1.8097, -1.7754],\n",
            "          [-1.8439, -1.8953, -1.8439,  ..., -1.8268, -1.7583, -1.7583],\n",
            "          [-1.8268, -1.8439, -1.8097,  ..., -1.8268, -1.7754, -1.7240]],\n",
            "\n",
            "         [[-1.7381, -1.7731, -1.8782,  ..., -1.8256, -1.8782, -1.8081],\n",
            "          [-1.8256, -1.7906, -1.8957,  ..., -1.7731, -1.7556, -1.8081],\n",
            "          [-1.8606, -1.7206, -1.8081,  ..., -1.7906, -1.7731, -1.8256],\n",
            "          ...,\n",
            "          [-1.7031, -1.7556, -1.7731,  ..., -1.8256, -1.8431, -1.8256],\n",
            "          [-1.7906, -1.8256, -1.7381,  ..., -1.7906, -1.8256, -1.7381],\n",
            "          [-1.7381, -1.7906, -1.7556,  ..., -1.7906, -1.7556, -1.7556]],\n",
            "\n",
            "         [[-1.5081, -1.6127, -1.5604,  ..., -1.5953, -1.5081, -1.4559],\n",
            "          [-1.4559, -1.5604, -1.5081,  ..., -1.5430, -1.4384, -1.3687],\n",
            "          [-1.5081, -1.6127, -1.5430,  ..., -1.4907, -1.5081, -1.4733],\n",
            "          ...,\n",
            "          [-1.5604, -1.5430, -1.5256,  ..., -1.5430, -1.4733, -1.5081],\n",
            "          [-1.4907, -1.4733, -1.5081,  ..., -1.5779, -1.5604, -1.4907],\n",
            "          [-1.5081, -1.5256, -1.5430,  ..., -1.5604, -1.4907, -1.4733]]],\n",
            "\n",
            "\n",
            "        [[[-1.6898, -1.9295, -1.9295,  ..., -1.9295, -1.9295, -1.9295],\n",
            "          [-1.9295, -1.9295, -1.9295,  ..., -1.8268, -1.9295, -1.9295],\n",
            "          [-1.9295, -1.9295, -1.8268,  ..., -1.9295, -1.8953, -1.9295],\n",
            "          ...,\n",
            "          [-1.9295, -1.8953, -1.9295,  ..., -1.9295, -1.9295, -1.9295],\n",
            "          [-1.9295, -1.8610, -1.9295,  ..., -1.9295, -1.8268, -1.9295],\n",
            "          [-1.9295, -1.9295, -1.7412,  ..., -1.8782, -1.9295, -1.9295]],\n",
            "\n",
            "         [[-1.5980, -1.8431, -1.8431,  ..., -1.8431, -1.8431, -1.8431],\n",
            "          [-1.8431, -1.8431, -1.8431,  ..., -1.7381, -1.8431, -1.8431],\n",
            "          [-1.8431, -1.8431, -1.7381,  ..., -1.8431, -1.8081, -1.8431],\n",
            "          ...,\n",
            "          [-1.8431, -1.8081, -1.8431,  ..., -1.8431, -1.8431, -1.8431],\n",
            "          [-1.8431, -1.7731, -1.8431,  ..., -1.8431, -1.7381, -1.8431],\n",
            "          [-1.8431, -1.8431, -1.6506,  ..., -1.7906, -1.8431, -1.8431]],\n",
            "\n",
            "         [[-1.3687, -1.6127, -1.6127,  ..., -1.6127, -1.6127, -1.6127],\n",
            "          [-1.6127, -1.6127, -1.6127,  ..., -1.5081, -1.6127, -1.6127],\n",
            "          [-1.6127, -1.6127, -1.5081,  ..., -1.6127, -1.5779, -1.6127],\n",
            "          ...,\n",
            "          [-1.6127, -1.5779, -1.6127,  ..., -1.6127, -1.6127, -1.6127],\n",
            "          [-1.6127, -1.5430, -1.6127,  ..., -1.6127, -1.5081, -1.6127],\n",
            "          [-1.6127, -1.6127, -1.4210,  ..., -1.5604, -1.6127, -1.6127]]],\n",
            "\n",
            "\n",
            "        [[[-1.4329, -1.8097, -1.8610,  ..., -1.9809, -1.9124, -2.0837],\n",
            "          [-1.6042, -1.8610, -1.5699,  ..., -1.9638, -2.0665, -2.0494],\n",
            "          [-1.8953, -1.7754, -1.6727,  ..., -1.9809, -2.0837, -2.0494],\n",
            "          ...,\n",
            "          [-2.0152, -2.1179, -2.0494,  ..., -1.2617, -1.8268, -2.0323],\n",
            "          [-1.9638, -2.1008, -2.1179,  ..., -0.7137, -1.8953, -2.0323],\n",
            "          [-1.9980, -2.1179, -2.1179,  ...,  0.1768, -1.8439, -1.8268]],\n",
            "\n",
            "         [[-1.3354, -1.7206, -1.7731,  ..., -1.8957, -1.8256, -2.0007],\n",
            "          [-1.5105, -1.7731, -1.4755,  ..., -1.8782, -1.9832, -1.9657],\n",
            "          [-1.8081, -1.6856, -1.5805,  ..., -1.8957, -2.0007, -1.9657],\n",
            "          ...,\n",
            "          [-1.9307, -2.0357, -1.9657,  ..., -1.1604, -1.7381, -1.9482],\n",
            "          [-1.8782, -2.0182, -2.0357,  ..., -0.6001, -1.8081, -1.9482],\n",
            "          [-1.9132, -2.0357, -2.0357,  ...,  0.3102, -1.7556, -1.7381]],\n",
            "\n",
            "         [[-1.1073, -1.4907, -1.5430,  ..., -1.6650, -1.5953, -1.7696],\n",
            "          [-1.2816, -1.5430, -1.2467,  ..., -1.6476, -1.7522, -1.7347],\n",
            "          [-1.5779, -1.4559, -1.3513,  ..., -1.6650, -1.7696, -1.7347],\n",
            "          ...,\n",
            "          [-1.6999, -1.8044, -1.7347,  ..., -0.9330, -1.5081, -1.7173],\n",
            "          [-1.6476, -1.7870, -1.8044,  ..., -0.3753, -1.5779, -1.7173],\n",
            "          [-1.6824, -1.8044, -1.8044,  ...,  0.5311, -1.5256, -1.5081]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.0837, -2.1008, -2.1179,  ..., -2.0494, -2.1008, -2.0665],\n",
            "          [-2.1008, -2.1179, -2.1008,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1008, -2.0837, -2.0323,  ..., -2.1179, -2.1179, -2.0837],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1008, -2.0665, -2.0665],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.0665, -2.1008, -2.0665],\n",
            "          [-2.1179, -2.0152, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0007, -2.0182, -2.0357,  ..., -1.9657, -2.0182, -1.9832],\n",
            "          [-2.0182, -2.0357, -2.0182,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0182, -2.0007, -1.9482,  ..., -2.0357, -2.0357, -2.0007],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0182, -1.9832, -1.9832],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.9832, -2.0182, -1.9832],\n",
            "          [-2.0357, -1.9307, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.7696, -1.7870, -1.8044,  ..., -1.7347, -1.7870, -1.7522],\n",
            "          [-1.7870, -1.8044, -1.7870,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.7870, -1.7696, -1.7173,  ..., -1.8044, -1.8044, -1.7696],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.7870, -1.7522, -1.7522],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.7522, -1.7870, -1.7522],\n",
            "          [-1.8044, -1.6999, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-1.7069, -1.7583, -1.8782,  ..., -1.8439, -1.7925, -1.7925],\n",
            "          [-1.8439, -1.7069, -1.7925,  ..., -1.7069, -1.7583, -1.7925],\n",
            "          [-1.7069, -1.8268, -1.8610,  ..., -1.9295, -1.8268, -1.7754],\n",
            "          ...,\n",
            "          [-1.8097, -1.7925, -1.8268,  ..., -1.6898, -1.8268, -1.7925],\n",
            "          [-1.6384, -1.7240, -1.8268,  ..., -1.8268, -1.8097, -1.8439],\n",
            "          [-1.9809, -1.8439, -1.8268,  ..., -1.7583, -1.8610, -1.6898]],\n",
            "\n",
            "         [[-1.7381, -1.7731, -1.6681,  ..., -1.8606, -1.7731, -1.8606],\n",
            "          [-1.7556, -1.6856, -1.6681,  ..., -1.7381, -1.6681, -1.7031],\n",
            "          [-1.7381, -1.6681, -1.7556,  ..., -1.8256, -1.5455, -1.5630],\n",
            "          ...,\n",
            "          [-1.7906, -1.7031, -1.6856,  ..., -1.7906, -1.7381, -1.7381],\n",
            "          [-1.8081, -1.8081, -1.9307,  ..., -1.7731, -1.6155, -1.5980],\n",
            "          [-1.6506, -1.7556, -1.7031,  ..., -1.7556, -1.8081, -1.8081]],\n",
            "\n",
            "         [[-1.4210, -1.5430, -1.5779,  ..., -1.5779, -1.4559, -1.3687],\n",
            "          [-1.5430, -1.4559, -1.4384,  ..., -1.3164, -1.4733, -1.4907],\n",
            "          [-1.4210, -1.5081, -1.4559,  ..., -1.4907, -1.4733, -1.5779],\n",
            "          ...,\n",
            "          [-1.4559, -1.5604, -1.4384,  ..., -1.4907, -1.5430, -1.4210],\n",
            "          [-1.4384, -1.5430, -1.4559,  ..., -1.4907, -1.4559, -1.5953],\n",
            "          [-1.6476, -1.2990, -1.5256,  ..., -1.3164, -1.4384, -1.3513]]],\n",
            "\n",
            "\n",
            "        [[[-1.9980, -1.9980, -1.9980,  ..., -1.9980, -1.9980, -1.9980],\n",
            "          [-1.9980, -1.9980, -1.9980,  ..., -1.9980, -1.9980, -1.9980],\n",
            "          [-1.9980, -1.9980, -1.9980,  ..., -1.9980, -1.9980, -1.9980],\n",
            "          ...,\n",
            "          [-1.9980, -1.9980, -1.9980,  ..., -1.9980, -1.9980, -1.9980],\n",
            "          [-1.9980, -1.9980, -1.9980,  ..., -1.9980, -1.9980, -1.9980],\n",
            "          [-1.9980, -1.9980, -1.9980,  ..., -1.9980, -1.9980, -1.9980]],\n",
            "\n",
            "         [[-1.9132, -1.9132, -1.9132,  ..., -1.9132, -1.9132, -1.9132],\n",
            "          [-1.9132, -1.9132, -1.9132,  ..., -1.9132, -1.9132, -1.9132],\n",
            "          [-1.9132, -1.9132, -1.9132,  ..., -1.9132, -1.9132, -1.9132],\n",
            "          ...,\n",
            "          [-1.9132, -1.9132, -1.9132,  ..., -1.9132, -1.9132, -1.9132],\n",
            "          [-1.9132, -1.9132, -1.9132,  ..., -1.9132, -1.9132, -1.9132],\n",
            "          [-1.9132, -1.9132, -1.9132,  ..., -1.9132, -1.9132, -1.9132]],\n",
            "\n",
            "         [[-1.6824, -1.6824, -1.6824,  ..., -1.6824, -1.6824, -1.6824],\n",
            "          [-1.6824, -1.6824, -1.6824,  ..., -1.6824, -1.6824, -1.6824],\n",
            "          [-1.6824, -1.6824, -1.6824,  ..., -1.6824, -1.6824, -1.6824],\n",
            "          ...,\n",
            "          [-1.6824, -1.6824, -1.6824,  ..., -1.6824, -1.6824, -1.6824],\n",
            "          [-1.6824, -1.6824, -1.6824,  ..., -1.6824, -1.6824, -1.6824],\n",
            "          [-1.6824, -1.6824, -1.6824,  ..., -1.6824, -1.6824, -1.6824]]]]), tensor([3, 0, 0, 0, 1, 1, 7, 1, 1, 1, 7, 1, 7, 1, 0, 0, 7, 0, 1, 1, 7, 7, 6, 6,\n",
            "        0, 7, 7, 7, 6, 6, 1, 1])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5KTEoNmRyH9",
        "colab_type": "text"
      },
      "source": [
        "**TEST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mn_quBW_KlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_model.load_state_dict(torch.load(os.path.join(\n",
        "        '/content/gdrive/My Drive/Colab Notebooks/odir-ivashnyov/ODIR/logs_final/clahe_vessel_forgetgate_new/clahe_vessel_forgetgate_new_epoch_18.pth')))\n",
        "x_model.eval()\n",
        "\n",
        "test_data = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/odir-ivashnyov/ODIR/data/XYZ_ODIR.csv')\n",
        "test_data_left = test_data.copy()\n",
        "test_data_right = test_data.copy()\n",
        "test_data_left.loc[:, 'id'] = test_data_left.ID.apply(\n",
        "    lambda x: str(x)+'_left.jpg')\n",
        "test_data_right.loc[:, 'id'] = test_data_left.ID.apply(\n",
        "    lambda x: str(x)+'_right.jpg')\n",
        "test_data = pd.concat([test_data_left, test_data_right])\n",
        "test_data.sort_values(['ID'], inplace=True)\n",
        "test_path = '/content/gdrive/My Drive/Colab Notebooks/odir-ivashnyov/ODIR/data/clahe-test/'\n",
        "test_dataset = EyeDataset(dataset_path=test_path,\n",
        "                          labels=test_data.loc[:, labels].values,\n",
        "                          ids=test_data.loc[:, 'id'].values,\n",
        "                          albumentations_tr=aug_val(image_size))\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                         num_workers=num_wkr,\n",
        "                         pin_memory=True,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=False)\n",
        "\n",
        "\n",
        "test_path1 = '/content/gdrive/My Drive/Colab Notebooks/odir-ivashnyov/ODIR/data/vessel-test-full/'\n",
        "test_dataset_vessel = EyeDataset(dataset_path=test_path1,\n",
        "                                 labels=test_data.loc[:, labels].values,\n",
        "                                 ids=test_data.loc[:, 'id'].values,\n",
        "                                 albumentations_tr=aug_val(image_size))\n",
        "test_loader_vessel = DataLoader(test_dataset_vessel,\n",
        "                                num_workers=num_wkr,\n",
        "                                pin_memory=True,\n",
        "                                batch_size=batch_size,\n",
        "                                shuffle=False)\n",
        "\n",
        "probabilities = []\n",
        "probabilities_list = []\n",
        "exp_name = 'initial_test_b3'\n",
        "#optimizer = torch.optim.Adam(x_model.parameters(), lr=1e-5)\n",
        "\n",
        "for i1, i2 in zip(enumerate(test_loader), enumerate(test_loader_vessel)):\n",
        "    # print(i1)\n",
        "    stt1, data1 = i1\n",
        "    input1, target1 = data1\n",
        "    # print(i2)\n",
        "    stt2, data2 = i2\n",
        "    input2, target2 = data2\n",
        "    # zero the parameter gradients\n",
        "    #optimizer.zero_grad()\n",
        "    input1, target1 = input1.to(device), target1.to(device)\n",
        "    input2, target2 = input2.to(device), target2.to(device)\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    outputs = x_model(input1, input2)\n",
        "    outputs = torch.Tensor.cpu(outputs).detach().numpy()\n",
        "    probabilities = softmax(torch.from_numpy(outputs), dim=0).numpy()\n",
        "    # print(probabilities)\n",
        "    for idx in range(probabilities.shape[0]):\n",
        "        if all(probabilities[idx] < 0.5):\n",
        "            probabilities[idx][0] = 1.0\n",
        "    probabilities_list.append(probabilities)\n",
        "arr_list = []\n",
        "arr = np.array(probabilities_list)\n",
        "arr_list.append(arr)\n",
        "print(arr_list)\n",
        "\n",
        "\n",
        "probabilities_combined = np.stack(arr_list, axis=0).mean(axis=0)\n",
        "predicted_labels = pd.DataFrame(probabilities_combined, columns=labels)\n",
        "predicted_labels['id'] = test_data.loc[:, 'id'].values\n",
        "predicted_labels.loc[:, 'ID'] = predicted_labels.id.apply(\n",
        "    lambda x: x.split('_')[0])\n",
        "predicted_labels_groupped = predicted_labels.groupby(\n",
        "    ['ID']).aggregate(dict(zip(labels, ['max']*(len(labels)))))\n",
        "print(type(predicted_labels_groupped))\n",
        "predicted_labels_groupped['ID'] = predicted_labels_groupped.index.values.astype(\n",
        "    int)\n",
        "predicted_labels_groupped.reset_index(drop=True, inplace=True)\n",
        "predicted_labels_groupped.sort_values('ID', inplace=True)\n",
        "predicted_labels_groupped = predicted_labels_groupped.loc[:, ['ID']+labels]\n",
        "predicted_labels_groupped.to_csv(\n",
        "    '/content/gdrive/My Drive/Colab Notebooks/odir-ivashnyov/ODIR/submit_final/clahe_vessel_forgetgate_new_epoch_19.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfJ7Jf-YcI6i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3a0aaaa7-8e50-457f-d8b4-4995bc782dd2"
      },
      "source": [
        "print(len(arr_list[0][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICLWdJ8jdVo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr_list = []\n",
        "arr = np.array(probabilities_list)\n",
        "arr_list.append(arr)\n",
        "print(arr_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRZ-cKvRfZYJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "72a99978-a331-40b3-a82a-a332b6327af9"
      },
      "source": [
        "print(probabilities_list[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.2144068e-04 4.7661279e-06 4.9535003e-03 9.9860054e-01 9.5265469e-04\n",
            "  8.2829781e-03 3.3253014e-02 4.9108714e-02]\n",
            " [1.0000000e+00 1.3654106e-02 1.6948028e-02 1.9251675e-05 2.4395110e-04\n",
            "  8.7407477e-02 1.9258418e-03 1.4824200e-04]\n",
            " [1.0000000e+00 2.3947457e-04 1.9015754e-03 2.9168342e-04 1.0105540e-02\n",
            "  3.0838929e-03 9.4037894e-03 1.3055870e-02]\n",
            " [1.0000000e+00 3.0995693e-02 3.5283307e-03 5.4242759e-05 1.7945549e-03\n",
            "  3.7506870e-03 6.2131430e-03 2.7398083e-03]\n",
            " [2.9051199e-04 2.8347517e-06 1.9345835e-02 2.3374027e-04 7.6764899e-01\n",
            "  1.5555695e-03 2.5892500e-02 2.1067078e-01]\n",
            " [1.0000000e+00 1.9937640e-03 2.3203806e-03 1.7631479e-06 1.0871205e-01\n",
            "  9.0088072e-04 1.4619349e-03 2.7955666e-03]\n",
            " [1.0000000e+00 1.0435772e-03 1.9407854e-03 4.4337203e-06 7.6591113e-04\n",
            "  2.8260378e-03 9.9492224e-04 2.6505769e-03]\n",
            " [1.0000000e+00 4.7300367e-05 4.6464153e-02 9.5620062e-06 8.1378054e-03\n",
            "  8.2513308e-03 1.5272426e-03 9.0417603e-04]\n",
            " [1.0000000e+00 3.6882999e-04 2.8758939e-02 3.6517076e-06 1.9461798e-04\n",
            "  6.3149235e-03 9.1493485e-04 1.6703944e-03]\n",
            " [1.0000000e+00 1.4480118e-05 3.0421233e-03 1.2920009e-05 6.3846016e-04\n",
            "  3.7961319e-01 2.8134830e-02 6.6618565e-03]\n",
            " [1.0000000e+00 2.9579649e-06 1.7174736e-02 9.5273253e-06 2.6952252e-02\n",
            "  2.6867846e-03 2.4840198e-01 1.2228714e-01]\n",
            " [1.0000000e+00 1.0595144e-03 1.4854281e-03 6.0832463e-06 3.4440964e-04\n",
            "  1.2358192e-01 5.1833848e-03 2.9892640e-02]\n",
            " [1.0000000e+00 1.8524937e-02 1.7344988e-03 5.3906322e-05 5.2037914e-03\n",
            "  9.5854821e-03 2.7850388e-02 2.4051362e-04]\n",
            " [1.0000000e+00 2.0540837e-02 3.2688596e-04 1.5482725e-06 9.5840474e-04\n",
            "  3.2855177e-03 4.5451752e-04 1.4604259e-03]\n",
            " [1.0000000e+00 1.6164449e-05 1.2615502e-02 6.1887775e-05 6.4442999e-04\n",
            "  4.3765083e-03 2.6325446e-03 1.4785409e-02]\n",
            " [1.0000000e+00 1.8679875e-01 3.6994223e-03 1.4185984e-05 8.7793429e-05\n",
            "  1.4345318e-02 2.9830707e-04 2.2307891e-05]\n",
            " [1.0000000e+00 5.8056493e-03 5.5016612e-04 1.2895585e-05 7.5818701e-03\n",
            "  1.4852502e-02 2.2041386e-03 5.1335292e-03]\n",
            " [1.0000000e+00 9.6515339e-04 1.4376645e-02 9.5902025e-05 5.5704004e-04\n",
            "  1.3399795e-01 3.3872728e-03 1.0035010e-03]\n",
            " [1.0000000e+00 1.0396797e-01 5.3488980e-03 5.7660338e-05 4.4859104e-02\n",
            "  1.0531911e-02 7.1352138e-03 4.3885539e-05]\n",
            " [1.0000000e+00 3.5385671e-04 9.7831478e-03 4.8289992e-05 1.7376909e-03\n",
            "  9.7789086e-02 2.5151109e-02 8.5240584e-03]\n",
            " [1.0000000e+00 2.8454844e-04 6.6029876e-02 8.3369530e-05 5.6668423e-04\n",
            "  1.9478956e-02 8.6327567e-04 9.1069116e-05]\n",
            " [1.0000000e+00 1.4865508e-03 3.3237950e-03 3.6620953e-05 2.6137065e-04\n",
            "  3.5037703e-03 5.1839584e-03 6.2320889e-03]\n",
            " [1.0000000e+00 4.2069904e-03 1.5303515e-02 1.9507310e-05 2.2866417e-04\n",
            "  1.6293284e-02 8.0892630e-04 1.1355356e-04]\n",
            " [2.1895049e-04 1.5978290e-05 1.8119800e-03 7.1114293e-05 2.7777543e-03\n",
            "  7.8673391e-03 5.1740062e-01 5.1911745e-02]\n",
            " [1.0000000e+00 2.7509494e-04 2.7724283e-03 2.0535128e-05 2.7876610e-03\n",
            "  1.9322890e-03 5.2329139e-03 1.0366108e-02]\n",
            " [1.0000000e+00 7.9221644e-02 3.4512626e-03 2.7280592e-05 1.8131881e-03\n",
            "  1.9756015e-03 1.8083882e-03 1.3858256e-04]\n",
            " [5.5779681e-05 1.3336383e-03 6.7318732e-01 2.0937990e-05 3.5463413e-04\n",
            "  7.1502062e-03 2.0697048e-02 7.8894285e-05]\n",
            " [1.0000000e+00 1.2149994e-02 7.3520634e-03 1.9927666e-06 2.3979618e-04\n",
            "  1.2062407e-02 4.0770308e-03 1.0076030e-04]\n",
            " [1.0000000e+00 1.5936130e-04 3.3476828e-03 2.1117106e-05 1.3208552e-03\n",
            "  2.6319157e-03 1.3016390e-03 1.2597838e-01]\n",
            " [1.0000000e+00 4.8563204e-05 2.4500347e-03 7.5148913e-05 1.3801976e-03\n",
            "  6.2457672e-03 8.5009085e-03 3.3106238e-01]\n",
            " [1.0000000e+00 2.2216457e-01 2.2167632e-02 8.4096318e-06 6.7553687e-05\n",
            "  2.2911599e-03 1.5444203e-03 5.3280113e-05]\n",
            " [1.0000000e+00 2.9225242e-01 2.5034302e-03 2.0303747e-05 8.0298225e-05\n",
            "  1.5473592e-03 1.5982539e-04 7.3753814e-05]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWlZlh24b3OZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9363a9dd-eea9-4376-ce2c-ec3800f1e52e"
      },
      "source": [
        "arr_list1 = []\n",
        "for i in probabilities_list:\n",
        "  for j in i:\n",
        "    print(j)\n",
        "    #print(len(j))\n",
        "    #x = np.array(j)\n",
        "    arr_list1.append(x)\n",
        "#print(arr_list1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0000000e+00 1.6316134e-04 5.2866463e-02 4.8119966e-03 5.8490634e-05\n",
            " 8.8020734e-02 1.1512419e-03 2.4260061e-03]\n",
            "[1.0000000e+00 7.7522993e-03 3.0436271e-03 7.2792908e-03 2.1664324e-04\n",
            " 3.7784681e-01 6.8974728e-03 7.4463210e-04]\n",
            "[1.0000000e+00 8.0106091e-03 8.5256775e-05 1.9860677e-03 5.4553780e-03\n",
            " 1.7367763e-03 4.7698678e-03 1.0894294e-02]\n",
            "[1.0000000e+00 1.7049800e-01 1.5615511e-03 1.2017510e-02 3.5965994e-03\n",
            " 4.9334257e-03 3.1994242e-02 5.7079447e-05]\n",
            "[1.0000000e+00 6.7672564e-04 1.0034190e-03 2.2619946e-02 6.7500259e-05\n",
            " 1.3488573e-04 2.1234720e-03 2.4030743e-02]\n",
            "[1.0000000e+00 8.5264684e-05 1.2379026e-03 5.7227097e-02 1.4787121e-03\n",
            " 1.2727933e-03 8.6145833e-02 3.7907790e-02]\n",
            "[1.00000000e+00 5.87351969e-04 3.00790387e-04 6.64554723e-03\n",
            " 1.77870702e-03 9.49199457e-05 8.40691268e-04 1.15386015e-02]\n",
            "[1.0000000e+00 5.7576858e-03 2.7080756e-04 3.6181763e-03 3.3660306e-04\n",
            " 5.2929803e-04 1.0146903e-03 3.5586834e-04]\n",
            "[1.0000000e+00 3.5348665e-02 4.0055756e-03 1.4681787e-02 3.3683394e-04\n",
            " 1.8258030e-03 1.8437341e-02 2.6051429e-04]\n",
            "[1.0000000e+00 4.2600925e-03 4.0244139e-03 3.2196534e-03 2.2548548e-04\n",
            " 2.7624649e-04 1.1331716e-02 2.2865608e-03]\n",
            "[1.0000000e+00 3.8383089e-03 1.8211735e-04 4.9794618e-02 9.0343245e-05\n",
            " 9.8046765e-04 2.2790864e-02 1.0377819e-01]\n",
            "[1.0000000e+00 2.4558092e-04 3.4966614e-04 3.2315186e-01 3.3591039e-04\n",
            " 2.8961428e-04 9.5772564e-02 1.3880667e-01]\n",
            "[1.0000000e+00 6.2405283e-04 1.6608761e-03 2.5268169e-03 2.7961540e-04\n",
            " 2.3120286e-02 1.8431108e-03 1.0516680e-03]\n",
            "[1.00000000e+00 3.73537908e-03 9.00758198e-04 1.54229915e-02\n",
            " 1.24062382e-04 7.54227338e-04 3.57301114e-03 1.36590831e-03]\n",
            "[1.0000000e+00 9.9333106e-03 3.9426622e-04 1.6187444e-01 4.5013585e-04\n",
            " 1.9617584e-01 1.9558053e-01 1.3768726e-03]\n",
            "[1.0000000e+00 3.4434809e-03 5.8622874e-04 2.9082876e-02 5.9332489e-04\n",
            " 2.5483745e-01 1.3723379e-01 2.1678586e-03]\n",
            "[1.0000000e+00 8.0918064e-03 4.5368820e-03 2.3660066e-03 2.9635874e-05\n",
            " 4.3924560e-04 3.3362301e-03 1.0702310e-02]\n",
            "[1.0000000e+00 1.1857269e-01 1.1109972e-03 1.2205938e-02 8.0354635e-05\n",
            " 2.6067947e-03 2.1551908e-03 4.8147951e-04]\n",
            "[1.0000000e+00 1.7994203e-01 7.2286697e-03 3.9874595e-03 6.0745740e-05\n",
            " 1.5027522e-03 9.9029923e-03 1.2322582e-04]\n",
            "[1.0000000e+00 1.1824194e-03 1.9134058e-03 8.5596461e-03 1.1161904e-04\n",
            " 3.2496009e-02 8.2972860e-03 3.2952612e-03]\n",
            "[1.0000000e+00 1.8938811e-01 2.8552421e-04 5.0863530e-03 8.9739493e-05\n",
            " 4.2837276e-03 4.0434580e-03 6.3125836e-04]\n",
            "[1.0000000e+00 7.2574783e-03 3.3542109e-04 5.1757524e-04 6.9487702e-05\n",
            " 2.2138574e-04 1.3439854e-02 6.4735785e-03]\n",
            "[1.0000000e+00 7.6351546e-02 4.0297330e-04 2.5424587e-03 1.4638684e-04\n",
            " 1.9277013e-03 1.0384944e-03 4.2845734e-04]\n",
            "[1.0000000e+00 1.6236793e-01 3.4518691e-04 3.4189527e-03 3.6528509e-05\n",
            " 1.1402697e-03 6.2799657e-04 4.8368721e-04]\n",
            "[1.0000000e+00 7.0151196e-05 1.9903835e-03 1.2344595e-02 7.0657342e-04\n",
            " 5.0620154e-05 3.7076168e-03 1.7971127e-01]\n",
            "[1.0000000e+00 1.7076190e-05 2.3633977e-03 1.2415576e-01 1.8354440e-04\n",
            " 5.8865262e-04 1.1270666e-01 2.2670105e-01]\n",
            "[1.0000000e+00 3.3935928e-04 1.2189849e-04 3.4131277e-03 9.7238347e-03\n",
            " 1.8219085e-04 7.6914220e-03 7.8469358e-02]\n",
            "[1.0000000e+00 5.6503079e-04 1.0549572e-03 1.4860667e-03 3.4360826e-04\n",
            " 7.6152428e-05 2.8101618e-03 3.9004363e-02]\n",
            "[1.0000000e+00 4.1452924e-05 3.6210020e-04 4.7481311e-03 1.4622462e-01\n",
            " 6.9425645e-05 3.0710734e-03 5.2506130e-02]\n",
            "[1.4948045e-03 2.7288288e-06 1.6968851e-03 7.2695926e-02 8.2610196e-01\n",
            " 1.7830082e-04 1.6201697e-01 4.4252731e-02]\n",
            "[3.4496128e-03 2.7208132e-05 9.0136927e-01 1.8778041e-02 4.0962594e-04\n",
            " 7.6231523e-04 1.3510096e-02 8.5060829e-03]\n",
            "[1.0000000e+00 8.2301785e-04 2.4083194e-03 7.7332947e-03 2.5738162e-04\n",
            " 6.4486364e-04 3.0144051e-02 9.1804955e-03]\n",
            "[2.2144068e-04 4.7661279e-06 4.9535003e-03 9.9860054e-01 9.5265469e-04\n",
            " 8.2829781e-03 3.3253014e-02 4.9108714e-02]\n",
            "[1.0000000e+00 1.3654106e-02 1.6948028e-02 1.9251675e-05 2.4395110e-04\n",
            " 8.7407477e-02 1.9258418e-03 1.4824200e-04]\n",
            "[1.0000000e+00 2.3947457e-04 1.9015754e-03 2.9168342e-04 1.0105540e-02\n",
            " 3.0838929e-03 9.4037894e-03 1.3055870e-02]\n",
            "[1.0000000e+00 3.0995693e-02 3.5283307e-03 5.4242759e-05 1.7945549e-03\n",
            " 3.7506870e-03 6.2131430e-03 2.7398083e-03]\n",
            "[2.9051199e-04 2.8347517e-06 1.9345835e-02 2.3374027e-04 7.6764899e-01\n",
            " 1.5555695e-03 2.5892500e-02 2.1067078e-01]\n",
            "[1.0000000e+00 1.9937640e-03 2.3203806e-03 1.7631479e-06 1.0871205e-01\n",
            " 9.0088072e-04 1.4619349e-03 2.7955666e-03]\n",
            "[1.0000000e+00 1.0435772e-03 1.9407854e-03 4.4337203e-06 7.6591113e-04\n",
            " 2.8260378e-03 9.9492224e-04 2.6505769e-03]\n",
            "[1.0000000e+00 4.7300367e-05 4.6464153e-02 9.5620062e-06 8.1378054e-03\n",
            " 8.2513308e-03 1.5272426e-03 9.0417603e-04]\n",
            "[1.0000000e+00 3.6882999e-04 2.8758939e-02 3.6517076e-06 1.9461798e-04\n",
            " 6.3149235e-03 9.1493485e-04 1.6703944e-03]\n",
            "[1.0000000e+00 1.4480118e-05 3.0421233e-03 1.2920009e-05 6.3846016e-04\n",
            " 3.7961319e-01 2.8134830e-02 6.6618565e-03]\n",
            "[1.0000000e+00 2.9579649e-06 1.7174736e-02 9.5273253e-06 2.6952252e-02\n",
            " 2.6867846e-03 2.4840198e-01 1.2228714e-01]\n",
            "[1.0000000e+00 1.0595144e-03 1.4854281e-03 6.0832463e-06 3.4440964e-04\n",
            " 1.2358192e-01 5.1833848e-03 2.9892640e-02]\n",
            "[1.0000000e+00 1.8524937e-02 1.7344988e-03 5.3906322e-05 5.2037914e-03\n",
            " 9.5854821e-03 2.7850388e-02 2.4051362e-04]\n",
            "[1.0000000e+00 2.0540837e-02 3.2688596e-04 1.5482725e-06 9.5840474e-04\n",
            " 3.2855177e-03 4.5451752e-04 1.4604259e-03]\n",
            "[1.0000000e+00 1.6164449e-05 1.2615502e-02 6.1887775e-05 6.4442999e-04\n",
            " 4.3765083e-03 2.6325446e-03 1.4785409e-02]\n",
            "[1.0000000e+00 1.8679875e-01 3.6994223e-03 1.4185984e-05 8.7793429e-05\n",
            " 1.4345318e-02 2.9830707e-04 2.2307891e-05]\n",
            "[1.0000000e+00 5.8056493e-03 5.5016612e-04 1.2895585e-05 7.5818701e-03\n",
            " 1.4852502e-02 2.2041386e-03 5.1335292e-03]\n",
            "[1.0000000e+00 9.6515339e-04 1.4376645e-02 9.5902025e-05 5.5704004e-04\n",
            " 1.3399795e-01 3.3872728e-03 1.0035010e-03]\n",
            "[1.0000000e+00 1.0396797e-01 5.3488980e-03 5.7660338e-05 4.4859104e-02\n",
            " 1.0531911e-02 7.1352138e-03 4.3885539e-05]\n",
            "[1.0000000e+00 3.5385671e-04 9.7831478e-03 4.8289992e-05 1.7376909e-03\n",
            " 9.7789086e-02 2.5151109e-02 8.5240584e-03]\n",
            "[1.0000000e+00 2.8454844e-04 6.6029876e-02 8.3369530e-05 5.6668423e-04\n",
            " 1.9478956e-02 8.6327567e-04 9.1069116e-05]\n",
            "[1.0000000e+00 1.4865508e-03 3.3237950e-03 3.6620953e-05 2.6137065e-04\n",
            " 3.5037703e-03 5.1839584e-03 6.2320889e-03]\n",
            "[1.0000000e+00 4.2069904e-03 1.5303515e-02 1.9507310e-05 2.2866417e-04\n",
            " 1.6293284e-02 8.0892630e-04 1.1355356e-04]\n",
            "[2.1895049e-04 1.5978290e-05 1.8119800e-03 7.1114293e-05 2.7777543e-03\n",
            " 7.8673391e-03 5.1740062e-01 5.1911745e-02]\n",
            "[1.0000000e+00 2.7509494e-04 2.7724283e-03 2.0535128e-05 2.7876610e-03\n",
            " 1.9322890e-03 5.2329139e-03 1.0366108e-02]\n",
            "[1.0000000e+00 7.9221644e-02 3.4512626e-03 2.7280592e-05 1.8131881e-03\n",
            " 1.9756015e-03 1.8083882e-03 1.3858256e-04]\n",
            "[5.5779681e-05 1.3336383e-03 6.7318732e-01 2.0937990e-05 3.5463413e-04\n",
            " 7.1502062e-03 2.0697048e-02 7.8894285e-05]\n",
            "[1.0000000e+00 1.2149994e-02 7.3520634e-03 1.9927666e-06 2.3979618e-04\n",
            " 1.2062407e-02 4.0770308e-03 1.0076030e-04]\n",
            "[1.0000000e+00 1.5936130e-04 3.3476828e-03 2.1117106e-05 1.3208552e-03\n",
            " 2.6319157e-03 1.3016390e-03 1.2597838e-01]\n",
            "[1.0000000e+00 4.8563204e-05 2.4500347e-03 7.5148913e-05 1.3801976e-03\n",
            " 6.2457672e-03 8.5009085e-03 3.3106238e-01]\n",
            "[1.0000000e+00 2.2216457e-01 2.2167632e-02 8.4096318e-06 6.7553687e-05\n",
            " 2.2911599e-03 1.5444203e-03 5.3280113e-05]\n",
            "[1.0000000e+00 2.9225242e-01 2.5034302e-03 2.0303747e-05 8.0298225e-05\n",
            " 1.5473592e-03 1.5982539e-04 7.3753814e-05]\n",
            "[1.0000000e+00 9.3320839e-02 5.2889995e-04 3.7172243e-02 4.0090581e-06\n",
            " 9.9013466e-03 4.8807802e-04 1.0945114e-03]\n",
            "[1.0000000e+00 1.2114385e-04 2.0586374e-01 1.5135439e-01 1.6523107e-05\n",
            " 5.1666446e-02 4.9992488e-03 1.2013516e-03]\n",
            "[1.0000000e+00 2.3222283e-06 3.6257526e-03 1.3814852e-01 1.1984936e-04\n",
            " 1.1751845e-03 6.3605765e-03 6.9654942e-03]\n",
            "[1.00000000e+00 1.10499450e-05 1.90282997e-03 3.55425142e-02\n",
            " 2.80275217e-05 1.23200985e-02 2.49064970e-03 1.64189786e-02]\n",
            "[1.0000000e+00 4.4723466e-02 3.5668010e-04 3.9843880e-02 1.3304587e-05\n",
            " 2.4696622e-02 1.2736459e-03 2.7794403e-03]\n",
            "[1.0000000e+00 5.1100601e-02 1.3027141e-04 2.1209817e-02 4.2140309e-05\n",
            " 7.4968971e-03 1.4910182e-03 5.5752965e-03]\n",
            "[1.0000000e+00 2.0462649e-03 5.2066590e-04 4.0307164e-02 1.7142016e-05\n",
            " 2.9295945e-01 1.8518619e-01 1.3309385e-02]\n",
            "[1.0000000e+00 4.5051415e-02 4.1252319e-03 1.6021620e-01 1.8272152e-05\n",
            " 7.6204777e-02 1.8553894e-02 6.2409043e-04]\n",
            "[1.0000000e+00 3.4270991e-02 2.4092283e-04 3.8834079e-03 6.7210649e-06\n",
            " 1.3397039e-01 1.2541654e-03 1.7355407e-03]\n",
            "[3.7752252e-05 7.1345425e-01 1.7990093e-04 1.1922999e-03 2.0498295e-05\n",
            " 6.1311782e-03 3.6425723e-04 1.6289597e-04]\n",
            "[1.0000000e+00 1.1012174e-04 4.8956694e-04 6.5370597e-04 4.3874814e-05\n",
            " 5.6095212e-04 8.7309832e-05 8.3617792e-03]\n",
            "[1.0000000e+00 6.2332849e-04 3.1998039e-03 2.8163942e-03 5.1632001e-06\n",
            " 5.6564701e-03 2.3264321e-03 3.8182497e-04]\n",
            "[1.0000000e+00 1.4851286e-05 2.3979181e-02 1.4302633e-02 2.3674117e-04\n",
            " 4.8883767e-03 3.9510310e-04 7.8359032e-03]\n",
            "[1.0000000e+00 4.8083081e-03 2.5556961e-04 6.6203736e-03 7.7796885e-06\n",
            " 1.9612643e-03 3.6847015e-04 9.3902871e-03]\n",
            "[1.0000000e+00 1.2599767e-06 1.0651475e-01 4.8209529e-02 2.3206901e-03\n",
            " 8.6985063e-03 2.9873984e-02 1.2266764e-01]\n",
            "[3.5220210e-06 9.0538460e-06 2.4851167e-01 1.3969095e-01 9.8187667e-01\n",
            " 1.6528670e-01 1.3998550e-01 8.2577602e-04]\n",
            "[1.0000000e+00 1.0274547e-05 1.0766796e-03 1.4529100e-03 2.9339290e-06\n",
            " 5.2544120e-04 5.4689078e-03 2.1477021e-01]\n",
            "[1.0000000e+00 1.3214332e-03 1.2503747e-03 9.2086795e-04 8.8066690e-06\n",
            " 1.0309197e-03 3.1018446e-04 2.6788414e-03]\n",
            "[1.0000000e+00 1.9725156e-03 1.6633952e-03 1.3462772e-03 1.1212816e-04\n",
            " 5.5485717e-03 8.6384534e-05 8.2993358e-03]\n",
            "[1.0000000e+00 4.8543415e-03 3.1048513e-04 6.8309600e-04 3.1875254e-05\n",
            " 6.8388972e-04 7.7527257e-05 1.9362342e-03]\n",
            "[1.0000000e+00 1.3112753e-05 3.7331195e-04 6.5163979e-03 1.7596633e-04\n",
            " 8.9836773e-03 3.2473642e-02 2.8562495e-01]\n",
            "[1.7177520e-04 9.7666853e-06 2.2136889e-04 3.8169570e-02 9.8455593e-04\n",
            " 2.6297052e-03 5.4861307e-01 3.5946168e-02]\n",
            "[5.1958245e-01 7.8895617e-05 4.8541045e-03 8.0069521e-04 2.0103011e-05\n",
            " 8.2061446e-04 2.5729497e-04 8.2107150e-04]\n",
            "[1.0000000e+00 1.3416949e-06 2.4372204e-01 3.0995335e-02 2.5087866e-05\n",
            " 2.4558168e-03 3.0857101e-03 4.6338653e-03]\n",
            "[1.0000000e+00 4.0729257e-04 2.9694344e-04 5.4775982e-04 1.8378436e-04\n",
            " 1.3752572e-02 2.7001477e-03 5.7415638e-02]\n",
            "[1.0000000e+00 8.1793823e-06 7.2765513e-04 1.0165693e-03 2.0600113e-04\n",
            " 1.4391777e-02 6.1437706e-03 1.1174359e-01]\n",
            "[1.00000000e+00 2.16440400e-04 7.00488861e-04 1.19984020e-02\n",
            " 1.18799144e-04 1.10912137e-02 6.90564746e-04 2.54331846e-02]\n",
            "[1.00000000e+00 1.75348177e-04 5.30156889e-04 5.59164863e-03\n",
            " 1.05097446e-04 2.75296420e-02 7.70871120e-05 1.31847281e-02]\n",
            "[1.0000000e+00 1.3113760e-04 1.3485402e-01 5.3389609e-02 2.6761090e-05\n",
            " 2.3849346e-02 2.5083199e-03 6.5469136e-04]\n",
            "[1.0000000e+00 2.3655067e-04 3.5809746e-03 7.2054495e-04 1.9344810e-05\n",
            " 5.6596458e-02 1.7433056e-04 3.6146136e-03]\n",
            "[1.0000000e+00 6.1427680e-04 3.4712034e-04 9.0906210e-04 1.3178403e-02\n",
            " 5.8895838e-03 5.5836979e-04 2.4115367e-02]\n",
            "[1.0000000e+00 2.7984104e-04 5.0654463e-03 3.7772474e-03 2.2916600e-05\n",
            " 2.0646101e-02 1.2761481e-03 9.7972965e-03]\n",
            "[3.70086665e-04 1.03131053e-03 7.60137677e-01 2.40031181e-06\n",
            " 1.21363686e-04 6.51582051e-03 2.05890814e-04 1.11023511e-03]\n",
            "[1.0000000e+00 1.2625112e-02 4.9330392e-05 1.6780705e-06 9.5376495e-04\n",
            " 9.0029780e-03 3.1872769e-05 1.1075005e-02]\n",
            "[1.0000000e+00 1.0419543e-03 1.0686388e-02 7.0546973e-03 2.8846960e-04\n",
            " 7.8963563e-03 1.8408542e-04 2.2675940e-03]\n",
            "[1.0000000e+00 9.5137529e-04 6.5665212e-03 3.8693102e-05 4.2625441e-04\n",
            " 1.6974676e-03 1.4242291e-05 8.3295949e-02]\n",
            "[2.9693967e-05 1.8226155e-03 1.8477123e-05 9.7290695e-01 7.9593965e-04\n",
            " 3.9148148e-02 2.0969221e-03 3.9315522e-02]\n",
            "[1.0000000e+00 4.3238039e-04 3.0655995e-02 7.7813835e-05 3.6297610e-05\n",
            " 2.5341532e-04 2.6764417e-05 2.0401331e-03]\n",
            "[1.0000000e+00 2.2187408e-03 1.2453774e-04 1.4524201e-05 9.9530751e-03\n",
            " 2.7337279e-02 3.2044851e-04 4.6085995e-03]\n",
            "[1.0000000e+00 1.8398454e-04 2.9326635e-03 1.8537059e-05 9.1400910e-03\n",
            " 8.7009650e-03 4.8882980e-04 1.3024712e-02]\n",
            "[1.0000000e+00 1.3461386e-02 1.1712319e-06 3.8892915e-05 1.8040832e-03\n",
            " 2.0366631e-02 7.2179869e-02 4.4133242e-02]\n",
            "[1.0000000e+00 2.4084719e-03 5.4153451e-03 5.0403628e-06 1.3294561e-04\n",
            " 1.1021143e-02 1.0641638e-04 5.3601056e-02]\n",
            "[1.0000000e+00 2.8186450e-03 7.9473357e-06 3.9413906e-05 2.9431097e-03\n",
            " 1.1205286e-02 4.4401029e-05 8.0643632e-03]\n",
            "[1.0000000e+00 1.4804037e-02 8.7795212e-05 2.1451440e-05 7.3425181e-04\n",
            " 3.9726488e-02 7.1119022e-05 8.1160985e-04]\n",
            "[1.1142250e-03 1.0261153e-03 1.0560811e-05 8.5267777e-05 4.5388308e-04\n",
            " 5.2758823e-03 8.8444179e-01 3.6035519e-02]\n",
            "[1.0000000e+00 3.7936740e-02 4.8160047e-05 1.4145987e-05 6.5712629e-05\n",
            " 1.2073563e-02 7.1990466e-06 6.0416973e-04]\n",
            "[1.00000000e+00 1.15681095e-02 7.30144529e-06 1.25261082e-03\n",
            " 1.86627454e-04 1.81364696e-02 1.21394463e-03 5.88482479e-03]\n",
            "[1.0000000e+00 5.3075410e-02 2.2436627e-05 3.8276776e-06 9.0892485e-04\n",
            " 2.0213982e-01 4.4914261e-05 1.4849136e-03]\n",
            "[1.0000000e+00 3.6431044e-01 1.5575939e-07 4.6703735e-05 9.4869843e-04\n",
            " 4.2235610e-01 1.6167916e-05 7.9570208e-03]\n",
            "[1.0000000e+00 7.1395473e-03 3.4472780e-06 7.4364361e-05 4.9383083e-04\n",
            " 1.9472257e-03 1.3175693e-04 2.5728250e-02]\n",
            "[1.0000000e+00 8.3008764e-04 9.7179698e-05 1.4001116e-02 4.4792914e-04\n",
            " 1.4600990e-02 5.4231921e-04 2.6473177e-03]\n",
            "[1.0000000e+00 1.7572460e-03 1.0787673e-04 4.5305722e-05 1.0973507e-03\n",
            " 1.4221699e-02 2.7653002e-04 7.5840992e-03]\n",
            "[1.0000000e+00 2.3685556e-03 4.6045379e-06 4.4599387e-06 3.3716045e-03\n",
            " 4.4462141e-03 2.6304118e-04 2.7209029e-01]\n",
            "[1.0000000e+00 5.4723802e-03 5.8708771e-08 4.9711621e-06 1.7142672e-02\n",
            " 4.7158087e-03 1.9522131e-03 1.6494094e-01]\n",
            "[1.00000000e+00 1.65113471e-02 1.51302083e-04 4.40149734e-06\n",
            " 1.17657546e-04 2.73970328e-03 4.83135664e-05 1.94437969e-02]\n",
            "[1.0000000e+00 4.0082479e-05 1.8138902e-01 4.1219868e-05 2.3624734e-05\n",
            " 3.3215299e-04 3.4078530e-05 5.9501629e-04]\n",
            "[1.0000000e+00 2.2505161e-04 9.2241459e-04 9.2225600e-06 4.2319208e-02\n",
            " 7.3575601e-03 3.0743773e-04 1.8145518e-02]\n",
            "[7.7378543e-05 7.0952387e-03 3.1689760e-05 3.6808644e-05 8.9717507e-01\n",
            " 1.8103542e-02 7.9508143e-04 5.5244300e-03]\n",
            "[1.0000000e+00 1.7835769e-03 2.2839180e-04 1.7228829e-05 1.7285891e-03\n",
            " 4.4312458e-03 2.9562685e-05 4.4658847e-02]\n",
            "[1.0000000e+00 3.4048391e-04 1.7328715e-04 3.6716613e-03 2.2925989e-04\n",
            " 1.4762770e-03 2.7462896e-05 6.6304179e-03]\n",
            "[1.0000000e+00 8.4786667e-03 1.2481708e-05 1.7703719e-04 5.5984472e-04\n",
            " 5.3263162e-03 2.3150427e-04 5.9630781e-02]\n",
            "[1.0000000e+00 9.3437694e-02 4.1845720e-07 1.6680624e-05 5.0692077e-05\n",
            " 1.1786071e-03 1.7804919e-05 4.1577339e-02]\n",
            "[1.0000000e+00 3.3122319e-01 3.7718337e-06 1.0726845e-06 5.5224184e-05\n",
            " 2.4282774e-03 1.1456074e-06 2.7429999e-03]\n",
            "[1.0000000e+00 1.5800004e-03 1.0156305e-04 2.7183018e-04 5.2939435e-03\n",
            " 7.3840581e-02 3.3846870e-02 1.2745507e-02]\n",
            "[1.0000000e+00 1.1067892e-04 8.9857034e-02 4.4858734e-06 6.5052829e-04\n",
            " 7.2055025e-04 3.9275412e-07 5.2856591e-05]\n",
            "[1.00000000e+00 2.37503016e-04 1.06323939e-02 9.23024515e-07\n",
            " 1.39519786e-02 1.53942555e-02 5.09434267e-06 1.60080241e-03]\n",
            "[1.0000000e+00 3.0104320e-03 9.0220034e-05 7.4128529e-08 1.4548586e-02\n",
            " 2.4550385e-03 1.2749358e-06 2.9866196e-02]\n",
            "[1.0000000e+00 7.6285686e-04 3.4678303e-06 1.1167424e-08 4.8817459e-01\n",
            " 3.9141639e-03 1.6204423e-06 4.0885058e-01]\n",
            "[1.0000000e+00 5.4529399e-05 4.6973811e-03 2.5944533e-07 2.6127947e-02\n",
            " 8.2507608e-03 1.7258364e-03 1.8211418e-04]\n",
            "[1.17822994e-04 4.08746491e-05 3.63439060e-04 1.27464518e-04\n",
            " 7.09707960e-02 4.63935852e-01 9.98100102e-01 1.18333660e-03]\n",
            "[8.4880950e-05 2.0383573e-03 4.2705269e-06 9.8326516e-01 5.8117555e-03\n",
            " 4.0698253e-02 1.0316974e-05 4.2507346e-03]\n",
            "[1.0000000e+00 1.2882797e-01 3.5904402e-05 8.5819414e-07 2.9219594e-03\n",
            " 1.0697089e-01 1.0171142e-06 2.4991331e-04]\n",
            "[1.0000000e+00 1.9946788e-03 5.4705772e-05 1.0266626e-08 4.0698871e-03\n",
            " 3.7223510e-03 1.2728225e-07 1.2727966e-02]\n",
            "[1.0000000e+00 8.3367946e-04 2.8219452e-02 1.3490156e-06 7.6305615e-03\n",
            " 3.9956826e-03 4.5380161e-06 1.2855009e-03]\n",
            "[1.0000000e+00 1.9084613e-03 1.2818463e-02 2.2642415e-07 2.7274149e-03\n",
            " 2.2259566e-03 2.2948241e-07 2.8006156e-04]\n",
            "[1.0000000e+00 4.5751058e-03 8.1593101e-04 8.6033128e-07 2.2201997e-03\n",
            " 4.7739130e-03 2.1056260e-07 5.8992417e-04]\n",
            "[1.0000000e+00 2.7652254e-04 1.3776875e-05 1.4536554e-02 7.0991524e-02\n",
            " 1.2857774e-01 2.1931704e-05 1.2258115e-02]\n",
            "[3.2016620e-02 5.7552910e-01 9.3643437e-05 8.6324308e-09 3.3252805e-03\n",
            " 1.1660362e-02 4.4906891e-08 5.6347220e-05]\n",
            "[1.00000000e+00 2.64123752e-04 1.62120006e-04 1.19851051e-04\n",
            " 2.06263340e-03 5.06472494e-03 5.36280913e-06 1.31372325e-02]\n",
            "[1.00000000e+00 6.91536814e-04 2.93745822e-03 1.31161905e-05\n",
            " 1.84829216e-02 2.69164294e-02 8.18030676e-05 2.54073733e-04]\n",
            "[1.0000000e+00 5.0716016e-02 7.9959028e-07 8.4131779e-10 3.3790722e-02\n",
            " 6.7999065e-03 7.9122515e-08 3.5857350e-02]\n",
            "[1.0000000e+00 4.9806540e-03 5.1877087e-05 1.5905751e-08 1.3408583e-03\n",
            " 3.2686165e-03 3.1351541e-07 5.7755649e-04]\n",
            "[1.00000000e+00 7.34713078e-02 3.53823969e-04 7.99820725e-08\n",
            " 7.47786195e-04 4.35652025e-03 4.18641335e-08 1.11374124e-04]\n",
            "[1.0000000e+00 1.1462221e-01 5.6831783e-04 7.3129193e-08 2.5562167e-02\n",
            " 1.8129542e-02 6.7696089e-07 1.5407595e-04]\n",
            "[1.0000000e+00 1.9401022e-03 3.1131434e-01 3.9844533e-08 1.8933989e-03\n",
            " 1.3482000e-02 7.3155370e-06 2.8942685e-04]\n",
            "[1.0000000e+00 1.4391281e-03 8.3596287e-03 4.0107759e-07 1.4534593e-03\n",
            " 6.4441464e-03 2.2322854e-06 3.1063645e-04]\n",
            "[1.0000000e+00 9.4932020e-03 2.7700198e-05 9.2528688e-07 4.2192927e-03\n",
            " 1.3248219e-02 5.2159816e-08 7.6240656e-04]\n",
            "[8.9449785e-04 1.0862311e-03 5.1642919e-01 5.2973629e-08 1.5125315e-03\n",
            " 6.7542382e-03 3.3004179e-07 1.6280105e-04]\n",
            "[1.00000000e+00 7.79431895e-04 8.35005101e-03 1.07134248e-07\n",
            " 2.36241799e-03 1.41711375e-02 3.71307647e-06 2.49709352e-04]\n",
            "[1.0000000e+00 1.8764309e-04 3.1807085e-03 1.6939037e-05 8.7232841e-04\n",
            " 1.5428576e-03 1.6697024e-06 9.6946827e-04]\n",
            "[1.0000000e+00 1.0634985e-02 1.2513900e-05 8.3895507e-08 1.1098315e-02\n",
            " 2.0386588e-02 1.1450078e-07 2.6840756e-03]\n",
            "[1.0000000e+00 6.4007525e-04 9.7843008e-07 1.7268370e-07 1.4527497e-01\n",
            " 5.2709021e-03 1.3232786e-05 3.2140207e-01]\n",
            "[1.0000000e+00 3.5892834e-03 3.9172177e-05 8.7509716e-07 1.7242381e-02\n",
            " 3.2287363e-02 5.0584308e-06 5.1177577e-03]\n",
            "[1.0000000e+00 1.4435665e-03 4.7234557e-06 1.9087631e-03 1.9522904e-03\n",
            " 1.7308688e-02 4.8052752e-06 7.9498142e-02]\n",
            "[1.0000000e+00 5.2117789e-04 9.6279626e-05 2.4140959e-07 1.4672337e-02\n",
            " 4.6941126e-03 4.3337025e-07 6.3985527e-02]\n",
            "[1.0000000e+00 3.2985429e-03 4.1022210e-04 8.6114627e-09 1.3361913e-03\n",
            " 2.5782399e-03 4.1908635e-08 1.0418517e-03]\n",
            "[1.0000000e+00 2.8111542e-02 1.6443193e-03 4.9940400e-08 2.3269666e-05\n",
            " 9.1372849e-03 1.5917276e-05 1.8027440e-03]\n",
            "[1.0000000e+00 1.9531595e-04 1.9224515e-05 9.4482406e-05 5.1101906e-06\n",
            " 5.7318917e-04 1.5708963e-06 6.0989764e-03]\n",
            "[1.0000000e+00 6.7619071e-04 3.9019778e-06 4.6744892e-05 5.8822311e-04\n",
            " 8.0088630e-02 7.0217255e-05 2.2914736e-02]\n",
            "[1.0000000e+00 1.8088390e-04 2.4380131e-07 7.4077707e-06 1.0856235e-03\n",
            " 2.0363128e-02 2.8659460e-05 1.2809650e-02]\n",
            "[1.0000000e+00 7.5628795e-03 3.1374404e-07 1.0000838e-07 1.4795241e-04\n",
            " 6.9787125e-03 9.9698009e-05 1.0486871e-02]\n",
            "[5.9148801e-06 4.7964009e-04 5.7293853e-08 9.0900731e-01 1.5842442e-04\n",
            " 5.5731479e-02 6.7741228e-03 2.1569006e-01]\n",
            "[1.0000000e+00 5.1530427e-04 6.5878794e-07 1.4967768e-06 2.7229911e-02\n",
            " 2.5106002e-02 6.3701026e-02 7.7116988e-03]\n",
            "[1.0000000e+00 2.9128664e-03 7.5573248e-06 1.7109230e-07 6.2839543e-05\n",
            " 3.6537394e-04 1.4726901e-05 3.0268263e-03]\n",
            "[1.0000000e+00 1.2871933e-02 3.2656330e-06 1.0899855e-07 2.9532855e-05\n",
            " 1.7308483e-03 3.1139928e-06 2.9628589e-03]\n",
            "[1.0000000e+00 1.3802908e-03 1.2814449e-05 2.0220360e-02 1.6946028e-04\n",
            " 9.1839321e-02 2.9196081e-04 3.3635013e-03]\n",
            "[1.0000000e+00 3.8209858e-03 5.2103709e-04 6.1745521e-07 1.8301029e-05\n",
            " 2.9329756e-02 1.9873544e-06 1.0177771e-02]\n",
            "[1.7910818e-02 5.8330351e-01 8.9801951e-08 1.6302458e-08 7.4193355e-05\n",
            " 2.5452964e-02 3.7700934e-07 1.1322630e-02]\n",
            "[1.00000000e+00 1.31676812e-03 3.59889304e-06 1.18417155e-07\n",
            " 2.02006835e-04 1.09235570e-02 4.70120449e-06 1.82436290e-03]\n",
            "[1.0000000e+00 1.7592952e-03 7.5013736e-06 8.4370164e-08 1.7509064e-04\n",
            " 3.3950540e-03 2.2472050e-06 3.6040407e-03]\n",
            "[1.3236606e-03 5.6485693e-05 8.2943022e-01 3.7104667e-06 1.4847533e-05\n",
            " 2.3956909e-03 9.9675002e-05 1.8840515e-04]\n",
            "[1.0000000e+00 4.4410437e-05 1.4989699e-01 7.3915253e-06 1.0775439e-05\n",
            " 2.3825588e-03 1.9513733e-05 9.8487048e-04]\n",
            "[1.0000000e+00 7.1445960e-03 4.1868780e-06 1.6543209e-08 6.1349192e-06\n",
            " 1.0978852e-03 1.0368929e-06 4.4062559e-02]\n",
            "[1.0000000e+00 7.2287869e-05 4.6329829e-03 6.2788226e-06 6.9708408e-06\n",
            " 3.1917328e-03 6.1759078e-05 5.3150542e-03]\n",
            "[1.00000000e+00 8.18252083e-05 5.90727257e-04 3.73336261e-05\n",
            " 1.39783995e-04 7.33466633e-03 1.07202985e-04 1.77281245e-03]\n",
            "[1.0000000e+00 6.6580666e-05 6.1685177e-03 7.3583680e-05 7.1518880e-04\n",
            " 1.1086926e-02 1.3022605e-04 6.0749060e-04]\n",
            "[1.0000000e+00 2.3076733e-05 2.4915684e-04 2.1814132e-05 1.4592063e-03\n",
            " 4.7145681e-03 3.9903265e-05 1.8372966e-03]\n",
            "[1.0000000e+00 1.9073306e-04 6.7156623e-03 7.7866594e-07 1.0386840e-05\n",
            " 1.9863152e-03 3.6198574e-06 1.1809263e-04]\n",
            "[1.0000000e+00 8.8761694e-04 9.5417256e-08 6.7842498e-02 5.5883880e-05\n",
            " 1.5014793e-02 8.9036774e-05 2.1034789e-01]\n",
            "[1.0000000e+00 2.7376675e-04 3.3247679e-06 1.2356666e-07 3.6450668e-04\n",
            " 8.6570326e-03 9.6149670e-05 1.4005543e-02]\n",
            "[1.00000000e+00 2.32169506e-04 3.23932312e-08 1.14501404e-07\n",
            " 3.57971783e-03 2.65162857e-03 1.01332955e-01 4.08185758e-02]\n",
            "[1.00000000e+00 1.08364504e-04 6.68135690e-05 5.83394879e-08\n",
            " 4.83469121e-05 6.00272208e-04 4.95286004e-05 1.45042703e-01]\n",
            "[1.0000000e+00 4.4839783e-04 1.2705684e-05 1.3845578e-04 7.5677184e-05\n",
            " 2.1733183e-02 1.4374350e-04 2.5533972e-02]\n",
            "[3.9369392e-05 1.3368270e-04 8.6803163e-07 3.3452212e-05 9.6127689e-01\n",
            " 2.0598419e-01 5.0468445e-01 7.4106669e-03]\n",
            "[1.00000000e+00 2.66712578e-03 5.11953090e-07 1.66124107e-06\n",
            " 1.54335739e-03 3.31944227e-02 2.38313861e-02 1.28174275e-02]\n",
            "[1.0000000e+00 2.2015479e-04 2.1803196e-06 2.3504184e-03 3.6010565e-04\n",
            " 2.1620612e-01 2.9797119e-01 3.8644662e-03]\n",
            "[1.0000000e+00 3.3326343e-01 2.0450499e-07 1.9956985e-07 1.6927283e-05\n",
            " 9.1469757e-02 1.8518970e-06 1.3754897e-01]\n",
            "[1.0000000e+00 8.9978762e-03 2.0405319e-07 1.0303564e-04 3.4536017e-04\n",
            " 9.2829550e-03 3.2648206e-04 3.3926483e-02]\n",
            "[1.0000000e+00 1.7612875e-03 2.0244292e-03 1.4549571e-04 2.1853579e-02\n",
            " 1.8280718e-02 1.4185537e-02 2.3081705e-03]\n",
            "[1.0000000e+00 1.6796829e-03 1.2202421e-02 2.8464600e-04 1.5619188e-02\n",
            " 6.9199465e-02 6.6459045e-02 1.5452318e-03]\n",
            "[1.0000000e+00 1.2592295e-03 7.8376662e-04 1.2260301e-02 5.2512498e-03\n",
            " 2.3888333e-02 2.7786622e-02 7.1198837e-04]\n",
            "[1.6314175e-04 7.8056694e-04 6.0323032e-06 8.3130085e-01 3.1273924e-02\n",
            " 6.4169280e-02 1.0899781e-01 2.2623660e-02]\n",
            "[1.0000000e+00 2.8743057e-03 4.2663846e-06 3.2041735e-05 2.0117969e-03\n",
            " 5.2356133e-03 9.3159573e-03 3.1668022e-01]\n",
            "[1.0000000e+00 1.3924961e-03 6.7855643e-07 2.9454945e-04 2.9219905e-01\n",
            " 2.4469866e-01 5.8220629e-02 1.8416448e-01]\n",
            "[1.0000000e+00 7.2514154e-03 8.5467653e-04 1.1743915e-05 9.6997002e-04\n",
            " 3.8560303e-03 5.3516100e-04 1.6203143e-03]\n",
            "[1.0000000e+00 4.9047470e-02 7.6525379e-04 1.9336155e-06 1.9548270e-03\n",
            " 2.2117088e-02 2.6881217e-04 4.1729433e-04]\n",
            "[1.0000000e+00 4.9592723e-04 2.2720028e-06 2.8902085e-03 3.1656935e-03\n",
            " 3.0055407e-03 1.6980877e-02 6.1447022e-04]\n",
            "[1.0000000e+00 2.6853275e-03 1.1404552e-05 3.5413518e-04 2.3441410e-03\n",
            " 4.6771266e-03 8.4565219e-04 1.3816328e-03]\n",
            "[1.0000000e+00 1.0665789e-02 1.7838358e-06 6.2410290e-05 5.4728474e-02\n",
            " 1.7635904e-01 3.2715187e-03 7.2286879e-03]\n",
            "[1.0000000e+00 1.8492153e-02 1.5246583e-06 6.5385493e-06 9.1144452e-03\n",
            " 1.1668215e-02 3.4401377e-04 2.3106516e-03]\n",
            "[1.0000000e+00 2.1673681e-03 1.1887410e-04 5.9251080e-04 1.0381369e-02\n",
            " 3.5796703e-03 1.3082382e-02 3.7764389e-02]\n",
            "[1.0000000e+00 1.1464901e-02 1.4425898e-06 5.4686357e-06 7.6114595e-02\n",
            " 5.9688978e-02 7.4987323e-04 7.2589754e-03]\n",
            "[2.1159247e-04 3.9764366e-04 8.9842719e-01 1.5139840e-04 6.8262611e-03\n",
            " 2.6999714e-02 1.0077800e-02 1.7390524e-04]\n",
            "[1.0000000e+00 1.3677726e-04 5.0158366e-03 4.4683708e-04 2.0376682e-02\n",
            " 5.4466069e-02 2.4943948e-02 1.1876777e-02]\n",
            "[1.0000000e+00 8.0938824e-04 1.6257502e-05 1.1967277e-03 2.0069844e-01\n",
            " 1.8634092e-02 6.9136202e-02 2.9200101e-02]\n",
            "[1.00000000e+00 2.68772186e-04 1.63165696e-05 2.43266253e-03\n",
            " 3.78748067e-02 4.10221424e-03 2.84089502e-02 1.15495235e-01]\n",
            "[1.0000000e+00 6.8929414e-03 1.2379052e-03 5.3026160e-05 5.4867397e-04\n",
            " 4.9484061e-04 1.2767165e-03 5.0553959e-03]\n",
            "[1.0000000e+00 2.1203596e-04 3.8770746e-04 7.8018373e-03 1.0288432e-02\n",
            " 2.4566536e-03 3.8966650e-01 4.2182673e-03]\n",
            "[1.4712795e-04 8.1518584e-01 1.0022301e-05 6.5232865e-07 1.6179361e-03\n",
            " 9.9819954e-03 2.0153830e-03 1.0583921e-02]\n",
            "[1.0000000e+00 1.1395638e-02 7.2953470e-02 4.6242890e-06 5.6849280e-04\n",
            " 8.2329866e-03 2.0509870e-03 1.7710384e-03]\n",
            "[1.0000000e+00 6.2351185e-03 1.4709598e-04 1.3419060e-05 1.9743035e-02\n",
            " 3.5570844e-03 1.4154165e-03 6.6908328e-03]\n",
            "[1.0000000e+00 1.6685748e-03 3.9668652e-05 1.4098163e-04 2.7399235e-03\n",
            " 1.2414763e-03 1.9478746e-03 2.1680298e-03]\n",
            "[1.0000000e+00 3.0056995e-04 2.7889589e-06 5.1651835e-02 2.4189234e-02\n",
            " 9.1490939e-02 6.9943823e-02 6.4217895e-02]\n",
            "[1.0000000e+00 9.3202590e-04 3.6938738e-03 8.1749722e-02 2.4387103e-03\n",
            " 1.5642256e-02 5.6834213e-02 2.6597822e-04]\n",
            "[1.0000000e+00 1.3300836e-04 1.3813980e-05 5.9846723e-03 9.9269522e-04\n",
            " 9.9049276e-04 1.2634029e-02 5.7475572e-03]\n",
            "[1.0000000e+00 2.8239907e-04 6.6658737e-05 2.5591888e-05 9.7088533e-04\n",
            " 1.1710827e-03 6.1146053e-03 3.4669600e-02]\n",
            "[1.0000000e+00 3.6895063e-02 5.5211456e-07 4.2743730e-05 3.2197437e-03\n",
            " 6.3178763e-03 1.6720784e-04 5.5137806e-02]\n",
            "[1.0000000e+00 1.9433702e-03 2.7796254e-06 2.1231783e-05 1.3604394e-01\n",
            " 3.2973900e-02 3.5016678e-04 1.8396191e-02]\n",
            "[1.0000000e+00 2.4606702e-03 1.2809698e-05 1.1567831e-05 2.5151719e-03\n",
            " 5.4238280e-03 2.0712672e-04 4.3379810e-02]\n",
            "[1.0000000e+00 1.8322380e-03 1.1764508e-03 2.7650534e-05 1.3646592e-03\n",
            " 5.3987633e-03 1.7651482e-03 4.3214788e-03]\n",
            "[1.0000000e+00 1.7234588e-05 1.4125067e-02 1.9318628e-01 1.1292319e-04\n",
            " 7.9071725e-04 1.5448067e-07 2.2606166e-04]\n",
            "[2.76767043e-03 1.38162068e-05 7.42850304e-01 1.03854323e-02\n",
            " 1.20034158e-04 7.66751240e-04 3.49436107e-07 1.12891794e-04]\n",
            "[1.0000000e+00 2.5618568e-03 9.5913645e-05 1.2528362e-04 2.6865051e-05\n",
            " 3.5629165e-04 4.5394999e-09 3.3931232e-03]\n",
            "[1.0000000e+00 1.3696401e-01 7.2174879e-07 2.8989423e-04 1.6909443e-04\n",
            " 5.0483728e-03 2.6879862e-08 3.9802052e-02]\n",
            "[1.0000000e+00 5.5535872e-02 5.4914148e-05 1.7323419e-04 5.3589967e-05\n",
            " 9.2025464e-03 2.3786729e-08 1.1572964e-04]\n",
            "[1.0000000e+00 4.0607979e-03 6.9715206e-05 9.4678551e-05 1.6645779e-04\n",
            " 4.4323779e-03 7.9028048e-08 1.0400159e-04]\n",
            "[1.00000000e+00 6.93257973e-02 4.00558037e-07 1.52267085e-05\n",
            " 2.58174469e-03 8.64136149e-04 9.78571606e-08 4.46920283e-03]\n",
            "[2.57889275e-04 6.41958773e-01 2.12079655e-07 4.72048159e-05\n",
            " 2.47634220e-04 3.73417214e-02 1.10768944e-07 1.84813363e-03]\n",
            "[1.0000000e+00 1.9806050e-04 1.1071962e-03 7.6761120e-05 1.9328243e-05\n",
            " 4.5111859e-03 7.3755766e-09 1.3302907e-02]\n",
            "[1.0000000e+00 2.3084213e-03 4.7466528e-05 6.8448186e-05 8.6089429e-05\n",
            " 8.7970365e-03 3.1150140e-09 5.6348497e-04]\n",
            "[1.0000000e+00 8.0069243e-05 1.1966407e-02 5.9475115e-04 4.9504300e-04\n",
            " 7.2167236e-03 1.3830091e-06 2.0640912e-03]\n",
            "[1.0000000e+00 2.0445581e-04 8.8947220e-03 4.3066540e-03 8.9229470e-05\n",
            " 2.7466277e-02 4.8647371e-07 6.7697081e-04]\n",
            "[1.0000000e+00 3.0487818e-05 4.2944707e-02 2.3276822e-03 7.1119990e-05\n",
            " 1.1804369e-03 2.7155596e-07 2.1418769e-04]\n",
            "[1.0000000e+00 3.6989167e-04 4.6970990e-02 2.5482377e-04 4.4675511e-05\n",
            " 1.5727397e-02 1.3091314e-07 8.1582129e-04]\n",
            "[1.0000000e+00 4.4919280e-04 2.6470509e-06 3.1511837e-01 1.0864793e-04\n",
            " 7.4460916e-03 1.5558668e-06 2.5586330e-03]\n",
            "[1.0000000e+00 1.4400051e-05 1.3056298e-01 2.0947503e-03 1.8479564e-05\n",
            " 7.1711239e-04 7.6727993e-08 5.6182314e-04]\n",
            "[1.00000000e+00 1.87984915e-04 2.65192903e-05 7.93962157e-04\n",
            " 1.04115228e-03 2.97819078e-03 1.16077004e-07 1.34752912e-03]\n",
            "[1.0000000e+00 3.8280756e-05 4.4664688e-05 2.3567369e-03 2.2856351e-05\n",
            " 4.9683539e-04 1.9571209e-08 1.5644422e-03]\n",
            "[1.0000000e+00 2.1109324e-04 5.6544031e-06 3.7857771e-04 1.3374590e-03\n",
            " 8.7521918e-04 1.1865416e-07 2.6650928e-02]\n",
            "[1.00000000e+00 2.27943630e-04 4.58706927e-06 7.20011376e-05\n",
            " 8.08362893e-05 1.01251804e-04 1.46145513e-08 2.31273863e-02]\n",
            "[1.00000000e+00 7.27717634e-05 1.06597807e-04 8.24630435e-04\n",
            " 4.16991825e-05 4.78389207e-04 2.02749746e-08 1.02836415e-02]\n",
            "[1.00000000e+00 6.70736190e-05 5.54854232e-05 1.03731835e-02\n",
            " 2.34244962e-05 7.21453223e-04 3.51728815e-08 1.57582462e-02]\n",
            "[1.00000000e+00 1.35484999e-02 6.65673838e-07 8.39292828e-04\n",
            " 1.05374005e-04 3.88635322e-03 1.09472760e-08 3.34796123e-03]\n",
            "[3.1956498e-04 3.3221857e-04 7.3615246e-07 2.1304189e-04 9.0094203e-05\n",
            " 1.5608629e-03 8.6833961e-07 8.2628709e-01]\n",
            "[1.0000000e+00 6.8349123e-02 1.6554967e-06 6.1053364e-03 1.5926136e-04\n",
            " 8.8873953e-03 5.1485409e-07 1.0354946e-03]\n",
            "[1.0000000e+00 1.0737123e-03 1.2895524e-05 3.0737150e-01 4.2209821e-04\n",
            " 1.8722779e-01 1.2743599e-06 2.7333957e-03]\n",
            "[1.9764986e-05 3.7173956e-04 6.3642897e-06 4.8700906e-02 1.4678638e-03\n",
            " 3.5659528e-01 5.3950489e-01 3.6733411e-04]\n",
            "[1.0000000e+00 2.1107089e-04 1.4198401e-06 5.7030141e-02 1.7987774e-04\n",
            " 4.8450217e-02 2.8457335e-01 2.4642874e-03]\n",
            "[6.1786006e-04 1.0347038e-03 8.5657007e-07 9.3024300e-04 6.6947740e-01\n",
            " 7.4565872e-03 7.5269063e-06 9.5098250e-04]\n",
            "[1.0000000e+00 2.2463462e-05 1.7507722e-06 1.2554465e-02 2.5907838e-01\n",
            " 7.1549892e-02 1.5586019e-01 7.9752468e-03]\n",
            "[1.0000000e+00 3.5256231e-05 2.1895521e-05 1.6715368e-02 1.6964532e-02\n",
            " 1.5033689e-01 1.6700758e-02 4.9536130e-03]\n",
            "[1.0000000e+00 1.2291982e-04 1.3892259e-05 5.5811205e-03 4.5096729e-02\n",
            " 2.6532227e-02 3.3455151e-03 3.2327976e-04]\n",
            "[1.00000000e+00 8.17575026e-04 1.19402565e-01 6.33440865e-03\n",
            " 1.76262915e-01 2.52807960e-02 1.77850237e-03 2.13966286e-03]\n",
            "[1.00000000e+00 2.13303231e-03 1.03617124e-01 2.86282115e-02\n",
            " 1.51549101e-01 1.13731034e-01 4.60815709e-03 9.65814746e-04]\n",
            "[1.0000000e+00 6.7043066e-04 3.2366344e-04 1.2827734e-04 2.5244306e-03\n",
            " 6.3080795e-04 6.8825501e-04 2.5581723e-01]\n",
            "[1.         0.00521507 0.00174727 0.00152117 0.00952976 0.01580046\n",
            " 0.00411971 0.0580679 ]\n",
            "[1.0000000e+00 5.3001873e-02 5.1826169e-03 1.2751351e-03 5.5770129e-03\n",
            " 1.2909014e-02 1.5981117e-04 2.2112201e-03]\n",
            "[1.0000000e+00 2.1667954e-02 2.3094162e-03 6.8730209e-04 1.5502104e-02\n",
            " 2.3532353e-02 1.5250838e-03 5.7089641e-03]\n",
            "[1.0000000e+00 3.7043162e-02 6.8256515e-04 3.0353782e-01 3.0036664e-04\n",
            " 1.9855214e-02 9.2594122e-04 1.7863043e-02]\n",
            "[6.55155554e-02 5.76130569e-01 6.61973329e-03 2.29476373e-05\n",
            " 1.72329354e-04 1.02043548e-03 1.00205066e-10 1.57469511e-02]\n",
            "[1.0000000e+00 9.7668928e-04 1.6102415e-01 6.6317655e-03 3.7975966e-03\n",
            " 3.0617200e-02 3.1441092e-03 7.5322823e-03]\n",
            "[9.2307997e-01 3.3049073e-02 8.5963849e-03 9.2655318e-06 1.9051049e-04\n",
            " 7.7357999e-04 5.9911298e-09 1.6567292e-02]\n",
            "[1.0000000e+00 1.9430288e-04 1.1040296e-01 1.6677836e-02 1.9201409e-02\n",
            " 5.6736479e-03 3.3714030e-05 5.2401391e-03]\n",
            "[1.0000000e+00 1.0789402e-03 6.5709673e-02 1.0504232e-02 2.4812853e-02\n",
            " 8.2356399e-03 7.3030638e-04 4.8258374e-03]\n",
            "[1.00000000e+00 3.57817486e-03 4.21264097e-02 1.65449064e-02\n",
            " 5.93719212e-03 1.00958794e-01 4.30457979e-01 8.53415171e-04]\n",
            "[1.0000000e+00 8.8727463e-04 2.0893587e-01 5.9016892e-03 4.5913118e-03\n",
            " 2.8387310e-02 4.8539550e-03 6.5479199e-03]\n",
            "[1.         0.00322075 0.00570415 0.01630026 0.02766768 0.04611317\n",
            " 0.00715831 0.04007863]\n",
            "[1.0000000e+00 4.1381530e-03 1.4541843e-03 9.8128885e-04 4.9099535e-01\n",
            " 5.7736924e-03 1.6214172e-04 2.7018860e-01]\n",
            "[1.0000000e+00 2.3581486e-02 2.7663826e-03 1.6124012e-02 3.0441053e-04\n",
            " 2.1054707e-02 5.7196288e-05 8.4781023e-03]\n",
            "[1.         0.00172303 0.00926324 0.12037732 0.00123676 0.03051212\n",
            " 0.00289514 0.00400176]\n",
            "[1.         0.02127299 0.00374044 0.00480415 0.00113073 0.03512248\n",
            " 0.15399872 0.00128353]\n",
            "[1.         0.02297269 0.00169177 0.00760728 0.01324275 0.0610224\n",
            " 0.02008375 0.0072942 ]\n",
            "[1.         0.01178227 0.00611628 0.00773829 0.00813803 0.10851855\n",
            " 0.01018479 0.01041859]\n",
            "[1.         0.00577535 0.00671155 0.0128673  0.00317274 0.06246316\n",
            " 0.08598779 0.01366879]\n",
            "[1.0000000e+00 1.7510599e-03 1.1480579e-03 5.0914421e-04 1.5073115e-03\n",
            " 4.2901589e-03 1.1637027e-02 3.7664130e-02]\n",
            "[1.0000000e+00 3.5625223e-02 9.8750824e-03 2.6202428e-03 1.2437343e-03\n",
            " 2.4694344e-02 4.3502461e-02 5.9464964e-04]\n",
            "[1.         0.00759157 0.00284342 0.00612251 0.00129777 0.023433\n",
            " 0.03108743 0.00953354]\n",
            "[1.0000000e+00 1.8917021e-03 4.7383569e-03 1.1694465e-02 1.3930515e-02\n",
            " 5.9556398e-03 1.6864057e-04 1.8630399e-01]\n",
            "[1.00000000e+00 9.26605798e-03 1.02467025e-02 3.76876950e-01\n",
            " 2.20397557e-03 1.08014122e-02 5.32829377e-04 1.74422155e-03]\n",
            "[1.         0.04912222 0.01120574 0.00188987 0.00140194 0.01281342\n",
            " 0.00786229 0.00104851]\n",
            "[1.         0.01917007 0.02484037 0.00164192 0.00264731 0.02288819\n",
            " 0.00659503 0.00241714]\n",
            "[1.0000000e+00 1.8623412e-02 3.2167878e-02 2.9413775e-03 2.2412252e-03\n",
            " 3.2353703e-02 5.8220495e-02 7.9261477e-04]\n",
            "[1.         0.00323987 0.02567982 0.00981862 0.00591449 0.05386037\n",
            " 0.0381926  0.00384562]\n",
            "[1.0000000e+00 2.2807991e-02 3.1261870e-03 6.8002503e-04 1.7743810e-03\n",
            " 5.0923198e-02 6.8647824e-02 5.5570342e-04]\n",
            "[1.0000000e+00 1.6024781e-02 2.8528998e-04 2.0714474e-03 6.5071627e-06\n",
            " 2.8738551e-02 8.5500121e-02 1.3511071e-03]\n",
            "[1.0000000e+00 1.8893336e-01 1.8804043e-04 2.0690427e-04 7.3688716e-06\n",
            " 1.4687055e-02 1.6805004e-02 1.2689983e-03]\n",
            "[1.0000000e+00 4.8829626e-02 1.3412331e-04 1.5490724e-03 9.0283584e-06\n",
            " 1.5990002e-02 8.6710406e-03 4.0153763e-03]\n",
            "[1.0000000e+00 6.5631784e-02 1.1725329e-03 2.0087203e-03 9.4738989e-06\n",
            " 1.6913438e-01 4.3479943e-01 2.6076337e-04]\n",
            "[1.0000000e+00 8.2652573e-04 4.4577007e-04 8.6509896e-04 5.6330511e-05\n",
            " 1.1843622e-02 2.8524224e-03 3.0607777e-02]\n",
            "[1.0000000e+00 2.8603833e-02 6.2596126e-05 4.4008470e-06 7.4968302e-06\n",
            " 1.6353995e-04 4.0908400e-08 7.9043865e-02]\n",
            "[1.0000000e+00 2.5754478e-02 1.7436150e-04 1.4472837e-03 2.1641408e-05\n",
            " 1.2145626e-01 6.5152675e-02 7.7377510e-04]\n",
            "[1.00000000e+00 4.01988141e-02 7.03594880e-04 1.61567831e-03\n",
            " 8.06522257e-06 1.15210995e-01 1.06110863e-01 3.91917769e-04]\n",
            "[1.0000000e+00 4.4186260e-03 2.9563523e-04 3.0981421e-03 1.0762972e-05\n",
            " 5.1522449e-02 2.5230438e-01 8.0128387e-04]\n",
            "[1.0000000e+00 1.6158381e-02 1.5079531e-04 3.8009089e-06 1.1317452e-06\n",
            " 9.4395009e-04 2.6645272e-05 9.1265896e-03]\n",
            "[1.1487978e-04 7.4466243e-03 9.5443410e-04 9.8093146e-01 7.7364357e-06\n",
            " 5.9317105e-02 1.1597999e-06 1.5355297e-02]\n",
            "[1.0000000e+00 2.5612835e-02 7.7429400e-03 1.3765292e-03 6.0182333e-06\n",
            " 2.7260670e-02 1.2061624e-02 3.5421478e-04]\n",
            "[1.0000000e+00 2.9143551e-04 3.0158199e-02 1.0340824e-05 4.1137142e-08\n",
            " 2.7987420e-05 2.7426543e-08 5.3764332e-02]\n",
            "[1.0000000e+00 6.6109601e-04 2.0327074e-03 1.4644464e-04 3.2349049e-06\n",
            " 3.1273975e-03 1.3223662e-04 1.8624263e-01]\n",
            "[1.0000000e+00 1.1845624e-02 1.8174456e-04 9.9406483e-05 5.6854238e-05\n",
            " 7.4706222e-03 1.7925455e-05 3.1449641e-03]\n",
            "[1.0000000e+00 2.1480729e-03 1.0109056e-03 7.2356005e-04 5.6344888e-04\n",
            " 1.6715769e-02 1.5539213e-02 8.0817807e-03]\n",
            "[1.0000000e+00 1.8069759e-02 3.3150665e-03 1.0078492e-03 6.4649683e-04\n",
            " 1.2071688e-02 5.5402243e-06 1.2391517e-02]\n",
            "[1.2232248e-04 1.1080422e-02 5.5147302e-01 3.4523924e-05 8.9203197e-05\n",
            " 5.2345437e-03 2.2339181e-07 2.2006275e-03]\n",
            "[1.0000000e+00 1.4640889e-02 7.2950039e-05 6.2092826e-05 2.6104574e-03\n",
            " 2.2957390e-02 3.2361532e-07 2.2625005e-01]\n",
            "[1.00000000e+00 1.14635095e-01 1.49988755e-05 1.56038168e-05\n",
            " 2.14544707e-03 1.25408731e-02 6.60315891e-08 7.23109990e-02]\n",
            "[1.0000000e+00 1.6350573e-02 4.5289919e-03 2.5278280e-04 9.5184976e-03\n",
            " 1.4533115e-02 3.7408536e-06 1.0022020e-03]\n",
            "[1.0000000e+00 4.5799516e-02 1.4208595e-04 1.0798419e-04 7.5851075e-02\n",
            " 1.3200568e-02 4.7457132e-07 2.3334806e-03]\n",
            "[1.0000000e+00 2.7113976e-02 3.6915972e-05 2.4275851e-04 2.4269111e-02\n",
            " 2.2582833e-02 2.5972156e-06 2.1200243e-03]\n",
            "[1.0000000e+00 1.6643666e-01 4.5875946e-05 6.6815155e-05 4.9738227e-03\n",
            " 2.8340185e-02 4.2084804e-07 1.0231428e-03]\n",
            "[2.6208254e-05 2.0003136e-02 1.8285951e-04 5.3494069e-04 7.4075156e-01\n",
            " 2.9348236e-02 5.9280131e-07 3.9529218e-03]\n",
            "[1.0000000e+00 6.8664490e-03 2.4711684e-04 3.7386394e-04 4.4353270e-05\n",
            " 9.7331771e-04 3.1856516e-08 2.4674928e-01]\n",
            "[1.00000000e+00 3.54093313e-02 2.61089150e-02 1.05564795e-05\n",
            " 2.35171683e-05 8.41324106e-02 3.93815583e-07 1.35226909e-03]\n",
            "[1.0000000e+00 2.2882974e-02 2.0488955e-01 5.8796548e-05 2.4814930e-05\n",
            " 3.4560908e-02 2.9889209e-06 5.0466736e-03]\n",
            "[1.0000000e+00 4.7206655e-03 1.6102083e-03 5.7735172e-04 1.3118871e-01\n",
            " 4.8754305e-02 5.1779289e-06 2.7806454e-04]\n",
            "[1.0000000e+00 3.1484871e-03 8.5393041e-03 3.6423921e-04 6.8852087e-03\n",
            " 1.9855227e-02 2.0113432e-06 2.5267989e-04]\n",
            "[7.6459837e-01 7.6795919e-03 1.4851190e-01 2.3998109e-06 1.4395046e-07\n",
            " 4.9437611e-05 5.7433014e-10 6.6124997e-04]\n",
            "[1.0000000e+00 1.7765732e-03 4.5865602e-03 1.2917705e-04 2.0241491e-04\n",
            " 7.2546164e-03 6.1465067e-07 2.7490137e-02]\n",
            "[1.0000000e+00 2.3266803e-02 6.2908079e-08 1.1220079e-05 1.0409057e-05\n",
            " 6.0774576e-02 1.0040174e-03 8.9733599e-04]\n",
            "[1.0000000e+00 3.3759986e-04 5.0032490e-08 1.2896029e-05 2.0640036e-06\n",
            " 1.0068386e-02 4.8503258e-05 2.0516001e-01]\n",
            "[1.0000000e+00 7.0379597e-06 1.6036620e-07 8.1199265e-05 4.5667373e-04\n",
            " 3.2321450e-03 9.6594880e-04 3.0155242e-03]\n",
            "[1.0000000e+00 2.5448691e-05 1.0650181e-07 1.2992496e-04 3.7683293e-02\n",
            " 8.2110940e-03 3.5430200e-03 6.5599778e-04]\n",
            "[1.0000000e+00 1.4197274e-05 3.1935843e-07 5.9899519e-04 3.2266998e-01\n",
            " 5.0846491e-02 3.8850042e-03 4.6836734e-03]\n",
            "[1.00000000e+00 5.09641677e-06 3.74805211e-07 5.06538549e-04\n",
            " 1.15474075e-01 1.79766156e-02 4.26132791e-03 2.36040726e-02]\n",
            "[5.67873176e-05 2.03197033e-06 4.53316687e-07 7.30565310e-01\n",
            " 1.12630023e-05 1.18054245e-02 2.47287795e-01 1.56976700e-01]\n",
            "[1.4595703e-04 1.9756326e-06 1.8331230e-06 2.3733556e-01 1.1265184e-03\n",
            " 4.6178073e-02 6.6158223e-01 9.2942063e-03]\n",
            "[1.0000000e+00 6.7295639e-07 1.0082157e-07 2.7590148e-02 1.2891551e-05\n",
            " 1.0782678e-03 5.2005001e-03 3.0291736e-01]\n",
            "[1.0000000e+00 4.8296031e-05 7.8628581e-08 4.0487332e-05 6.2809949e-04\n",
            " 6.5385499e-03 3.4635531e-04 2.0646121e-02]\n",
            "[1.0000000e+00 1.5530792e-04 2.9032529e-07 2.1570704e-05 4.4580185e-04\n",
            " 5.1072459e-03 3.6942557e-04 7.9764985e-04]\n",
            "[1.00000000e+00 1.38125215e-05 7.07106039e-07 7.43838493e-04\n",
            " 1.08260721e-01 1.32411644e-02 1.12177553e-02 4.69902152e-04]\n",
            "[1.0000000e+00 3.2174225e-06 9.9614908e-07 1.9758943e-04 8.5522520e-04\n",
            " 5.2017728e-03 2.2973176e-02 2.7235888e-02]\n",
            "[1.0000000e+00 5.7480815e-05 2.6891649e-07 8.8606525e-05 2.7659398e-03\n",
            " 1.2296642e-02 8.5145114e-03 6.1748386e-03]\n",
            "[1.0000000e+00 1.8004121e-05 2.6876216e-07 1.5473811e-04 4.0836015e-01\n",
            " 3.2532574e-03 2.9994741e-03 4.9165502e-04]\n",
            "[1.0000000e+00 2.6983065e-05 1.0113754e-05 3.1884512e-05 1.2930884e-06\n",
            " 7.5279386e-04 8.6401869e-04 5.7067992e-03]\n",
            "[6.6347075e-06 6.9785076e-01 1.6671787e-07 2.0409356e-05 1.3108431e-07\n",
            " 1.3006968e-02 2.0785598e-04 3.2543024e-04]\n",
            "[1.0000000e+00 2.5569186e-01 6.2559076e-07 6.5834036e-05 1.0202617e-07\n",
            " 1.7689973e-02 9.1923971e-04 8.5803047e-05]\n",
            "[1.0000000e+00 5.1619631e-06 4.4318617e-07 1.6879539e-04 1.1219820e-03\n",
            " 4.8934338e-03 1.1002966e-03 2.2163789e-03]\n",
            "[1.0000000e+00 9.7413076e-06 7.7011236e-07 1.0605279e-04 7.4911441e-06\n",
            " 3.9541973e-03 2.7283214e-04 8.4481137e-03]\n",
            "[1.0000000e+00 1.8113931e-05 5.8144769e-07 5.8637543e-05 1.8384995e-06\n",
            " 1.6079877e-01 8.2694698e-04 7.0602568e-03]\n",
            "[1.0000000e+00 5.3489381e-05 7.1776171e-08 1.7633238e-05 1.0109787e-04\n",
            " 1.0775539e-02 8.9194259e-04 6.3783772e-02]\n",
            "[1.0000000e+00 7.1123868e-05 5.7681252e-08 9.3204064e-05 1.7140884e-06\n",
            " 1.7548116e-02 3.5721893e-04 4.0103078e-02]\n",
            "[1.0000000e+00 9.3243475e-04 1.3439549e-07 1.6519168e-04 1.8367759e-07\n",
            " 3.8084853e-01 3.3164017e-03 9.4568580e-03]\n",
            "[5.83132824e-05 2.38096209e-06 8.80228639e-01 1.16433876e-04\n",
            " 1.66389071e-07 4.78994334e-03 7.74613628e-03 5.28360717e-04]\n",
            "[1.0000000e+00 1.5386890e-04 1.1944236e-01 3.9364044e-05 7.8777113e-08\n",
            " 4.4936482e-02 3.9191209e-03 1.0047975e-04]\n",
            "[1.0000000e+00 1.4449394e-02 4.2110778e-06 1.4517002e-04 9.0767237e-08\n",
            " 2.6210569e-02 3.0045731e-03 1.7993178e-04]\n",
            "[1.0000000e+00 2.3400786e-05 3.0371911e-04 7.1332666e-05 4.4539895e-08\n",
            " 3.2171004e-02 2.1730657e-03 4.2628520e-03]\n",
            "[1.0000000e+00 4.9446104e-03 1.5638017e-08 2.6572936e-05 1.9200111e-07\n",
            " 5.1307253e-04 2.9472067e-05 1.7473551e-02]\n",
            "[1.00000000e+00 1.59145985e-03 4.82008602e-07 1.38709975e-05\n",
            " 1.65268759e-07 1.50750799e-03 2.54477563e-05 3.46374959e-02]\n",
            "[5.1483828e-01 4.6370355e-06 1.4973633e-06 6.8791711e-04 1.7028258e-07\n",
            " 3.4430262e-04 9.1196700e-05 4.6368768e-03]\n",
            "[1.0000000e+00 2.1359892e-04 6.8130220e-08 9.3102877e-05 1.2836674e-07\n",
            " 2.3449101e-02 5.5176344e-05 3.7973013e-02]\n",
            "[1.0000000e+00 5.0813484e-04 2.2986130e-04 1.4055377e-01 4.3239825e-06\n",
            " 3.2706381e-04 2.0135515e-07 1.2144163e-02]\n",
            "[1.0000000e+00 7.5569436e-02 6.2472759e-07 1.4007872e-04 8.4135490e-06\n",
            " 1.5798240e-03 4.3569905e-08 6.7465091e-03]\n",
            "[1.0000000e+00 8.4001839e-04 4.3635946e-02 4.9797451e-04 6.3085616e-07\n",
            " 1.5767039e-04 2.8792348e-08 1.0536255e-04]\n",
            "[1.0000000e+00 3.0460088e-03 1.8559661e-03 5.4217973e-05 2.1516316e-06\n",
            " 1.6482119e-03 1.0938436e-08 1.4841033e-03]\n",
            "[1.0000000e+00 4.6584464e-05 2.0345677e-02 5.0566555e-04 4.4180333e-06\n",
            " 5.5152114e-04 2.3949957e-08 2.1067688e-03]\n",
            "[1.0000000e+00 7.3117801e-05 2.5838800e-04 3.5483864e-04 6.9769872e-06\n",
            " 1.1291931e-03 1.2202380e-08 4.2270329e-03]\n",
            "[1.0000000e+00 1.5068040e-04 1.9967745e-01 5.8909180e-04 4.6182627e-06\n",
            " 8.0289406e-04 1.6712750e-08 1.6681560e-03]\n",
            "[1.0000000e+00 5.3954037e-04 1.2255295e-01 2.3995095e-04 2.4920880e-06\n",
            " 4.1912687e-03 3.1243605e-08 6.4462388e-04]\n",
            "[1.0000000e+00 1.5723825e-03 2.3659256e-06 5.9544778e-04 1.6734575e-05\n",
            " 1.5971851e-01 7.1228006e-09 7.2866092e-03]\n",
            "[1.0000000e+00 1.2123451e-01 9.4369798e-06 1.3526827e-04 5.1739257e-06\n",
            " 2.1731793e-03 4.6300350e-09 3.3550028e-04]\n",
            "[1.0000000e+00 2.8487556e-03 1.2377939e-06 2.2424877e-04 2.4275698e-05\n",
            " 1.2636526e-03 8.0457987e-09 1.6257770e-01]\n",
            "[1.0000000e+00 6.8429718e-04 6.0503124e-03 8.5100584e-04 9.3993131e-06\n",
            " 1.8327058e-03 7.1629678e-08 1.7198406e-03]\n",
            "[2.4077526e-05 6.3842094e-01 1.1398965e-05 8.7936968e-04 1.9781264e-05\n",
            " 1.1500176e-02 5.1748440e-08 3.7245898e-04]\n",
            "[1.0000000e+00 1.8730075e-03 1.9516943e-04 7.5622280e-03 1.4811527e-05\n",
            " 6.8513520e-02 6.1390232e-08 1.8054182e-02]\n",
            "[1.0000000e+00 1.0528201e-02 1.1316574e-06 2.5060217e-04 3.8357881e-05\n",
            " 9.6402839e-02 7.2051951e-09 5.7162088e-03]\n",
            "[1.0000000e+00 8.8576171e-06 2.7498469e-01 2.8834267e-02 3.0709754e-05\n",
            " 3.9345282e-03 1.2863167e-07 4.7637886e-04]\n",
            "[1.0000000e+00 1.5748175e-02 3.4551249e-05 2.9361955e-04 3.2766004e-06\n",
            " 1.3057835e-03 1.8513271e-08 1.2166818e-02]\n",
            "[1.0000000e+00 6.8100167e-06 9.6874543e-02 3.3881193e-01 2.5049731e-05\n",
            " 4.0279673e-03 4.4532162e-06 5.2845897e-03]\n",
            "[1.00000000e+00 9.29709568e-05 1.82332680e-01 2.93991924e-03\n",
            " 4.45951355e-06 2.87812063e-03 1.15480304e-07 1.00432045e-03]\n",
            "[2.3283688e-03 4.9446149e-05 4.8521135e-04 7.7868055e-04 1.9526731e-05\n",
            " 9.5741119e-04 1.6122664e-08 5.4849154e-01]\n",
            "[1.0000000e+00 8.5601663e-05 6.3595162e-03 9.5502939e-04 9.2941540e-05\n",
            " 3.9453404e-03 4.5442619e-08 9.8373531e-04]\n",
            "[1.0000000e+00 1.6041116e-04 4.3231670e-05 1.9665705e-03 6.5108629e-06\n",
            " 1.1909517e-03 7.9995557e-09 4.9688227e-02]\n",
            "[1.0000000e+00 5.1396473e-06 3.8780924e-02 4.0890956e-03 6.8776980e-03\n",
            " 1.8016427e-03 3.1741448e-07 8.4314886e-03]\n",
            "[3.8585870e-04 1.3519393e-04 5.6441109e-05 1.7728368e-03 9.9055576e-01\n",
            " 1.3283980e-03 3.3506632e-07 5.2727573e-03]\n",
            "[1.0000000e+00 6.2227678e-03 6.4459769e-06 8.8072929e-04 1.0191961e-04\n",
            " 2.1920942e-02 1.1008180e-07 5.2001723e-03]\n",
            "[1.0000000e+00 1.5668867e-02 9.9384106e-06 7.8716395e-05 2.0393499e-04\n",
            " 8.2482696e-03 5.6955649e-08 4.5985375e-03]\n",
            "[1.0000000e+00 4.3311775e-05 5.0980961e-03 1.2847042e-04 2.3105952e-04\n",
            " 2.7638271e-03 1.4198591e-07 3.9775642e-03]\n",
            "[4.4994330e-04 3.4916031e-06 5.6441004e-05 4.5787323e-01 1.4349488e-03\n",
            " 1.6412596e-01 9.9998772e-01 1.2893012e-03]\n",
            "[1.0000000e+00 5.0368137e-05 4.6524969e-05 1.1613604e-03 6.5329834e-05\n",
            " 1.0121432e-03 5.3463518e-06 3.4814107e-03]\n",
            "[1.0000000e+00 1.6711393e-03 7.0223672e-07 3.3709155e-03 1.6913901e-04\n",
            " 5.2748690e-03 5.6809643e-07 1.0005357e-02]\n",
            "[1.0000000e+00 4.5849145e-03 1.2595665e-06 2.3947486e-03 4.1970070e-06\n",
            " 6.4839341e-02 2.6258267e-08 1.1345000e-01]\n",
            "[1.0000000e+00 9.7526908e-02 8.6575096e-07 2.3613071e-04 1.0964822e-05\n",
            " 3.5865226e-01 1.7005947e-08 1.0085566e-03]\n",
            "[1.0000000e+00 3.9361708e-05 3.6502078e-02 1.0348614e-02 8.3482238e-03\n",
            " 4.1358188e-02 2.7183020e-02 7.9457369e-03]\n",
            "[1.0000000e+00 4.3112137e-05 1.6855160e-02 1.8887538e-02 7.5744968e-03\n",
            " 1.3986574e-02 1.1870811e-02 9.9049760e-03]\n",
            "[1.0000000e+00 2.0632244e-04 1.8595951e-02 9.4209705e-03 1.1044112e-02\n",
            " 6.2775247e-02 4.1647729e-02 1.3833235e-03]\n",
            "[1.0000000e+00 3.7822896e-04 2.4119496e-02 1.8177968e-08 2.0784268e-02\n",
            " 1.6730273e-03 2.9958725e-02 6.7954476e-04]\n",
            "[1.0000000e+00 2.0149803e-04 1.6427048e-02 8.2287891e-04 3.6361730e-03\n",
            " 6.5492145e-03 2.9721169e-03 1.5241341e-02]\n",
            "[6.8806758e-04 9.8107946e-01 2.5238452e-04 1.8736022e-09 3.3448418e-03\n",
            " 5.7370581e-02 2.8469248e-04 6.0666013e-03]\n",
            "[1.0000000e+00 7.8264136e-05 9.1445241e-03 6.7596282e-03 2.7501505e-02\n",
            " 8.6227730e-02 8.8021167e-02 8.4591042e-03]\n",
            "[1.0000000e+00 7.2297356e-05 5.6314166e-04 1.2392416e-03 3.6229847e-03\n",
            " 3.4101938e-03 7.4362783e-03 4.6988213e-01]\n",
            "[1.0000000e+00 2.8585189e-04 1.7916192e-03 8.0015190e-02 3.1672856e-03\n",
            " 1.6479537e-02 1.7424421e-02 1.2281070e-02]\n",
            "[1.0000000e+00 6.7114399e-04 6.5690130e-02 7.3673560e-05 5.5208051e-04\n",
            " 1.6212285e-03 5.1867100e-04 4.3903254e-03]\n",
            "[1.0000000e+00 1.3316396e-05 2.1949789e-02 1.6533373e-02 4.1392399e-03\n",
            " 1.4095265e-02 4.2796351e-02 7.5268229e-03]\n",
            "[2.0806189e-03 3.2126918e-05 6.8718445e-01 8.6194043e-05 1.5735608e-03\n",
            " 2.2619690e-03 1.5255467e-03 7.8679975e-03]\n",
            "[1.0000000e+00 3.9768267e-05 9.1800429e-03 8.2851864e-02 1.0390311e-02\n",
            " 4.8861735e-02 2.4909835e-02 9.8645864e-03]\n",
            "[1.0000000e+00 3.9488473e-04 4.7658673e-03 2.2165425e-04 4.3301750e-02\n",
            " 2.0735687e-02 2.5625831e-02 1.3105210e-02]\n",
            "[1.0000000e+00 3.8542872e-04 9.5874281e-04 6.3766233e-06 3.2883536e-02\n",
            " 2.0903661e-03 5.8535254e-04 2.0318052e-02]\n",
            "[1.0000000e+00 9.0292699e-05 3.4755433e-03 1.6109183e-02 1.6413780e-02\n",
            " 2.0373046e-02 7.4140686e-03 2.0108571e-02]\n",
            "[1.0000000e+00 1.7637112e-03 2.2804607e-03 6.5525495e-07 3.1274389e-03\n",
            " 1.1849158e-02 6.6008465e-04 5.4909408e-02]\n",
            "[1.0000000e+00 7.4429947e-05 5.6679016e-03 9.6988060e-02 1.0926503e-02\n",
            " 3.4110103e-02 1.7783975e-02 9.9548353e-03]\n",
            "[1.0000000e+00 3.3321150e-04 5.9776055e-04 7.3588481e-08 4.9033454e-01\n",
            " 8.1530912e-04 8.8195375e-05 6.2677986e-03]\n",
            "[1.0000000e+00 3.8164650e-05 6.1240424e-03 3.1066872e-02 1.4807237e-02\n",
            " 4.5320727e-02 1.6665849e-01 1.8739577e-02]\n",
            "[5.6796479e-01 1.1581640e-03 2.1666659e-03 3.0830719e-08 7.3872261e-02\n",
            " 6.1717634e-03 4.5752891e-05 8.4701343e-04]\n",
            "[1.0000000e+00 3.9848790e-05 5.9651029e-03 1.3534132e-01 2.6972406e-02\n",
            " 6.9808185e-02 5.9178952e-02 1.1763112e-02]\n",
            "[1.0000000e+00 4.3577253e-05 6.4952695e-03 3.9489020e-02 3.0242965e-02\n",
            " 7.7518895e-02 7.3601201e-02 1.9807015e-02]\n",
            "[1.0000000e+00 3.5980749e-05 1.0062057e-02 1.2561426e-01 2.5689879e-02\n",
            " 8.8765539e-02 6.4727552e-02 9.1094282e-03]\n",
            "[1.0000000e+00 1.7646869e-04 1.7937418e-02 2.2678763e-05 1.4379783e-02\n",
            " 7.8288801e-03 1.8465018e-02 1.4292685e-03]\n",
            "[1.0000000e+00 3.4848668e-05 6.2889867e-03 1.0211637e-01 2.5194127e-02\n",
            " 6.9345124e-02 7.4384354e-02 1.4690190e-02]\n",
            "[1.0000000e+00 1.8889278e-04 1.3384700e-03 2.5080370e-03 1.1517240e-02\n",
            " 9.7393626e-03 8.7076565e-03 6.4249434e-02]\n",
            "[1.0000000e+00 1.2802986e-04 3.7414231e-03 4.1363858e-02 6.1040726e-03\n",
            " 2.8672859e-02 3.7914474e-02 1.6022684e-02]\n",
            "[1.0000000e+00 1.1805940e-02 3.1444931e-04 3.1696771e-08 5.3658034e-03\n",
            " 4.5944084e-03 1.2302445e-04 5.3316060e-02]\n",
            "[1.0000000e+00 9.8751596e-05 1.4254436e-03 2.2619376e-02 5.9324680e-03\n",
            " 1.1852265e-02 1.1790661e-02 7.2903469e-02]\n",
            "[1.0000000e+00 3.9658018e-05 4.9519832e-03 4.0993769e-02 2.6081860e-02\n",
            " 4.5955006e-02 5.2651912e-02 1.9934909e-02]\n",
            "[1.00000000e+00 2.89612926e-05 7.18660560e-03 1.18499205e-01\n",
            " 3.11732665e-02 8.77828225e-02 8.30440745e-02 1.10304030e-02]\n",
            "[1.00000000e+00 2.29676705e-04 2.07046440e-04 1.52683025e-02\n",
            " 1.00621926e-02 7.46341888e-03 6.75880071e-03 7.12686405e-02]\n",
            "[1.0000000e+00 1.0059453e-04 9.0916007e-04 5.9579365e-02 2.8617935e-02\n",
            " 2.6397131e-02 6.1893042e-02 8.2412036e-03]\n",
            "[1.0000000e+00 8.8801165e-04 2.0090627e-04 7.0414491e-05 3.5001351e-03\n",
            " 9.8498713e-04 3.8006292e-03 1.6429481e-01]\n",
            "[1.0000000e+00 5.7662877e-05 2.7729007e-03 6.0331933e-02 4.2606737e-02\n",
            " 4.4777911e-02 2.9565774e-02 2.7627079e-03]\n",
            "[1.0000000e+00 1.1622368e-03 2.2663860e-05 7.6267173e-07 2.3824017e-04\n",
            " 6.9443784e-05 2.1398539e-04 3.8861349e-01]\n",
            "[1.0000000e+00 2.6259411e-04 3.4936008e-03 5.7196780e-06 9.6138514e-04\n",
            " 2.7403384e-04 8.4361738e-05 5.8427821e-03]\n",
            "[1.0000000e+00 7.4189779e-04 2.0307764e-04 1.5425998e-04 2.4875763e-03\n",
            " 1.1610651e-03 6.4412616e-03 8.7023824e-03]\n",
            "[1.0000000e+00 1.7502360e-03 6.4271097e-03 1.9413806e-08 3.1554871e-03\n",
            " 6.2814611e-04 1.2796895e-04 4.2276926e-04]\n",
            "[1.0000000e+00 2.1130621e-04 1.6535410e-03 4.7054090e-02 6.7257858e-03\n",
            " 2.6464419e-02 3.5162836e-02 2.9744299e-03]\n",
            "[1.0000000e+00 1.0644251e-01 3.0151554e-04 1.7081561e-06 1.7042950e-03\n",
            " 3.8972939e-03 2.4237607e-03 5.8382814e-04]\n",
            "[1.0000000e+00 1.3447332e-04 1.7739041e-03 1.5795431e-03 1.1542755e-02\n",
            " 1.0466811e-02 1.0592924e-02 7.6910434e-03]\n",
            "[1.00000000e+00 2.89936670e-05 1.36402445e-02 4.86648344e-02\n",
            " 2.11485438e-02 2.29847897e-02 1.85287744e-02 6.00221916e-04]\n",
            "[1.0000000e+00 3.0969150e-05 1.0286450e-02 1.2606157e-01 6.8042837e-02\n",
            " 5.3558726e-02 4.4376671e-02 9.5669541e-04]\n",
            "[1.0000000e+00 1.7975445e-04 8.9532346e-04 4.1131204e-07 8.5257655e-03\n",
            " 2.5939588e-03 7.9745138e-03 1.0730851e-02]\n",
            "[1.0000000e+00 4.1694573e-05 6.6048410e-03 7.5121835e-02 3.8500275e-02\n",
            " 6.4214826e-02 9.2255458e-02 2.5237701e-03]\n",
            "[1.00000000e+00 4.17607152e-05 1.20228678e-02 1.29134387e-01\n",
            " 7.71997944e-02 9.85749811e-02 1.12742975e-01 1.69685087e-03]\n",
            "[1.0000000e+00 8.6257824e-05 2.0432258e-02 9.2456033e-03 4.1523721e-02\n",
            " 5.3464726e-02 3.4984145e-02 2.3387917e-03]\n",
            "[1.0000000e+00 2.4201781e-04 3.4471874e-03 4.2392281e-03 5.6446049e-02\n",
            " 4.3104712e-02 4.8995920e-02 4.6852669e-03]\n",
            "[1.0000000e+00 7.9495047e-05 1.9533464e-03 1.4829996e-02 2.6107743e-02\n",
            " 2.8749399e-02 6.0088839e-02 1.3432383e-02]\n",
            "[7.1729541e-05 8.6947465e-01 3.2313759e-04 3.2903566e-10 1.1762367e-01\n",
            " 9.5657515e-04 6.8413341e-05 2.2073521e-03]\n",
            "[1.0000000e+00 5.5201952e-05 2.6355507e-03 3.6262095e-02 6.3329555e-02\n",
            " 6.4951465e-02 7.7296443e-02 1.8016105e-03]\n",
            "[1.0000000e+00 4.0425646e-05 3.6181984e-03 1.3721424e-01 1.0387423e-01\n",
            " 7.5266130e-02 8.0988280e-02 1.7248803e-03]\n",
            "[1.0000000e+00 5.5645731e-05 2.5705972e-03 3.8068946e-02 6.2227119e-02\n",
            " 6.4872675e-02 7.5717457e-02 1.7755213e-03]\n",
            "[1.0000000e+00 3.9107923e-05 3.8711850e-03 1.4470905e-01 1.1302160e-01\n",
            " 8.3063215e-02 9.0236716e-02 1.6438179e-03]\n",
            "[1.0000000e+00 2.9016945e-03 1.0855356e-04 2.4794786e-10 4.3400074e-03\n",
            " 7.4116013e-04 1.8549124e-05 8.5991517e-02]\n",
            "[1.00000000e+00 2.03837524e-04 9.70773282e-04 3.53046209e-02\n",
            " 8.34682863e-03 1.48837315e-02 2.50288974e-02 8.58066883e-03]\n",
            "[1.0000000e+00 8.8494327e-03 3.0116220e-03 2.9370457e-09 3.4026084e-03\n",
            " 3.7002810e-03 4.7584766e-05 1.9352713e-03]\n",
            "[1.0000000e+00 1.6625584e-04 2.4789855e-02 1.7097063e-02 5.9560861e-02\n",
            " 1.9746684e-01 7.3423453e-02 4.2747988e-04]\n",
            "[1.0000000e+00 1.0328628e-03 4.2936385e-02 8.0053664e-10 7.6601631e-03\n",
            " 1.8972052e-03 5.0756622e-05 4.4690716e-04]\n",
            "[1.0000000e+00 2.8196201e-03 4.0670199e-04 2.6418052e-09 1.9001365e-03\n",
            " 1.3011704e-03 4.2241434e-05 6.4323004e-03]\n",
            "[4.3438679e-01 3.1768455e-04 8.2707256e-01 8.8259428e-11 6.6637102e-04\n",
            " 7.3112184e-05 2.7194190e-05 3.5028919e-04]\n",
            "[1.00000000e+00 1.33145158e-03 4.36921749e-04 1.13150884e-10\n",
            " 4.94960230e-03 9.95664974e-04 4.13742709e-05 1.88319474e-01]\n",
            "[1.4045872e-04 2.9541864e-06 2.6606370e-03 6.0783811e-02 1.9719454e-02\n",
            " 3.0359745e-03 9.9752480e-01 6.6188036e-04]\n",
            "[1.0000000e+00 3.5221083e-06 1.3096289e-01 1.4951763e-03 1.5080353e-03\n",
            " 3.9357390e-05 2.6257636e-05 1.1737325e-03]\n",
            "[4.6192295e-06 1.4385012e-02 1.8644223e-06 7.1816350e-04 6.1865069e-04\n",
            " 1.2601471e-03 9.5066298e-06 6.7817312e-01]\n",
            "[1.0000000e+00 5.4492033e-03 5.3577922e-05 3.7135851e-02 9.7127224e-04\n",
            " 1.4912020e-03 3.8713433e-06 8.9735789e-03]\n",
            "[1.0000000e+00 9.3331176e-04 2.3546749e-05 6.1190198e-04 1.8070315e-03\n",
            " 1.2231931e-04 1.2235386e-06 9.1698114e-04]\n",
            "[1.0000000e+00 9.8365033e-04 2.1865419e-05 3.8077304e-04 1.7683633e-01\n",
            " 7.4332841e-03 6.3744083e-06 1.8420446e-03]\n",
            "[1.0000000e+00 7.5376453e-04 4.9482314e-06 3.8206231e-04 2.7912391e-02\n",
            " 1.1284709e-03 2.2911382e-07 2.6477159e-03]\n",
            "[1.00000000e+00 5.23554441e-03 5.69426584e-06 1.06537496e-04\n",
            " 1.98483351e-03 2.11204955e-04 2.13531493e-07 2.65611714e-04]\n",
            "[1.0000000e+00 5.1368633e-03 4.0179475e-05 1.3163187e-05 8.9988336e-03\n",
            " 4.6291068e-04 1.6486413e-06 2.7828692e-02]\n",
            "[1.0000000e+00 1.0764397e-02 6.1382701e-07 2.4669280e-05 1.4341526e-02\n",
            " 2.8326322e-04 1.6985327e-07 5.0458934e-02]\n",
            "[1.0000000e+00 6.8345811e-04 1.2004811e-05 6.6461088e-04 4.7780063e-02\n",
            " 9.6482463e-04 1.1164264e-05 3.4477853e-03]\n",
            "[1.0000000e+00 8.1178063e-04 1.5714945e-06 5.9458664e-05 1.8392722e-01\n",
            " 6.8261557e-05 6.2654306e-07 3.1968511e-03]\n",
            "[1.3191227e-03 2.8112223e-03 9.8582996e-06 7.5107947e-04 1.7884554e-02\n",
            " 9.0180314e-01 7.6616871e-06 1.8786669e-03]\n",
            "[1.0000000e+00 5.4152058e-03 4.1418552e-05 2.5808353e-03 1.3827528e-02\n",
            " 7.5132206e-02 1.6934089e-05 1.3319070e-03]\n",
            "[1.0000000e+00 7.3637348e-03 3.8431021e-06 4.5568850e-03 1.5447857e-03\n",
            " 1.5862534e-03 7.4663279e-07 1.5880013e-02]\n",
            "[1.0000000e+00 1.3414727e-02 3.9169054e-06 2.5882418e-03 6.5614481e-04\n",
            " 2.2429263e-04 2.9417731e-07 1.5476013e-02]\n",
            "[1.0000000e+00 2.5132732e-04 9.3654060e-05 1.8266623e-04 8.9364452e-04\n",
            " 1.3307997e-04 4.4715949e-07 3.1578050e-03]\n",
            "[1.0000000e+00 5.8754429e-04 5.8535461e-06 7.2421357e-03 3.1037363e-01\n",
            " 1.3506241e-04 2.9612047e-06 6.0604475e-03]\n",
            "[1.5384235e-04 1.0325194e-05 2.7276752e-05 7.6487094e-01 5.1667211e-03\n",
            " 5.4632977e-04 2.3220920e-03 2.3440611e-02]\n",
            "[1.2365868e-02 1.2749835e-04 7.8222179e-01 9.1211565e-05 3.0317775e-04\n",
            " 9.8798173e-06 3.0244425e-06 3.2563687e-05]\n",
            "[1.0000000e+00 2.0302240e-02 1.0744779e-05 9.3871451e-05 7.8325090e-04\n",
            " 8.8773129e-05 1.8382900e-07 3.8125487e-03]\n",
            "[3.7694885e-05 8.5903144e-01 3.9733604e-07 1.3583305e-04 3.6481339e-03\n",
            " 1.9945708e-04 2.9451024e-07 2.4560023e-02]\n",
            "[1.00000000e+00 3.52020129e-06 1.28646920e-04 1.02590755e-01\n",
            " 1.33190211e-02 1.08131149e-04 4.88029982e-05 4.44910768e-03]\n",
            "[1.00000000e+00 3.60316684e-04 1.79524668e-05 9.55441967e-03\n",
            " 1.29384762e-02 4.82817122e-04 1.57731779e-06 1.47355115e-02]\n",
            "[1.0000000e+00 7.5176591e-04 2.5257687e-05 5.1626150e-04 3.8548779e-02\n",
            " 8.8456774e-04 2.5799875e-06 2.9380861e-04]\n",
            "[1.0000000e+00 8.4990719e-03 8.4543649e-07 2.8852561e-05 4.6792449e-03\n",
            " 4.2509835e-04 8.9818190e-07 4.9817450e-02]\n",
            "[1.0000000e+00 1.1367305e-02 1.4679334e-06 2.0667592e-04 5.9334207e-02\n",
            " 6.5521873e-04 1.9783299e-06 4.9669348e-02]\n",
            "[1.0000000e+00 1.1539308e-02 7.6381411e-06 1.3537848e-04 2.2893794e-02\n",
            " 4.5377668e-04 1.8117724e-07 2.6145540e-04]\n",
            "[1.0000000e+00 9.9209026e-03 4.8503216e-06 7.6761888e-04 3.8713487e-03\n",
            " 4.9755652e-04 1.3564315e-06 3.2589457e-03]\n",
            "[1.0000000e+00 3.0453373e-03 1.0807025e-03 2.0112898e-04 1.8796964e-03\n",
            " 8.8091110e-05 9.7031364e-07 4.1853133e-04]\n",
            "[1.0000000e+00 4.5976292e-05 2.2666954e-02 4.3223513e-04 6.8115460e-04\n",
            " 4.1883817e-05 7.4159578e-07 5.4448558e-04]\n",
            "[1.0000000e+00 7.7975528e-06 5.9857544e-02 9.6770927e-05 3.6706153e-04\n",
            " 3.1395223e-06 1.9430104e-07 1.3338212e-03]\n",
            "[1.0000000e+00 7.5855164e-04 7.5781468e-04 2.1119689e-04 7.1542262e-04\n",
            " 1.4176155e-02 2.7499775e-07 7.6202643e-03]\n",
            "[1.0000000e+00 5.5833120e-04 7.9717423e-04 2.1458986e-04 5.2624929e-04\n",
            " 1.4358274e-02 3.3097058e-07 1.3312346e-02]\n",
            "[1.0000000e+00 1.1755307e-03 5.2246219e-04 7.2068430e-04 3.8619976e-02\n",
            " 1.9518029e-03 1.4036902e-05 1.2038678e-01]\n",
            "[1.0000000e+00 1.5523466e-02 4.6592178e-03 4.9143162e-04 2.9231084e-03\n",
            " 8.6826952e-03 1.0128984e-04 8.8974182e-04]\n",
            "[1.0000000e+00 1.7102281e-02 7.4917879e-03 3.0256842e-05 2.7713291e-03\n",
            " 2.4800450e-02 4.6791189e-07 2.6505315e-04]\n",
            "[7.4248084e-05 8.2942456e-01 1.0345590e-03 5.9570990e-05 1.0928271e-03\n",
            " 1.4018813e-03 3.6832753e-07 6.2534923e-04]\n",
            "[1.0000000e+00 3.5447920e-05 1.3773721e-01 7.6529123e-03 4.0992391e-03\n",
            " 4.0316526e-03 8.2846636e-06 2.1778834e-03]\n",
            "[1.0000000e+00 8.8820234e-06 9.5845439e-02 1.0682844e-02 8.1867231e-03\n",
            " 3.7490360e-03 2.7500879e-05 1.0315838e-03]\n",
            "[1.0000000e+00 1.3588291e-03 2.6651847e-04 3.4375643e-04 4.9386290e-03\n",
            " 5.0929831e-03 6.5271030e-05 1.4550473e-01]\n",
            "[4.9203667e-05 6.0553502e-06 2.5396951e-02 7.3680490e-01 4.0771537e-02\n",
            " 3.3278961e-02 9.9896067e-01 1.7764926e-03]\n",
            "[1.0000000e+00 2.6346904e-03 1.0199228e-03 5.6538058e-05 2.0174910e-03\n",
            " 1.7683556e-03 7.4186761e-07 3.1944192e-03]\n",
            "[1.00000000e+00 1.12724025e-02 4.69170744e-03 7.72467538e-05\n",
            " 3.74339492e-04 4.88686492e-04 3.69588975e-07 1.30085181e-03]\n",
            "[1.0000000e+00 6.9109313e-03 3.7521203e-03 2.1060517e-04 7.4027351e-04\n",
            " 4.4163908e-03 1.5668729e-06 8.9928722e-03]\n",
            "[1.4760497e-03 4.3104188e-05 7.5534908e-03 1.0464356e-03 1.2093402e-03\n",
            " 2.9022403e-03 5.4554844e-06 5.4578382e-01]\n",
            "[1.0000000e+00 6.7054338e-05 8.1584835e-03 9.1759572e-03 1.3402776e-02\n",
            " 1.2871489e-02 9.3957879e-06 5.0286404e-03]\n",
            "[1.0000000e+00 2.7881242e-05 1.7031886e-02 1.4821659e-01 1.3417239e-01\n",
            " 4.7966257e-02 1.0029153e-04 2.2279255e-03]\n",
            "[1.1107528e-03 3.2439522e-05 1.2164431e-03 2.7089319e-04 6.8196386e-01\n",
            " 6.2833773e-03 3.2290665e-04 1.7318120e-02]\n",
            "[1.0000000e+00 1.2446719e-04 4.4130053e-02 4.5215414e-04 3.4516603e-03\n",
            " 7.4572633e-03 6.3539196e-06 3.2714095e-02]\n",
            "[2.8500848e-03 2.7660008e-03 7.6640176e-04 7.5753214e-04 5.8804685e-04\n",
            " 6.8737608e-01 1.5691833e-06 2.2737186e-03]\n",
            "[1.0000000e+00 8.2366988e-02 3.2625513e-04 1.5140430e-04 6.3280435e-04\n",
            " 5.7536565e-02 4.8739145e-07 1.6878997e-03]\n",
            "[1.0000000e+00 1.1349231e-02 6.8379296e-03 3.1084388e-03 2.1667185e-03\n",
            " 5.9318789e-03 3.7246213e-05 4.3818899e-04]\n",
            "[1.0000000e+00 5.3721567e-04 1.3978641e-02 2.5675623e-04 3.7996154e-03\n",
            " 2.3712257e-03 3.6722324e-06 2.8444340e-03]\n",
            "[1.0000000e+00 1.4417985e-06 7.7269956e-02 6.8449103e-03 4.8016933e-05\n",
            " 1.1528740e-04 2.6790533e-06 2.3374137e-02]\n",
            "[1.0000000e+00 7.4090954e-04 1.5254524e-02 7.7355122e-05 2.3534786e-04\n",
            " 3.4214315e-04 2.2598576e-07 2.4124980e-03]\n",
            "[1.0000000e+00 3.2217729e-05 6.1194915e-02 4.5297295e-02 1.2287132e-02\n",
            " 8.1834560e-03 1.4613911e-05 7.6558986e-03]\n",
            "[1.0000000e+00 4.0698913e-05 7.7796862e-02 2.5044316e-02 2.7531726e-02\n",
            " 2.6186628e-02 3.1210689e-04 1.8761747e-03]\n",
            "[1.0000000e+00 2.5448117e-05 2.7582519e-02 4.4921064e-05 1.8809971e-03\n",
            " 4.8089775e-04 1.4057839e-07 1.2339393e-02]\n",
            "[1.0000000e+00 6.3807046e-04 1.3544783e-03 3.2812983e-04 1.0518634e-03\n",
            " 7.1875881e-03 2.8047725e-07 4.8087272e-03]\n",
            "[1.0000000e+00 4.9718455e-03 2.1195163e-03 1.0772972e-04 2.3093475e-03\n",
            " 1.8686770e-03 2.5984446e-07 5.1324768e-04]\n",
            "[1.0000000e+00 8.8496841e-03 2.5247471e-04 1.8138287e-04 4.4234749e-03\n",
            " 1.6077355e-03 3.5128099e-07 2.6503208e-03]\n",
            "[1.0000000e+00 1.8971181e-04 1.4705339e-02 5.0606567e-04 3.6140898e-04\n",
            " 4.5600818e-03 2.8653224e-07 2.6564380e-02]\n",
            "[1.0000000e+00 4.2565909e-04 3.3849692e-01 5.7520409e-04 7.0630125e-04\n",
            " 5.7378242e-04 4.9582610e-07 4.1003191e-04]\n",
            "[1.0000000e+00 3.2054719e-02 5.2403288e-07 2.7342946e-03 2.5518332e-03\n",
            " 3.1318024e-03 7.9126179e-04 1.8475308e-03]\n",
            "[1.0000000e+00 1.8178236e-01 5.1783985e-07 5.8202393e-04 1.9045154e-03\n",
            " 8.5424893e-03 4.0632897e-04 1.5961494e-03]\n",
            "[1.0000000e+00 8.2986080e-04 4.9582254e-06 1.5696203e-02 5.8711502e-03\n",
            " 1.7698245e-02 3.5948511e-03 3.4179925e-03]\n",
            "[1.0000000e+00 2.4939230e-02 4.2900797e-07 2.0343792e-03 2.5941057e-02\n",
            " 2.4284222e-03 1.0355215e-03 1.1852878e-03]\n",
            "[1.0000000e+00 3.7224675e-04 1.7821511e-06 3.3688016e-02 1.2469705e-03\n",
            " 1.6911644e-02 1.3105856e-03 1.3328211e-01]\n",
            "[1.0000000e+00 1.0596270e-04 2.0601900e-07 5.2095349e-03 7.2331624e-03\n",
            " 3.6502060e-01 7.7081188e-03 8.3432056e-02]\n",
            "[1.0000000e+00 1.7670881e-02 2.2832513e-07 4.1034239e-04 1.6812242e-03\n",
            " 3.0822780e-02 1.6646861e-03 8.3147055e-03]\n",
            "[1.00000000e+00 4.95548127e-03 1.03737841e-06 5.44394832e-03\n",
            " 2.36532348e-03 1.03473604e-01 8.88240337e-03 1.25113539e-02]\n",
            "[1.0000000e+00 2.7164390e-02 8.7003252e-07 3.6703469e-03 1.1186559e-03\n",
            " 1.7873219e-01 7.3679473e-04 1.8063264e-03]\n",
            "[1.0000000e+00 1.7090721e-01 1.5150935e-06 5.4797381e-03 1.9653111e-04\n",
            " 3.1668521e-02 4.6075875e-04 6.7457010e-04]\n",
            "[1.0000000e+00 1.0949118e-03 5.3142754e-05 2.0645397e-02 2.0692166e-04\n",
            " 1.4724618e-02 5.1011001e-03 7.3163508e-04]\n",
            "[1.0000000e+00 2.1165042e-04 5.0278911e-03 4.7610197e-03 1.5644653e-04\n",
            " 2.7106255e-03 1.9637106e-03 4.2676469e-04]\n",
            "[1.00000000e+00 1.73290864e-01 2.80061585e-07 2.41022836e-03\n",
            " 2.40000343e-04 5.67531697e-02 1.07404434e-04 3.36503057e-04]\n",
            "[4.1444153e-03 2.4479587e-04 2.4143966e-07 2.8869143e-02 2.4117529e-02\n",
            " 1.6304628e-03 7.5728631e-01 1.2808596e-02]\n",
            "[1.0000000e+00 1.2759438e-04 5.0465801e-06 2.5621086e-02 2.8176737e-04\n",
            " 9.0628015e-03 6.7664692e-03 7.8407213e-02]\n",
            "[1.0000000e+00 2.5481472e-04 2.4628198e-05 1.5384671e-02 1.2397143e-04\n",
            " 4.2859828e-03 9.9064484e-03 2.3614971e-02]\n",
            "[1.0000000e+00 2.3726723e-03 7.1823635e-08 3.5186638e-03 2.8062537e-02\n",
            " 2.2398573e-03 5.5417772e-03 3.2343086e-02]\n",
            "[4.1276417e-03 7.4554677e-04 1.8677540e-07 1.1796776e-02 7.3159063e-01\n",
            " 1.1560351e-03 1.2820587e-03 1.4795584e-02]\n",
            "[1.0000000e+00 1.5419896e-02 2.7937122e-07 9.9425670e-03 1.0522096e-03\n",
            " 3.9951273e-04 5.1112362e-04 1.4269721e-02]\n",
            "[1.0000000e+00 5.5060115e-02 1.1222555e-06 1.2365780e-03 3.4715669e-04\n",
            " 2.7087536e-03 7.0889905e-04 2.5862787e-02]\n",
            "[1.0000000e+00 6.1719737e-04 1.7567918e-06 8.1504714e-03 7.7582747e-03\n",
            " 5.1761768e-04 8.3649538e-02 1.6682751e-03]\n",
            "[1.0000000e+00 1.1137064e-04 1.7854718e-06 3.3733070e-02 4.8067868e-03\n",
            " 2.4948756e-03 3.8538501e-02 1.3334273e-02]\n",
            "[1.0000000e+00 1.5087329e-01 2.2599242e-07 8.7441248e-04 4.4665587e-04\n",
            " 3.6637986e-03 4.2171861e-04 3.4407567e-04]\n",
            "[1.0000000e+00 2.2445306e-02 3.5379509e-07 3.3419763e-04 1.1648665e-03\n",
            " 7.3553226e-04 8.0258069e-05 1.8384957e-03]\n",
            "[1.4706049e-02 4.6694208e-06 9.9295682e-01 1.4137943e-01 1.7886172e-04\n",
            " 1.0369769e-03 1.9596698e-02 7.7495810e-05]\n",
            "[1.0000000e+00 2.5073264e-04 1.8998848e-03 1.2874721e-01 5.1021914e-04\n",
            " 2.0471640e-02 8.3569605e-03 1.1192298e-04]\n",
            "[1.0000000e+00 4.1240342e-02 1.2357923e-06 1.9656792e-02 5.4000672e-03\n",
            " 9.0558425e-02 6.2119262e-03 4.6453341e-03]\n",
            "[5.3135725e-04 2.6926249e-03 3.3001163e-06 1.6153315e-02 5.8597192e-04\n",
            " 4.4718669e-03 1.4991186e-03 5.0755239e-01]\n",
            "[1.0000000e+00 2.7705471e-03 2.7041137e-06 4.2342541e-01 2.4636625e-03\n",
            " 4.0162718e-03 1.4100192e-02 8.0497749e-03]\n",
            "[1.0000000e+00 7.8749172e-03 6.4535975e-06 2.0241398e-02 1.5750869e-04\n",
            " 3.6247245e-03 9.9463547e-03 7.8596920e-04]\n",
            "[1.0000000e+00 2.3051426e-02 1.8603002e-07 2.0849442e-03 1.3631296e-01\n",
            " 2.3625256e-03 1.0042861e-03 2.7475450e-03]\n",
            "[1.0000000e+00 3.8462359e-02 3.4106429e-07 6.0843751e-03 3.9245845e-03\n",
            " 1.1943633e-02 8.2786038e-04 7.1795322e-03]\n",
            "[1.00000000e+00 7.69501494e-05 1.16055635e-04 5.94696682e-03\n",
            " 7.71318143e-03 1.93702150e-03 2.42147788e-01 1.58329736e-02]\n",
            "[7.8464689e-04 5.5077404e-04 9.0198744e-05 1.1239684e-04 8.7301284e-03\n",
            " 1.0603217e-03 4.2758679e-06 9.1598666e-01]\n",
            "[7.8742584e-04 4.5313567e-02 3.9332230e-05 1.9404438e-03 1.4028265e-03\n",
            " 5.8468950e-01 2.4570255e-07 3.8548463e-03]\n",
            "[1.0000000e+00 4.3597454e-03 1.6195088e-04 5.7900520e-03 3.1359664e-03\n",
            " 6.3046124e-03 2.3452972e-07 8.5265178e-04]\n",
            "[1.00000000e+00 1.11866025e-02 9.35146236e-05 2.88586738e-03\n",
            " 1.04133040e-02 2.15378101e-03 1.82392043e-07 9.24969849e-04]\n",
            "[1.0000000e+00 3.0277399e-02 5.7693291e-05 6.7330373e-04 8.7904431e-02\n",
            " 2.7211935e-03 1.1571419e-07 6.5291341e-04]\n",
            "[1.2299793e-02 5.2081883e-01 6.1439321e-05 2.2753200e-04 7.7571394e-04\n",
            " 1.0779594e-02 9.1154938e-08 3.1605017e-04]\n",
            "[1.0000000e+00 7.4820663e-04 2.3045667e-04 6.5330975e-03 1.2373298e-02\n",
            " 4.2121846e-02 2.7537723e-07 6.8687135e-04]\n",
            "[1.0000000e+00 7.6911889e-04 6.1483402e-04 3.4856349e-02 9.7267944e-03\n",
            " 1.9698925e-03 2.2156312e-06 2.1283214e-04]\n",
            "[1.00000000e+00 1.38134055e-04 1.74037821e-04 4.08179425e-02\n",
            " 1.01119734e-01 9.17472318e-03 4.05718834e-04 4.55339113e-03]\n",
            "[1.0000000e+00 5.2989018e-04 3.3184765e-03 2.2247627e-03 3.2261489e-03\n",
            " 1.4848827e-03 1.3828343e-06 1.1517613e-03]\n",
            "[1.0000000e+00 6.1855931e-04 3.9702081e-03 3.0807736e-03 4.7452687e-03\n",
            " 9.2285994e-04 3.7944946e-07 2.3608999e-03]\n",
            "[4.9694729e-05 5.0798797e-05 1.3965813e-02 6.7554750e-02 3.0888114e-02\n",
            " 5.5412393e-02 7.5617009e-01 2.4184941e-04]\n",
            "[9.14132281e-04 3.06467155e-05 5.25007963e-01 7.66984792e-03\n",
            " 1.19860545e-02 2.33373488e-03 3.86198546e-04 2.72426551e-04]\n",
            "[1.0000000e+00 5.7053603e-03 1.6505596e-04 1.8402826e-03 5.6583970e-03\n",
            " 1.8053282e-02 2.5009621e-07 5.2684601e-03]\n",
            "[1.0000000e+00 5.9255879e-02 3.3567514e-05 1.6598888e-04 2.4184340e-03\n",
            " 3.3424138e-03 4.7351254e-08 1.5220519e-03]\n",
            "[1.0000000e+00 3.4730550e-02 3.3390570e-05 9.8819938e-04 9.2444774e-03\n",
            " 2.0485828e-02 3.4690988e-08 4.3714760e-04]\n",
            "[1.0000000e+00 7.9542115e-02 1.2986935e-04 3.6691260e-04 8.4581181e-02\n",
            " 2.3860014e-03 1.1193124e-07 2.8117295e-04]\n",
            "[1.0000000e+00 9.8149956e-04 3.6290867e-04 1.4288845e-03 7.4188469e-04\n",
            " 1.7301727e-03 1.8455672e-06 7.2009214e-03]\n",
            "[1.0000000e+00 4.7314907e-03 1.2971914e-03 1.4581189e-04 9.6212782e-04\n",
            " 2.4774668e-03 5.8690750e-07 2.9714487e-03]\n",
            "[1.0000000e+00 8.4936200e-03 1.9527760e-03 5.9593748e-04 1.5683622e-03\n",
            " 9.6852786e-04 1.2959585e-07 3.0438919e-04]\n",
            "[1.0000000e+00 2.4202834e-03 5.5030696e-03 1.6252863e-03 2.3494067e-03\n",
            " 1.7403343e-04 5.0262582e-08 9.2392601e-04]\n",
            "[1.0000000e+00 4.3684544e-04 3.3051163e-01 2.0762362e-01 2.5557571e-03\n",
            " 6.2751598e-03 2.0582447e-06 1.3104457e-04]\n",
            "[1.0000000e+00 3.4333658e-05 1.0272471e-01 6.5703742e-02 1.5246350e-02\n",
            " 1.2250919e-03 2.1547019e-05 2.0894741e-04]\n",
            "[1.0000000e+00 2.9481305e-02 2.8086136e-04 6.1449874e-03 9.3209062e-04\n",
            " 1.0025061e-03 4.1536310e-08 5.4430519e-03]\n",
            "[1.0000000e+00 1.7073920e-03 8.3768545e-03 4.8354189e-04 8.1490504e-04\n",
            " 6.5862684e-04 9.2847372e-08 2.5584628e-03]\n",
            "[1.0000000e+00 9.5282696e-02 9.6246913e-05 3.0445142e-04 6.6991621e-03\n",
            " 3.5209691e-03 2.8202109e-07 2.3218295e-04]\n",
            "[1.0000000e+00 3.1789489e-02 6.1435276e-05 6.2273080e-05 4.4177612e-03\n",
            " 2.6650154e-03 7.5808806e-08 1.5778226e-03]\n",
            "[1.7740929e-03 3.2334428e-03 1.2253536e-04 1.3272957e-03 5.3808242e-01\n",
            " 6.0498640e-02 4.3405961e-07 2.6644683e-03]\n",
            "[1.0000000e+00 1.8904964e-02 1.7056293e-04 1.9746739e-03 2.2595566e-02\n",
            " 1.4365256e-01 5.3930955e-07 1.2357378e-03]\n",
            "[1.0000000e+00 2.4330765e-03 4.7234607e-05 1.0112022e-02 4.1987984e-03\n",
            " 2.6288703e-03 3.5832607e-04 1.8710984e-02]\n",
            "[1.2504750e-05 5.3664334e-03 2.2812362e-04 5.1879203e-01 2.7919791e-03\n",
            " 5.1884716e-03 4.9436028e-04 4.2668401e-04]\n",
            "[1.00000000e+00 8.43833041e-05 7.26036076e-03 1.19491786e-01\n",
            " 4.91438725e-04 1.39268290e-03 1.73915073e-03 2.17163833e-04]\n",
            "[1.0000000e+00 6.6540844e-05 7.3842942e-03 4.4045052e-01 2.1362032e-03\n",
            " 5.4865363e-03 4.8387623e-03 6.1118495e-05]\n",
            "[1.0000000e+00 1.1098834e-01 6.0237295e-07 6.3693238e-04 3.5010530e-03\n",
            " 1.5726147e-03 2.4650435e-04 4.2860265e-04]\n",
            "[1.0000000e+00 1.1490130e-02 4.7694675e-07 3.5368381e-03 6.2675290e-03\n",
            " 2.2898631e-03 1.3078925e-03 1.9268258e-04]\n",
            "[6.7802094e-04 6.4499379e-04 4.7111893e-08 7.7727373e-04 5.1523671e-02\n",
            " 3.2312563e-04 2.3760493e-03 8.4542930e-01]\n",
            "[1.0000000e+00 2.3707720e-02 5.4570862e-08 3.9279817e-05 1.3126521e-02\n",
            " 1.1673947e-03 3.4018443e-04 6.4609893e-02]\n",
            "[1.0000000e+00 4.5022886e-04 8.9255718e-06 8.6136619e-03 4.2438689e-01\n",
            " 6.1710202e-03 2.6743919e-02 3.0238184e-03]\n",
            "[1.0000000e+00 5.1525058e-03 1.3216940e-07 9.5015705e-05 5.6410688e-03\n",
            " 1.3314532e-03 7.8487769e-03 9.9018393e-03]\n",
            "[1.0000000e+00 1.3149099e-01 2.3127502e-06 1.2136509e-03 2.1786185e-03\n",
            " 1.1013070e-02 1.7882815e-04 1.5332473e-04]\n",
            "[1.0000000e+00 4.6626450e-03 3.6854399e-05 2.4767892e-02 3.2630836e-04\n",
            " 1.1026078e-03 1.1723683e-03 3.4410466e-04]\n",
            "[9.4030023e-04 1.7845614e-05 6.9093704e-01 1.3354443e-01 2.7601924e-03\n",
            " 1.9905936e-02 6.3904017e-01 2.7112481e-05]\n",
            "[1.0000000e+00 6.6298620e-05 1.1118956e-02 6.5381113e-03 4.0062502e-04\n",
            " 2.0627251e-04 6.3678466e-02 5.2249161e-05]\n",
            "[1.0000000e+00 8.9259492e-03 2.7768147e-06 4.1883603e-02 1.1458727e-02\n",
            " 1.8718453e-02 8.4202401e-02 1.3230508e-04]\n",
            "[1.0000000e+00 1.2064652e-02 8.7390765e-07 1.1847192e-02 9.4133981e-02\n",
            " 5.5191588e-02 1.3577913e-02 1.7730516e-04]\n",
            "[5.9543150e-03 2.2744494e-02 1.0899626e-05 1.9396454e-03 6.6241209e-04\n",
            " 5.1533866e-01 1.0096254e-03 3.6764718e-04]\n",
            "[1.0000000e+00 2.3952855e-03 1.1257363e-02 9.1902418e-03 1.9182304e-03\n",
            " 1.6692853e-02 1.2258150e-02 1.5073267e-05]\n",
            "[1.0000000e+00 7.5760979e-04 2.4283318e-06 4.3162750e-03 9.3632862e-03\n",
            " 4.4141933e-03 4.0364671e-03 9.3537355e-03]\n",
            "[1.0000000e+00 3.5482463e-01 1.5211039e-07 2.5667530e-04 3.0523743e-03\n",
            " 2.3829504e-03 1.1092500e-03 7.9755532e-03]\n",
            "[1.0000000e+00 1.4988685e-03 5.7263645e-05 6.2903147e-03 1.1406977e-03\n",
            " 5.0346372e-03 1.2270740e-03 6.8940781e-04]\n",
            "[1.0000000e+00 4.3550394e-03 4.3450673e-06 2.3476219e-02 3.1073880e-04\n",
            " 1.1283036e-02 3.7626483e-04 1.6763271e-03]\n",
            "[1.0000000e+00 1.7462505e-04 1.5510984e-04 7.9833262e-02 4.1638371e-03\n",
            " 1.3031715e-03 1.7868582e-02 2.1535490e-04]\n",
            "[1.0000000e+00 1.6485045e-04 1.0813428e-04 1.5627472e-02 3.7112779e-03\n",
            " 1.6838611e-03 8.4293313e-02 8.7972835e-04]\n",
            "[1.0000000e+00 1.5526119e-04 2.1554089e-05 2.4575688e-02 6.9461353e-03\n",
            " 1.7107411e-01 7.9393545e-03 5.2182064e-03]\n",
            "[1.0000000e+00 1.0845106e-03 2.7856486e-05 3.4080588e-03 2.4854825e-03\n",
            " 7.6895535e-02 2.7732719e-03 8.7649720e-03]\n",
            "[1.0000000e+00 4.8422795e-03 3.1099785e-07 2.3132567e-03 2.0731579e-01\n",
            " 8.1471065e-03 1.6818547e-03 1.2093053e-02]\n",
            "[1.0000000e+00 9.0640634e-03 3.0895748e-07 4.3777263e-04 1.2771357e-02\n",
            " 2.3064895e-03 3.9101814e-04 5.7746097e-03]\n",
            "[1.0000000e+00 1.4692562e-02 3.8970556e-06 2.7143648e-03 4.4772897e-02\n",
            " 3.1572755e-02 6.8964821e-04 4.1301559e-05]\n",
            "[1.0000000e+00 2.5004319e-05 4.3322821e-06 3.2429800e-03 7.6518223e-02\n",
            " 2.0700886e-03 1.2647210e-03 1.6839027e-02]\n",
            "[1.0000000e+00 1.0972960e-01 1.4802914e-06 2.9020358e-03 8.3128596e-04\n",
            " 1.1871684e-02 1.0329443e-02 4.0764320e-03]\n",
            "[1.0000000e+00 3.8290299e-03 1.0798238e-04 1.0232232e-02 5.7654304e-04\n",
            " 5.2452944e-03 1.3475436e-03 5.8942987e-04]\n",
            "[1.0000000e+00 5.2990508e-05 2.7147821e-01 1.5615135e-02 1.6542237e-03\n",
            " 1.4279954e-03 3.6953357e-03 1.9910663e-05]\n",
            "[1.0000000e+00 1.5979607e-01 4.6658288e-06 1.9219454e-04 3.4723901e-03\n",
            " 5.3829369e-03 4.1768287e-04 6.5938488e-04]\n",
            "[1.0000000e+00 3.4154826e-04 2.2583775e-02 2.1378540e-02 6.2492397e-02\n",
            " 2.1036046e-02 2.1648037e-01 7.5127762e-05]\n",
            "[1.0000000e+00 2.5308679e-04 3.7034665e-04 7.3554538e-02 7.0152074e-02\n",
            " 1.5920759e-03 4.1849604e-01 7.9076545e-04]\n",
            "[1.0000000e+00 2.3970529e-04 3.5175649e-04 3.4195323e-02 3.0496651e-01\n",
            " 7.6144986e-02 7.8591757e-02 7.1389000e-03]\n",
            "[1.0000000e+00 2.4834130e-04 9.6471859e-03 2.9420231e-02 2.2768155e-02\n",
            " 6.0768696e-03 3.7845943e-02 2.4502531e-03]\n",
            "[1.0000000e+00 2.5480774e-03 7.7735930e-04 7.9272976e-03 2.0539802e-03\n",
            " 2.9819232e-04 1.7530400e-03 7.0521806e-04]\n",
            "[1.0000000e+00 2.0824627e-03 1.5171467e-03 3.7849075e-04 3.1371606e-03\n",
            " 2.5460706e-04 1.8002226e-03 7.2527875e-04]\n",
            "[1.         0.00488729 0.00103756 0.00348428 0.02197432 0.00739023\n",
            " 0.00260984 0.00363282]\n",
            "[1.0000000e+00 4.4533294e-02 1.8923449e-05 1.9861173e-03 4.6750223e-03\n",
            " 7.0109488e-03 5.4727439e-03 1.6685993e-03]\n",
            "[1.0000000e+00 5.5536174e-04 7.7662908e-04 1.5379721e-01 9.5878970e-03\n",
            " 2.5249757e-02 1.3072282e-01 2.0658332e-03]\n",
            "[1.0000000e+00 8.7631059e-05 4.9103547e-02 4.8884889e-03 5.5929855e-04\n",
            " 1.3543277e-04 2.9708717e-03 1.0423864e-03]\n",
            "[1.0000000e+00 9.6884847e-04 4.9521714e-05 1.8315669e-03 8.2101946e-04\n",
            " 1.7010354e-04 2.8149720e-04 2.6494995e-01]\n",
            "[1.0000000e+00 3.7885732e-03 2.8730590e-05 8.8747183e-04 1.2256977e-02\n",
            " 8.8225203e-03 2.6248983e-04 6.0001388e-03]\n",
            "[1.0000000e+00 1.6591983e-02 2.7515698e-04 6.7212584e-04 1.2751592e-03\n",
            " 1.2353293e-03 2.7345406e-04 1.4556092e-03]\n",
            "[1.7553967e-03 5.7139391e-01 3.5053417e-05 9.9007378e-04 3.9219295e-04\n",
            " 1.4044354e-03 4.8142951e-04 1.3242002e-03]\n",
            "[1.1962208e-01 1.3323845e-05 8.1571400e-01 2.6756683e-02 6.7404471e-05\n",
            " 5.1737345e-05 7.1634646e-03 8.1939308e-04]\n",
            "[1.0000000e+00 1.9295238e-02 5.4792596e-05 9.3211728e-04 2.5434737e-04\n",
            " 4.1479021e-04 8.6384761e-04 6.2476413e-04]\n",
            "[1.0000000e+00 7.0435635e-04 6.2620304e-05 3.4751019e-01 2.1960957e-03\n",
            " 3.5245382e-04 3.4432110e-04 3.1543065e-02]\n",
            "[1.0000000e+00 4.8662205e-03 3.2763273e-05 1.3415086e-01 1.1948111e-03\n",
            " 8.5608102e-04 1.5301285e-03 8.2058802e-02]\n",
            "[1.0000000e+00 1.9422943e-04 1.3912187e-02 1.4451669e-02 1.0090972e-03\n",
            " 3.7934678e-04 1.0144113e-02 3.0178952e-03]\n",
            "[1.0000000e+00 3.8830517e-04 2.8802125e-02 5.1283715e-03 6.3507399e-04\n",
            " 3.5792630e-04 4.3559957e-02 6.0113071e-04]\n",
            "[1.0000000e+00 3.8963042e-03 9.5954310e-05 3.8140215e-04 4.1175753e-04\n",
            " 7.6348799e-05 8.7358546e-04 1.0351083e-03]\n",
            "[1.0000000e+00 7.2500104e-04 3.3162837e-04 1.6915454e-02 1.3313018e-01\n",
            " 1.9022238e-02 7.5143380e-03 1.8418586e-02]\n",
            "[1.0000000e+00 3.2872716e-03 6.6796169e-03 1.9980794e-04 1.2934268e-04\n",
            " 7.2898576e-04 3.0833413e-04 9.2168141e-04]\n",
            "[1.0000000e+00 1.7022640e-04 3.5889942e-02 4.0070047e-03 5.9066373e-05\n",
            " 5.3558900e-04 2.0021682e-03 2.4592134e-04]\n",
            "[1.0000000e+00 1.9082709e-01 1.1666035e-04 8.6210202e-04 4.8131440e-04\n",
            " 4.8604500e-03 2.0897499e-04 4.8590671e-05]\n",
            "[1.0000000e+00 1.1036433e-01 2.4242881e-04 2.3270987e-03 5.7637441e-04\n",
            " 8.0256060e-02 4.4494765e-04 6.8035974e-05]\n",
            "[1.0000000e+00 1.1407163e-03 5.2799092e-04 1.4358649e-03 6.7425914e-02\n",
            " 3.0797085e-04 5.0130830e-04 1.4077532e-03]\n",
            "[1.0000000e+00 4.2574425e-04 3.2843376e-04 9.9254083e-03 2.6828802e-01\n",
            " 9.3481102e-04 2.8615806e-03 1.8731551e-03]\n",
            "[8.81305023e-05 2.74169305e-03 9.61687788e-03 1.98019780e-02\n",
            " 2.61131418e-03 7.17164993e-01 1.26979295e-02 3.10227624e-03]\n",
            "[1.0000000e+00 7.6324646e-03 1.1080565e-04 1.1646429e-02 3.6581445e-03\n",
            " 1.1297302e-02 3.2820855e-03 3.3109967e-02]\n",
            "[1.4893561e-04 8.5267809e-04 2.6621623e-05 6.0510773e-02 4.0291410e-04\n",
            " 6.0928299e-04 6.3399267e-03 5.2356434e-01]\n",
            "[1.0000000e+00 3.9546662e-03 8.8187633e-04 7.6650446e-03 3.5666095e-04\n",
            " 4.9720765e-03 1.3164494e-03 3.5144796e-03]\n",
            "[1.0000000e+00 4.5047966e-03 7.8285091e-05 1.5763344e-02 1.7879459e-01\n",
            " 1.7193006e-02 3.0224206e-02 2.4519704e-02]\n",
            "[1.0000000e+00 9.4226189e-03 1.1717565e-02 4.3252423e-02 3.6545426e-02\n",
            " 2.1069892e-02 1.2916487e-02 4.2763934e-04]\n",
            "[1.00000000e+00 4.11944371e-03 1.14233524e-04 9.06767882e-03\n",
            " 3.67719494e-02 5.77811040e-02 8.15563835e-03 3.74207310e-02]\n",
            "[1.0000000e+00 4.5844685e-02 1.1833294e-04 1.2766738e-02 2.0553222e-02\n",
            " 2.5340354e-02 1.4743426e-02 3.9318319e-02]\n",
            "[1.         0.00323968 0.00213052 0.00650193 0.00597526 0.08087637\n",
            " 0.00417717 0.02211826]\n",
            "[1.         0.00301995 0.00100625 0.03751136 0.0596218  0.02634921\n",
            " 0.00889725 0.00206261]\n",
            "[1.         0.00711705 0.00715837 0.05133179 0.02519532 0.10560264\n",
            " 0.04798814 0.0011748 ]\n",
            "[1.0000000e+00 2.4279141e-05 4.7012765e-02 1.3190213e-01 9.9960551e-02\n",
            " 9.9136226e-02 1.2557879e-01 1.6867243e-02]\n",
            "[1.0000000e+00 4.7380465e-05 4.3309274e-01 1.7973544e-02 3.2244300e-04\n",
            " 3.1382713e-04 9.6363545e-04 4.4119093e-04]\n",
            "[1.0000000e+00 7.4840813e-05 1.2661743e-02 9.6351817e-02 2.6269727e-03\n",
            " 5.6960010e-03 2.0433391e-02 5.1545975e-04]\n",
            "[1.0000000e+00 2.6981365e-02 4.5749047e-04 1.4678087e-03 1.2233165e-02\n",
            " 6.2057003e-02 2.9419312e-02 1.4298974e-02]\n",
            "[1.0000000e+00 1.9832356e-02 7.1403314e-04 3.5609822e-03 1.2779793e-02\n",
            " 7.6640911e-02 1.0660945e-02 6.6882214e-03]\n",
            "[1.0000000e+00 2.0014051e-05 3.0160376e-01 2.6288142e-02 1.8713832e-03\n",
            " 3.1773030e-04 2.6254313e-02 1.2544177e-03]\n",
            "[1.0000000e+00 2.3721319e-04 8.6648595e-03 7.7101886e-02 3.3240649e-03\n",
            " 1.6212290e-03 1.2357664e-01 2.9966799e-03]\n",
            "[1.0000000e+00 7.8207385e-03 8.1368099e-04 1.4207936e-02 6.7137979e-02\n",
            " 1.9656499e-03 5.2948654e-02 3.5498314e-02]\n",
            "[1.         0.00148697 0.00174199 0.03206015 0.07776047 0.00231777\n",
            " 0.0502456  0.10109007]\n",
            "[1.         0.00699739 0.00174113 0.00722523 0.05649769 0.01175359\n",
            " 0.0244985  0.02575061]\n",
            "[1.0000000e+00 7.5610337e-04 2.4513965e-03 5.9745293e-02 4.2674724e-02\n",
            " 1.8006280e-01 8.9377657e-02 9.3010351e-02]\n",
            "[1.0000000e+00 1.2144922e-01 1.6715731e-04 1.3092409e-02 2.4276949e-03\n",
            " 1.1176547e-02 9.8474147e-03 1.0245482e-02]\n",
            "[1.0000000e+00 3.1199781e-03 2.1859051e-03 1.0489141e-02 5.2932287e-03\n",
            " 2.6094861e-04 1.0054703e-03 4.4145649e-03]\n",
            "[1.0000000e+00 6.5334834e-04 1.1326098e-02 6.5239896e-03 1.8369437e-03\n",
            " 2.4893173e-04 5.4399967e-03 2.3390092e-03]\n",
            "[1.         0.00211143 0.00350901 0.00465266 0.00418748 0.00276137\n",
            " 0.00735902 0.16769923]\n",
            "[1.0000000e+00 4.0457234e-01 2.2954757e-04 4.5924550e-03 8.3962167e-03\n",
            " 4.1730285e-02 3.2525552e-03 5.0040847e-04]\n",
            "[1.0000000e+00 2.2696659e-01 1.9184338e-04 1.6469952e-03 3.2817514e-03\n",
            " 1.7675528e-03 1.3899832e-03 4.0990624e-04]\n",
            "[1.0000000e+00 5.0769711e-04 4.9082607e-02 2.7305707e-02 6.5070987e-03\n",
            " 4.6068253e-03 7.1291454e-02 1.4491971e-03]\n",
            "[1.0000000e+00 9.5227314e-04 9.9998778e-03 2.8904837e-03 1.2214682e-02\n",
            " 3.0759065e-03 4.5950849e-02 7.4145882e-03]\n",
            "[1.0000000e+00 7.0743408e-04 1.1418120e-03 1.8711893e-02 7.2643384e-03\n",
            " 2.9196823e-02 1.6557993e-02 1.5286026e-02]\n",
            "[1.00000000e+00 1.35559859e-02 6.69797824e-04 3.36559769e-03\n",
            " 1.17682675e-02 1.20414561e-02 3.31636295e-02 6.61992515e-03]\n",
            "[1.0000000e+00 8.4197723e-05 1.3323608e-03 9.9255405e-03 7.8048430e-02\n",
            " 1.1383494e-02 2.6904203e-02 3.0374578e-01]\n",
            "[1.0000000e+00 6.5312278e-04 2.0306623e-03 2.8942423e-02 1.1023614e-01\n",
            " 9.1735080e-02 6.1095990e-02 3.6755055e-02]\n",
            "[1.00000000e+00 8.18846896e-02 2.23701907e-04 1.00959845e-01\n",
            " 3.58843943e-03 2.41192617e-03 2.59103696e-03 1.56886969e-02]\n",
            "[1.         0.00123484 0.08463049 0.12282068 0.0043025  0.01150754\n",
            " 0.03309065 0.00197853]\n",
            "[1.0000000e+00 8.8117544e-05 4.9012476e-03 1.5630403e-05 4.1588959e-03\n",
            " 2.8010388e-04 2.0555414e-02 8.0686854e-03]\n",
            "[1.0000000e+00 9.2879328e-04 1.6533122e-03 7.3427918e-06 8.2337029e-02\n",
            " 4.3204706e-03 5.3920774e-03 3.0507597e-03]\n",
            "[1.0000000e+00 5.6258973e-02 3.9962931e-03 1.9551956e-06 2.2447268e-03\n",
            " 2.0848962e-03 1.8842162e-04 2.3514131e-04]\n",
            "[1.0000000e+00 2.8125141e-03 4.3557794e-04 1.1578105e-05 1.9985516e-02\n",
            " 1.2111288e-03 3.0586618e-04 4.8241267e-01]\n",
            "[1.00000000e+00 2.70452956e-03 6.82334183e-04 1.42251865e-05\n",
            " 1.31139634e-02 1.68079436e-01 4.92234365e-04 1.98761263e-04]\n",
            "[1.0000000e+00 6.5013659e-03 1.2464869e-03 5.9382364e-06 3.4588752e-03\n",
            " 1.4300878e-02 1.0886075e-04 1.2035629e-04]\n",
            "[1.00000000e+00 4.36794432e-03 5.26239444e-03 4.98957797e-06\n",
            " 5.61335008e-04 3.52770486e-03 1.13393595e-04 8.16498324e-03]\n",
            "[1.0000000e+00 2.6700109e-02 1.3454274e-03 1.0150666e-05 1.3776376e-03\n",
            " 3.1367650e-03 1.8482057e-04 1.3878048e-04]\n",
            "[1.0000000e+00 6.4526603e-04 4.7504995e-02 3.6450216e-05 8.2135550e-04\n",
            " 6.6696026e-04 3.3688638e-02 3.1493363e-04]\n",
            "[1.0000000e+00 1.5930186e-03 1.1012972e-03 1.4930690e-05 3.2191211e-03\n",
            " 3.5342074e-03 2.3826053e-03 5.3078274e-04]\n",
            "[1.0000000e+00 3.4533337e-01 3.1098194e-04 2.0745108e-05 1.5796132e-03\n",
            " 2.8650064e-03 9.3295667e-03 7.9697752e-03]\n",
            "[1.0000000e+00 1.4281647e-03 3.6356220e-01 6.3556909e-05 1.2616357e-03\n",
            " 3.3669960e-04 4.6713520e-03 1.4041633e-03]\n",
            "[1.0000000e+00 1.8479611e-04 2.0293475e-03 6.9967791e-06 4.7313914e-01\n",
            " 8.1080897e-04 2.0206682e-03 3.9969298e-01]\n",
            "[1.0000000e+00 7.1331253e-03 5.2808976e-04 1.8575342e-05 1.1465205e-01\n",
            " 3.3308982e-03 3.2848938e-04 1.3555834e-03]\n",
            "[1.0000000e+00 1.5213248e-02 2.2742413e-03 2.0329899e-05 4.1632690e-03\n",
            " 3.8992837e-03 2.1547091e-04 1.9464044e-02]\n",
            "[1.0000000e+00 7.3337510e-02 6.4160768e-04 2.1915561e-04 1.4998607e-03\n",
            " 4.2371112e-03 1.1031833e-03 7.0780986e-03]\n",
            "[1.0000000e+00 1.0117000e-03 4.4471137e-02 1.9939177e-02 2.6638859e-03\n",
            " 4.6883575e-03 9.6842805e-03 3.6345233e-04]\n",
            "[9.5779425e-04 6.8662307e-06 6.7249820e-02 9.7911191e-01 4.7724992e-03\n",
            " 1.7841023e-03 8.0984670e-01 1.9601006e-03]\n",
            "[1.0000000e+00 1.4815481e-02 4.1531600e-02 5.7017996e-06 1.2241488e-03\n",
            " 2.4531079e-03 2.8644996e-02 2.4922320e-04]\n",
            "[1.0000000e+00 2.1403559e-04 3.8396880e-01 7.0123169e-06 4.1007777e-03\n",
            " 9.4043475e-04 3.5484838e-03 4.1806749e-03]\n",
            "[1.0000000e+00 1.4040680e-03 2.5847114e-03 6.2361731e-05 1.8784633e-03\n",
            " 3.5180426e-03 3.5613296e-03 4.9490668e-03]\n",
            "[1.0000000e+00 7.0356519e-04 5.3253551e-03 1.7564732e-04 7.9126820e-02\n",
            " 5.8076635e-04 1.0442672e-02 1.8329643e-02]\n",
            "[1.0000000e+00 1.1294880e-01 3.3779168e-05 7.3275560e-06 1.0953423e-02\n",
            " 2.6744362e-02 3.8722067e-03 5.5407686e-03]\n",
            "[1.0000000e+00 8.3405860e-03 8.6968765e-03 1.0179088e-05 2.6266731e-02\n",
            " 2.0825119e-01 1.8793212e-02 5.2309819e-03]\n",
            "[1.0000000e+00 8.7129157e-03 3.9024142e-04 4.2188974e-05 6.1736114e-02\n",
            " 1.5199364e-03 1.7568396e-03 2.2855476e-03]\n",
            "[1.0000000e+00 1.1367465e-01 2.6798810e-04 1.4333776e-05 5.2024880e-03\n",
            " 1.2169920e-03 2.0662604e-03 1.3030601e-03]\n",
            "[1.0000000e+00 1.8926207e-02 1.2977257e-03 1.7586479e-05 2.8841119e-04\n",
            " 8.1388811e-03 2.1884886e-04 6.7382545e-04]\n",
            "[1.0000000e+00 2.4043461e-03 1.5147749e-03 3.7352987e-05 5.8096321e-03\n",
            " 1.6984860e-03 6.4876764e-03 8.4924754e-03]\n",
            "[1.0000000e+00 2.5233524e-02 3.0355042e-04 6.7230021e-06 1.6564261e-02\n",
            " 5.7428055e-03 3.2084549e-03 1.9388101e-03]\n",
            "[1.0000000e+00 1.1786350e-01 1.1678284e-04 7.3870234e-07 1.1759322e-03\n",
            " 2.2773144e-03 2.1753274e-04 4.0346850e-03]\n",
            "[1.0000000e+00 3.1092525e-03 2.1850900e-03 7.0366514e-05 4.3201916e-02\n",
            " 4.1458112e-01 1.3644916e-02 1.0618023e-04]\n",
            "[1.0000000e+00 2.5399668e-02 2.5859158e-03 1.8847502e-05 7.4604657e-03\n",
            " 9.9241756e-02 2.9245066e-03 1.6099756e-04]\n",
            "[1.0000000e+00 2.7351867e-04 7.2417998e-07 4.4908084e-04 1.8942354e-02\n",
            " 1.3272780e-02 1.3634476e-01 2.6536945e-01]\n",
            "[1.00000000e+00 1.29968405e-01 4.16543706e-08 8.15864041e-06\n",
            " 9.77936853e-03 1.04123475e-02 1.90121689e-04 1.44338165e-03]\n",
            "[1.0000000e+00 2.1832332e-04 8.6252921e-06 4.0571380e-04 1.9455461e-02\n",
            " 1.2170320e-03 7.0609301e-02 5.1796890e-04]\n",
            "[1.0000000e+00 7.3056130e-05 6.6408114e-07 4.7256050e-05 4.7222733e-02\n",
            " 1.0066861e-03 1.5326714e-02 2.0130086e-03]\n",
            "[1.0000000e+00 1.2107739e-03 4.6577264e-07 1.5972281e-04 7.7683772e-03\n",
            " 6.3159955e-03 3.4335097e-03 2.0615183e-02]\n",
            "[1.0000000e+00 3.3077114e-04 1.4623078e-06 3.4011216e-04 5.2974592e-03\n",
            " 1.6854055e-02 6.4002811e-03 6.0994152e-02]\n",
            "[1.0000000e+00 2.5833207e-01 2.5388704e-08 5.8184637e-06 2.1903848e-03\n",
            " 1.1365587e-04 6.1564802e-05 1.7038977e-02]\n",
            "[1.0000000e+00 1.7414057e-01 2.7324000e-07 5.3740529e-05 1.5681580e-02\n",
            " 2.2635637e-03 3.3194353e-04 3.8148658e-04]\n",
            "[1.0000000e+00 1.3223018e-04 1.7582050e-06 6.5536023e-04 9.8505113e-03\n",
            " 1.1452195e-03 1.3444181e-01 2.1944906e-01]\n",
            "[1.00000000e+00 1.11440138e-03 2.96164235e-05 7.19876407e-05\n",
            " 8.71786033e-04 1.02055994e-04 1.67386176e-03 2.73271289e-04]\n",
            "[1.0000000e+00 4.2956439e-03 6.6078474e-07 1.4003461e-05 2.9052261e-03\n",
            " 3.0012865e-04 3.5190533e-04 3.4127184e-03]\n",
            "[1.0000000e+00 1.4324365e-03 1.2198309e-07 1.6682941e-05 1.1794752e-01\n",
            " 9.5130097e-05 3.8145776e-04 3.7414826e-02]\n",
            "[1.00000000e+00 1.11086039e-04 2.31258760e-04 1.32078575e-02\n",
            " 5.23643102e-04 1.32730391e-04 3.70205473e-03 7.32127301e-05]\n",
            "[2.0825191e-04 7.9738420e-05 9.5832396e-01 1.1542422e-03 9.7269926e-04\n",
            " 2.8496969e-04 5.0017707e-02 4.5667304e-05]\n",
            "[3.2328484e-05 8.3388187e-02 1.3813898e-06 1.4228495e-04 4.8827482e-03\n",
            " 8.3988780e-01 2.4915575e-03 1.8815133e-03]\n",
            "[1.0000000e+00 2.6550332e-01 8.2524828e-08 1.8938534e-05 4.6268166e-03\n",
            " 1.5600822e-02 1.6031708e-03 4.5384183e-03]\n",
            "[1.0000000e+00 6.8251294e-04 1.4149607e-04 2.2214391e-04 1.9610059e-02\n",
            " 1.8244602e-02 2.7095189e-02 2.3947738e-03]\n",
            "[1.0000000e+00 3.6471940e-03 7.6574346e-05 1.3301568e-04 8.1870868e-04\n",
            " 8.2059886e-04 2.2848239e-02 9.3565090e-03]\n",
            "[1.0000000e+00 9.1136899e-04 2.0276166e-06 2.2094299e-04 6.5076211e-03\n",
            " 9.4931172e-03 4.1216696e-03 4.7134787e-02]\n",
            "[1.00000000e+00 4.45151731e-04 2.20166348e-05 7.13180110e-04\n",
            " 1.34741166e-03 1.34846065e-02 2.56692152e-02 1.10713216e-02]\n",
            "[1.0000000e+00 6.1106752e-03 1.3764991e-06 7.4456097e-05 8.3729615e-03\n",
            " 2.4675189e-03 9.6528378e-04 1.0985608e-03]\n",
            "[3.2689158e-02 2.7722437e-03 7.2617388e-07 6.0465216e-05 5.5504221e-01\n",
            " 2.8464145e-03 1.0212399e-03 5.4021849e-04]\n",
            "[1.0000000e+00 6.3732573e-06 2.9527815e-02 2.6010908e-02 1.6948309e-02\n",
            " 2.4534712e-04 5.8366783e-02 2.9441755e-05]\n",
            "[1.0000000e+00 2.0287673e-05 1.1540134e-02 5.6696497e-03 8.9648962e-03\n",
            " 1.1992141e-04 1.9352742e-02 1.1343250e-04]\n",
            "[1.0000000e+00 2.3003902e-02 2.7014758e-07 2.8583969e-04 4.8064152e-03\n",
            " 1.1887374e-02 5.1925128e-04 8.5198722e-04]\n",
            "[1.0000000e+00 3.8130499e-02 6.6588672e-07 2.7049817e-05 1.6371036e-03\n",
            " 4.9608606e-03 2.3878827e-04 2.8665038e-04]\n",
            "[1.0000000e+00 4.0051871e-04 2.8039438e-05 8.3485979e-04 6.8974562e-02\n",
            " 1.1146975e-02 3.6220160e-01 3.6208230e-04]\n",
            "[1.0000000e+00 4.1966696e-04 2.2401298e-05 2.0879478e-04 1.2996455e-02\n",
            " 2.2421007e-03 1.8847138e-02 7.3535845e-04]\n",
            "[5.4800659e-02 3.7854534e-05 6.9814587e-06 9.4640410e-01 1.5194608e-03\n",
            " 1.6212033e-04 1.2249058e-02 8.1723911e-04]\n",
            "[1.0000000e+00 3.7753696e-05 2.3885616e-05 1.9511386e-03 1.3590897e-02\n",
            " 1.2982391e-03 5.7417122e-03 4.3686689e-03]\n",
            "[1.0000000e+00 1.9976753e-03 3.5793812e-06 2.3048237e-04 3.3556556e-03\n",
            " 7.0355069e-03 1.0519334e-02 9.2381462e-02]\n",
            "[1.0000000e+00 7.7179185e-04 9.2128403e-07 2.0199176e-04 6.5886052e-03\n",
            " 4.5397170e-03 2.8810576e-03 1.9299521e-01]\n",
            "[1.0000000e+00 2.3428451e-04 9.4898706e-07 2.7310777e-02 2.0280218e-01\n",
            " 6.6306922e-03 1.3867705e-03 1.6864479e-02]\n",
            "[1.00000000e+00 2.04093894e-03 4.84061388e-07 1.94305452e-04\n",
            " 1.02474414e-01 7.09104119e-03 1.91953470e-04 1.49111003e-01]\n",
            "[1.0000000e+00 7.1399822e-03 2.3573648e-06 3.5628069e-05 7.6045259e-03\n",
            " 4.8791956e-02 5.3268541e-05 2.8144787e-03]\n",
            "[1.0000000e+00 6.2950922e-04 6.9137363e-06 8.1349745e-06 1.9009501e-03\n",
            " 3.9726522e-04 3.1725845e-05 7.9732836e-04]\n",
            "[1.0000000e+00 2.6309618e-04 2.4756175e-04 1.3226770e-04 3.4880478e-04\n",
            " 4.3436419e-04 4.1474148e-05 2.9617082e-04]\n",
            "[1.0000000e+00 3.4607857e-04 5.4778004e-05 6.2736231e-05 1.8335184e-03\n",
            " 1.2842654e-01 5.5177964e-04 2.0703839e-03]\n",
            "[1.0000000e+00 1.7008344e-02 7.9435472e-07 6.1392748e-05 5.7404214e-03\n",
            " 2.4471277e-02 4.4489243e-05 3.4940947e-02]\n",
            "[1.0000000e+00 1.7217590e-04 2.9525654e-06 2.1932553e-03 1.1650746e-02\n",
            " 1.4851238e-03 4.4408767e-04 1.0333401e-01]\n",
            "[1.0000000e+00 6.9292792e-04 1.6600208e-05 2.6497699e-05 6.0887570e-03\n",
            " 4.6456465e-03 8.7554443e-05 7.1197556e-04]\n",
            "[1.0000000e+00 2.3857944e-03 5.6884055e-05 3.0503086e-05 2.6461319e-03\n",
            " 4.5892703e-03 5.8109639e-05 9.9440140e-04]\n",
            "[1.0000000e+00 1.3875439e-03 4.3618175e-07 6.4859560e-05 2.4315076e-01\n",
            " 3.5933763e-02 6.9465605e-05 9.9783652e-03]\n",
            "[1.0000000e+00 2.0025377e-03 1.5815267e-06 5.6839850e-05 1.5259981e-02\n",
            " 7.9610506e-03 3.5929323e-05 2.5824462e-03]\n",
            "[1.3537849e-03 1.4592862e-05 6.8183567e-07 1.6167083e-05 1.0696562e-02\n",
            " 3.7790688e-03 6.6819075e-03 6.0247874e-01]\n",
            "[8.3159923e-04 5.9039688e-05 2.1435044e-06 1.4800125e-05 3.9435453e-03\n",
            " 7.2289340e-04 9.0464252e-01 1.1323668e-02]\n",
            "[1.0000000e+00 7.8913094e-05 2.6715973e-03 7.9164803e-03 1.9457821e-02\n",
            " 1.6398590e-02 6.4832233e-03 1.6455913e-04]\n",
            "[1.0000000e+00 6.2247195e-06 3.9677951e-02 8.9949621e-03 7.4797481e-02\n",
            " 5.3756725e-02 1.8792082e-02 2.3262062e-04]\n",
            "[1.0000000e+00 4.0151696e-03 8.7936866e-07 1.7824341e-05 4.4103593e-02\n",
            " 1.5339423e-03 1.0588563e-04 1.1365879e-03]\n",
            "[1.0000000e+00 1.1855165e-03 3.8697276e-06 1.4403643e-04 3.8955519e-03\n",
            " 8.0878232e-03 3.8168061e-04 2.4042367e-04]\n",
            "[1.0000000e+00 3.7341624e-01 9.5128951e-07 9.9310855e-06 5.0833118e-03\n",
            " 2.3767283e-02 3.5028806e-05 1.6650905e-04]\n",
            "[1.0000000e+00 2.2756651e-02 4.8358224e-06 8.6554745e-04 4.6563488e-03\n",
            " 9.1861822e-02 1.2550857e-04 2.7046452e-04]\n",
            "[1.0000000e+00 3.0050613e-04 1.4532461e-06 6.4434593e-05 2.6492609e-02\n",
            " 6.7962613e-03 7.9418696e-04 3.4047503e-02]\n",
            "[1.0000000e+00 9.1806939e-03 6.0622961e-07 1.1769389e-05 2.0132219e-02\n",
            " 4.2269695e-01 4.2055661e-05 7.6046970e-04]\n",
            "[1.9648382e-04 1.6303564e-05 9.5301133e-01 3.2266479e-03 4.8372028e-03\n",
            " 3.1999110e-03 1.3696512e-03 8.5742911e-05]\n",
            "[1.0000000e+00 1.9660949e-04 1.4051268e-03 9.0406025e-03 1.9223694e-02\n",
            " 2.0469571e-02 1.9882328e-03 2.3547662e-03]\n",
            "[2.1686591e-03 2.1712984e-05 3.7949331e-04 9.3096048e-01 9.2838295e-03\n",
            " 1.4116152e-02 4.8043747e-02 2.6152545e-04]\n",
            "[1.0000000e+00 8.3933599e-05 1.8372426e-03 1.6490608e-03 1.7644279e-03\n",
            " 9.1253570e-04 2.2431536e-04 3.7727316e-04]\n",
            "[1.0000000e+00 3.0606845e-02 1.8908720e-07 2.4980369e-05 5.6199819e-02\n",
            " 9.6420124e-03 2.6151669e-04 1.0594518e-03]\n",
            "[1.0000000e+00 9.4204716e-02 7.3453364e-08 6.9427151e-06 7.5181271e-03\n",
            " 4.6414924e-03 7.1030103e-05 4.2628369e-04]\n",
            "[1.0000000e+00 3.1595942e-04 6.0526293e-04 1.6867340e-04 3.1923621e-03\n",
            " 2.5815400e-03 2.7355507e-03 1.9052489e-04]\n",
            "[1.0000000e+00 2.0622062e-03 1.9250492e-06 6.5234494e-03 4.2576380e-03\n",
            " 2.1138646e-02 2.3038196e-03 1.4250277e-02]\n",
            "[1.0000000e+00 1.2607366e-03 1.3522948e-06 9.4771720e-05 2.9663362e-02\n",
            " 1.9178404e-02 1.6749204e-03 5.3520855e-03]\n",
            "[1.0000000e+00 4.2591420e-01 7.3025041e-07 7.1260518e-05 4.9299300e-02\n",
            " 3.8603889e-03 2.4651640e-04 3.2449691e-04]\n",
            "[1.0000000e+00 9.1649778e-04 1.5834333e-06 3.9051641e-03 4.2724147e-01\n",
            " 2.8076297e-02 1.5207803e-01 9.6280879e-04]\n",
            "[1.0000000e+00 1.3136327e-02 1.6015805e-06 8.8337995e-03 1.9986818e-03\n",
            " 1.3663168e-03 1.8945180e-01 1.9737541e-04]\n",
            "[1.0000000e+00 2.2395449e-03 5.6335296e-07 1.1081125e-03 8.3579362e-04\n",
            " 1.8801724e-03 5.6985009e-04 5.3542125e-04]\n",
            "[1.0000000e+00 4.7055622e-05 5.4973248e-06 4.6954919e-02 2.9495792e-02\n",
            " 1.6499877e-03 6.3497238e-03 1.5171432e-03]\n",
            "[7.6966643e-02 6.8853285e-07 9.9963862e-01 6.6293187e-02 2.8491032e-04\n",
            " 2.0773903e-05 2.8671916e-03 1.0554306e-04]\n",
            "[1.0000000e+00 1.9976718e-05 5.8046357e-05 7.8288689e-02 1.1741098e-03\n",
            " 6.5393746e-04 1.1443518e-02 1.4736004e-03]\n",
            "[1.0000000e+00 4.1289954e-06 2.9891075e-05 1.1992788e-02 1.3380995e-03\n",
            " 1.5261448e-03 2.9663083e-03 2.0628504e-01]\n",
            "[1.0000000e+00 7.7930914e-04 6.7228975e-06 1.3275531e-03 2.2642978e-03\n",
            " 6.4391573e-04 1.0624480e-02 5.4891431e-03]\n",
            "[1.0000000e+00 2.8918113e-05 4.0701993e-06 6.8239840e-03 1.3743740e-02\n",
            " 3.9456566e-03 5.0052516e-03 6.5509747e-03]\n",
            "[5.7975976e-03 6.4672675e-04 4.1533892e-07 8.5635728e-04 1.1963876e-03\n",
            " 9.6360483e-04 6.6224282e-04 5.0624430e-01]\n",
            "[1.0000000e+00 1.5635474e-04 7.8858983e-07 8.2827685e-03 4.0822405e-02\n",
            " 2.3031819e-03 7.5279810e-03 1.3262500e-01]\n",
            "[1.0000000e+00 6.1512733e-04 1.8361089e-06 3.8317077e-02 1.0898792e-02\n",
            " 5.3763529e-04 2.1106454e-03 1.0198674e-02]\n",
            "[1.0000000e+00 9.6311113e-03 2.1774661e-06 2.7641153e-03 4.0828865e-03\n",
            " 5.2127223e-02 1.0486291e-02 2.1011676e-03]\n",
            "[1.00000000e+00 4.47067618e-03 2.72105524e-07 8.89011193e-04\n",
            " 1.05335616e-01 3.27343296e-04 1.20404630e-03 1.32513549e-02]\n",
            "[1.0000000e+00 3.2316055e-02 6.4555393e-06 5.2761752e-02 4.9703415e-03\n",
            " 3.8666590e-03 2.2152381e-02 1.9946448e-03]\n",
            "[1.0000000e+00 1.2847048e-04 8.0508380e-06 5.9449032e-02 1.0238717e-02\n",
            " 1.5279759e-01 4.7179468e-02 2.2490101e-02]\n",
            "[6.6459453e-04 1.0639725e-02 2.8093646e-07 3.4296606e-04 7.1271753e-04\n",
            " 6.1253113e-01 1.2897884e-03 5.0975539e-04]\n",
            "[1.0000000e+00 1.6824320e-04 5.5550197e-05 1.0134899e-02 4.4639022e-03\n",
            " 2.7480211e-02 2.9396549e-02 1.5389405e-03]\n",
            "[1.0000000e+00 6.1718575e-03 1.8678696e-06 2.8849354e-03 4.8138797e-03\n",
            " 2.1420200e-03 4.9693752e-03 7.9505735e-05]\n",
            "[1.00000000e+00 8.90551237e-05 1.17616815e-04 1.10895801e-02\n",
            " 3.67092201e-03 3.68072302e-04 1.57030728e-02 4.82106203e-04]\n",
            "[1.0000000e+00 5.6117185e-04 4.0896621e-06 7.9613298e-02 1.2353254e-03\n",
            " 1.4161710e-02 5.4881658e-02 1.5592963e-02]\n",
            "[1.0000000e+00 6.5956534e-05 5.4000839e-06 3.9535642e-01 3.5158992e-03\n",
            " 8.9313462e-03 9.0721048e-02 6.2073567e-03]\n",
            "[1.0000000e+00 2.5127511e-05 2.1543103e-05 6.9901817e-03 2.8393278e-03\n",
            " 1.9117286e-04 8.6949542e-02 2.4587164e-02]\n",
            "[1.0000000e+00 2.4217784e-02 5.1762208e-06 1.6279519e-03 6.6460361e-04\n",
            " 5.3395480e-02 2.7591558e-03 5.4765231e-04]\n",
            "[1.0795279e-06 7.7677637e-01 6.8654759e-07 2.4092610e-03 1.7437933e-03\n",
            " 7.6242868e-04 2.5479353e-03 4.8690138e-04]\n",
            "[1.0000000e+00 9.7220704e-02 4.0586096e-06 6.8523651e-03 3.4373729e-03\n",
            " 1.8265178e-02 4.9497019e-02 3.1033022e-04]\n",
            "[1.0000000e+00 4.7471523e-03 8.1702802e-07 7.6019554e-04 8.8366559e-03\n",
            " 1.4056342e-03 1.0881303e-03 4.1486342e-03]\n",
            "[1.0000000e+00 4.0162099e-03 5.5414102e-07 1.0193303e-03 3.1051959e-03\n",
            " 7.6275336e-04 4.0075841e-04 3.9386428e-03]\n",
            "[1.0000000e+00 1.1866335e-04 1.2813927e-06 1.3942978e-02 2.0118487e-01\n",
            " 2.4952779e-03 6.2365010e-03 1.0598606e-02]\n",
            "[1.0000000e+00 1.3671661e-03 3.9499022e-07 3.2140616e-02 3.2509249e-02\n",
            " 2.3014077e-03 9.1428524e-03 3.8261127e-03]\n",
            "[1.0000000e+00 1.4179645e-03 1.2884025e-05 4.1818205e-02 6.0880896e-02\n",
            " 1.9790940e-03 1.4497410e-01 6.9043543e-03]\n",
            "[1.00000000e+00 7.25987693e-03 1.21444145e-06 4.16849460e-03\n",
            " 1.04633495e-02 1.40643926e-04 2.67632958e-02 8.21870659e-03]\n",
            "[1.0000000e+00 9.4254352e-02 1.4762536e-02 4.6855174e-02 6.3571264e-03\n",
            " 4.0081706e-02 1.4779802e-01 1.6541961e-04]\n",
            "[1.0000000e+00 8.9243583e-02 1.0931315e-01 1.2830809e-01 5.4183463e-03\n",
            " 2.9868830e-02 4.9298105e-01 2.8297663e-05]\n",
            "[1.0000000e+00 9.6701348e-05 9.4603971e-03 8.2463529e-03 9.1620006e-02\n",
            " 7.1856161e-03 3.1187756e-03 8.7524611e-05]\n",
            "[1.0000000e+00 2.4125702e-05 1.7071471e-02 7.0375954e-03 1.3521941e-01\n",
            " 5.1247221e-03 3.0728313e-03 2.2253252e-04]\n",
            "[1.0000000e+00 1.9389024e-02 2.3212319e-03 4.0626312e-03 4.3214685e-03\n",
            " 3.4681011e-02 6.6402747e-04 1.8092491e-04]\n",
            "[1.00000000e+00 7.31661159e-04 2.05662870e-03 1.16722658e-02\n",
            " 4.20476794e-02 1.53689105e-02 1.10273389e-03 2.73656740e-04]\n",
            "[1.0000000e+00 2.5710008e-01 1.9234056e-02 9.0193702e-03 5.3700646e-03\n",
            " 1.5199551e-02 9.5470576e-03 2.5225774e-05]\n",
            "[1.0000000e+00 1.5198836e-01 3.8272150e-02 6.3849222e-03 2.1867892e-03\n",
            " 1.8553639e-02 2.3805404e-03 1.2080533e-05]\n",
            "[1.         0.01903145 0.00111694 0.00392184 0.00861141 0.00418663\n",
            " 0.00436544 0.0067137 ]\n",
            "[1.0000000e+00 5.1872652e-02 8.9357905e-03 5.7383142e-02 4.2263973e-03\n",
            " 4.8630677e-02 2.7199227e-02 1.0660988e-04]\n",
            "[1.0000000e+00 8.8096425e-02 1.8034007e-02 1.0292417e-01 3.1354721e-03\n",
            " 1.4220509e-02 8.3760828e-02 1.1790232e-04]\n",
            "[1.0000000e+00 1.2696621e-01 2.5971312e-02 5.9412852e-02 1.7703387e-01\n",
            " 7.6100782e-02 1.5428874e-01 7.0160793e-05]\n",
            "[1.0000000e+00 2.4217991e-04 1.0914103e-03 7.0711359e-02 2.0662110e-02\n",
            " 1.2662204e-03 4.7688084e-03 1.3640054e-01]\n",
            "[4.2451653e-04 4.7344118e-05 5.9278711e-04 4.8038367e-02 1.9685430e-02\n",
            " 1.6650258e-03 2.4520860e-03 8.1553376e-01]\n",
            "[1.0000000e+00 2.8716386e-04 5.0665634e-03 5.4503717e-02 3.0159883e-03\n",
            " 3.2769863e-02 2.7554587e-03 9.4777849e-03]\n",
            "[1.0000000e+00 3.0932364e-03 8.9353267e-03 2.1091515e-02 1.7409873e-03\n",
            " 3.8838446e-01 8.9676940e-04 4.6204490e-04]\n",
            "[1.0000000e+00 2.7331526e-03 2.2872307e-03 9.6035320e-03 1.0484208e-02\n",
            " 1.2183012e-02 6.0075818e-04 4.1910150e-04]\n",
            "[1.0000000e+00 1.0193069e-04 4.7299936e-03 4.5875856e-03 6.7947353e-03\n",
            " 3.0190551e-03 6.0197292e-04 4.4677160e-03]\n",
            "[1.0000000e+00 1.5936850e-04 9.3887053e-02 2.4842765e-02 2.6385637e-03\n",
            " 4.7529843e-03 2.1611967e-03 2.6766775e-04]\n",
            "[1.0000000e+00 4.0805277e-05 4.8630077e-02 4.5125116e-02 2.9898447e-03\n",
            " 4.6631694e-04 5.5927685e-03 1.0796433e-03]\n",
            "[1.0000000e+00 4.1192754e-05 2.0771277e-01 9.7785600e-02 9.1167279e-02\n",
            " 1.2825063e-01 2.5089754e-02 1.1569700e-04]\n",
            "[1.00000000e+00 1.15765826e-04 2.33531790e-03 1.23963192e-01\n",
            " 2.79669940e-01 2.12458801e-02 1.35608641e-02 1.04390943e-04]\n",
            "[1.0000000e+00 2.6505571e-04 5.4089641e-03 4.5494889e-03 3.3531137e-02\n",
            " 1.0191387e-02 7.6407526e-04 3.0048852e-04]\n",
            "[1.0000000e+00 4.8133936e-02 1.3485598e-02 6.8773897e-03 2.8185830e-03\n",
            " 5.7730400e-03 1.7189875e-03 2.1709009e-05]\n",
            "[1.0000000e+00 1.0557209e-02 7.0171645e-03 6.1032707e-03 5.2545597e-03\n",
            " 3.7201848e-03 3.2323529e-04 5.0940700e-05]\n",
            "[1.0000000e+00 1.0798402e-03 1.0787748e-02 7.5623584e-03 2.1265568e-03\n",
            " 2.2162173e-02 9.4152865e-04 1.7457578e-03]\n",
            "[1.0000000e+00 2.3144777e-03 2.1152891e-02 5.0382176e-03 2.9035751e-03\n",
            " 1.9747477e-02 3.5899607e-04 1.7125909e-05]\n",
            "[1.0000000e+00 4.4937227e-03 1.5367658e-02 7.9268934e-03 1.1556823e-02\n",
            " 2.2440078e-02 7.0112350e-04 2.7037042e-05]\n",
            "[1.0000000e+00 9.5006812e-04 3.1834433e-03 4.0291329e-03 8.9689653e-04\n",
            " 6.0423207e-03 6.2221329e-04 2.1089541e-02]\n",
            "[1.0000000e+00 1.5782095e-04 2.7564561e-01 5.0250404e-03 7.4708918e-03\n",
            " 2.1848760e-03 4.5908834e-03 2.7891170e-04]\n",
            "[1.0000000e+00 2.4292709e-02 1.5065714e-03 2.0773653e-03 7.1395412e-03\n",
            " 3.6933678e-03 7.9095026e-04 4.8382863e-05]\n",
            "[1.0000000e+00 2.0983957e-03 4.6261530e-03 5.3296965e-03 1.9042972e-03\n",
            " 8.3905272e-04 4.2832951e-04 8.7756052e-05]\n",
            "[1.0000000e+00 4.6062382e-04 1.1831268e-03 4.2970898e-04 1.2204346e-02\n",
            " 6.7372504e-04 1.8399621e-04 4.0373430e-03]\n",
            "[1.0000000e+00 4.8711905e-03 8.6812797e-05 1.9793049e-04 5.2342273e-04\n",
            " 8.7003846e-04 2.1615527e-03 5.3048875e-02]\n",
            "[1.0000000e+00 1.0396328e-04 4.6902677e-04 6.2052067e-04 2.3042662e-03\n",
            " 1.0807407e-03 2.3581888e-04 1.1457697e-02]\n",
            "[7.4879504e-03 9.4800533e-05 1.6031272e-04 9.0782711e-04 7.2112507e-01\n",
            " 1.0616583e-03 1.4416812e-03 1.2940596e-02]\n",
            "[1.0000000e+00 2.2580023e-01 5.7068060e-04 1.6544992e-03 4.2659389e-03\n",
            " 1.0360418e-03 1.7631860e-02 5.4307439e-04]\n",
            "[1.0000000e+00 2.6150377e-04 1.6654916e-03 3.4125451e-02 1.6949391e-02\n",
            " 2.5726224e-03 6.8034336e-02 4.6799880e-02]\n",
            "[1.0000000e+00 9.4959557e-02 3.8989085e-05 6.5887230e-04 1.3079861e-03\n",
            " 1.6744493e-03 1.3913793e-02 1.4828856e-03]\n",
            "[1.0000000e+00 3.2513913e-02 2.9313502e-05 5.3475058e-05 1.1178999e-02\n",
            " 5.1022619e-03 3.2533337e-03 5.0918884e-03]\n",
            "[1.0000000e+00 1.6621160e-03 2.5449840e-03 8.4783410e-04 1.6385580e-03\n",
            " 1.6546182e-02 6.1750268e-03 1.2735403e-03]\n",
            "[1.0000000e+00 7.4438890e-04 3.2763854e-03 1.5276989e-03 2.1547559e-03\n",
            " 1.0781268e-02 1.6738297e-03 6.4396723e-03]\n",
            "[1.0000000e+00 9.2494767e-04 4.8011230e-04 1.3742178e-03 3.3676573e-03\n",
            " 6.9163486e-02 3.7764248e-02 1.4765319e-02]\n",
            "[1.0000000e+00 7.4807853e-02 9.2899462e-04 8.9292061e-03 2.2882004e-03\n",
            " 7.2037928e-02 6.0565468e-02 9.7451109e-04]\n",
            "[1.0000000e+00 7.5329139e-05 3.6293201e-03 1.0800157e-04 6.8651019e-03\n",
            " 5.3360878e-04 7.9375086e-03 5.1077448e-02]\n",
            "[1.0000000e+00 3.0043693e-05 1.0717072e-03 1.9069928e-04 1.0666737e-01\n",
            " 1.4455132e-04 1.3790627e-01 3.4509275e-02]\n",
            "[1.0000000e+00 3.0196394e-04 1.2987930e-03 8.1135705e-04 2.0320248e-03\n",
            " 1.8756270e-01 2.5015622e-03 1.5230832e-03]\n",
            "[1.0000000e+00 4.9127019e-03 2.4841784e-04 7.9917209e-04 2.0633191e-03\n",
            " 3.8265234e-01 7.6150675e-03 2.5024984e-03]\n",
            "[1.0000000e+00 1.0345417e-02 2.3272466e-04 8.2821463e-04 2.4386519e-03\n",
            " 1.1185075e-03 2.4440296e-02 2.8680740e-03]\n",
            "[1.0000000e+00 2.8594784e-04 3.6356159e-04 6.5767387e-04 8.6272396e-03\n",
            " 4.3310840e-03 1.5270990e-02 7.5979950e-03]\n",
            "[1.0000000e+00 5.0064329e-02 4.0870500e-04 8.8498846e-04 4.1856132e-03\n",
            " 1.8483379e-03 3.4079596e-03 1.2002774e-03]\n",
            "[1.0000000e+00 4.4917367e-02 1.3687351e-04 9.8638714e-04 6.7032585e-03\n",
            " 6.4187041e-03 3.5996959e-02 1.3485716e-02]\n",
            "[1.0000000e+00 4.4959702e-06 3.6196783e-01 4.1300635e-04 1.1984322e-03\n",
            " 7.8717880e-05 1.4648313e-03 9.7301218e-04]\n",
            "[1.0000000e+00 8.6500302e-05 1.3156307e-03 1.7680343e-03 8.7630153e-03\n",
            " 1.2979980e-02 1.1589001e-02 9.4013261e-03]\n",
            "[1.0000000e+00 1.7108809e-02 1.1896447e-01 1.8962281e-02 3.3800271e-03\n",
            " 1.8760899e-02 2.5898072e-01 7.9532911e-05]\n",
            "[3.1062348e-02 1.5394527e-06 4.5660701e-01 9.1103405e-01 1.4274994e-04\n",
            " 4.0183141e-04 1.5904710e-02 1.7421540e-03]\n",
            "[1.0000000e+00 7.8453260e-05 2.7562758e-02 1.8684871e-03 3.4748435e-03\n",
            " 1.4406098e-01 1.6381569e-02 2.8491292e-02]\n",
            "[1.0000000e+00 2.9809508e-04 1.9230839e-04 1.2685539e-04 5.9921010e-03\n",
            " 2.2963239e-02 3.0829073e-03 2.3234449e-01]\n",
            "[1.0000000e+00 9.4231497e-03 1.1469484e-05 1.2125545e-03 5.2823027e-04\n",
            " 1.5320235e-03 9.5838541e-03 5.5795759e-02]\n",
            "[1.0000000e+00 1.0214213e-01 7.0210680e-04 2.8185409e-03 5.0402810e-03\n",
            " 1.2947328e-02 1.3926637e-01 3.2741704e-04]\n",
            "[1.0000000e+00 3.0190581e-01 5.4240978e-04 1.2499282e-04 1.5598518e-02\n",
            " 3.9757113e-03 3.8551558e-03 3.4185237e-04]\n",
            "[1.0000000e+00 9.1284706e-04 3.4304586e-04 1.3463061e-03 2.7361622e-02\n",
            " 2.8311505e-03 3.0671943e-03 3.3869961e-01]\n",
            "[1.0000000e+00 4.3607804e-05 2.6156632e-03 7.7405985e-04 4.2735594e-03\n",
            " 7.7945972e-03 7.6544508e-03 5.7141256e-02]\n",
            "[1.         0.01985638 0.01035097 0.00295712 0.00535543 0.0044633\n",
            " 0.08105769 0.00104264]\n",
            "[1.0000000e+00 5.6716537e-05 1.4379313e-03 3.6490793e-04 1.1602715e-01\n",
            " 5.7581422e-04 4.1611391e-04 8.6709643e-03]\n",
            "[1.0000000e+00 2.0845052e-02 1.1910864e-03 7.0119306e-04 1.0268354e-02\n",
            " 9.5265440e-04 1.3148658e-03 3.5840203e-03]\n",
            "[3.5409021e-04 7.6859345e-05 3.0127445e-03 7.6288897e-01 1.9201464e-03\n",
            " 4.7018193e-03 7.0806961e-03 2.2542080e-02]\n",
            "[1.0000000e+00 5.5689790e-04 2.1318676e-02 2.2451352e-02 8.5680181e-04\n",
            " 1.5963959e-02 5.0990372e-03 1.3386203e-03]\n",
            "[1.0000000e+00 2.9078481e-04 5.2869162e-03 1.3094965e-03 1.9430463e-03\n",
            " 1.9634207e-01 4.4606209e-02 1.5581699e-02]\n",
            "[1.0000000e+00 1.2484430e-02 1.0868639e-03 2.2974960e-03 9.5406332e-04\n",
            " 7.3412322e-03 3.9477289e-02 1.2661879e-03]\n",
            "[1.0000000e+00 6.6157170e-02 1.5170844e-02 1.4737688e-03 1.1213785e-02\n",
            " 1.6383862e-02 2.1922730e-02 4.9645598e-05]\n",
            "[1.0000000e+00 4.1960321e-02 4.0453732e-02 6.4292527e-04 4.1348957e-03\n",
            " 2.4707736e-03 9.5074680e-03 7.3782132e-05]\n",
            "[1.0000000e+00 7.4453056e-02 3.1695052e-03 5.3323130e-03 6.6429591e-03\n",
            " 6.3815499e-03 2.2915173e-02 2.8197494e-04]\n",
            "[5.4439261e-06 6.6465372e-01 1.4332832e-03 1.3308489e-03 5.4948858e-04\n",
            " 1.9474307e-03 9.9881059e-03 1.6539745e-04]\n",
            "[1.0000000e+00 2.4416769e-02 1.5852447e-03 7.3226364e-03 1.9017191e-03\n",
            " 3.4498083e-03 2.6645124e-02 2.3708396e-04]\n",
            "[1.0000000e+00 2.8814247e-02 1.2124964e-02 2.1537457e-02 2.3755888e-03\n",
            " 1.8549899e-02 2.6478229e-02 3.2173080e-05]\n",
            "[1.0000000e+00 3.6621186e-05 4.2998437e-03 2.5000237e-02 3.7700180e-02\n",
            " 6.6749393e-03 6.7822062e-03 2.2741447e-03]\n",
            "[4.72079322e-04 2.44961266e-04 2.53584236e-03 1.19575989e-02\n",
            " 5.43508410e-01 5.97893307e-03 1.55704105e-02 1.91722566e-03]\n",
            "[1.0000000e+00 1.6007610e-02 6.9823075e-04 2.8343976e-04 8.2554109e-04\n",
            " 8.7811574e-02 2.1520501e-03 6.8381679e-04]\n",
            "[1.0000000e+00 2.5598146e-02 3.1418810e-03 5.2620987e-03 9.9635217e-04\n",
            " 9.5782019e-03 1.3196143e-02 2.0398096e-04]\n",
            "[1.0000000e+00 7.9376111e-04 1.1522708e-03 4.6913968e-03 7.9324050e-03\n",
            " 5.0048815e-04 5.6749871e-03 2.2252288e-02]\n",
            "[1.0000000e+00 2.7911614e-03 1.8236382e-03 6.2345178e-04 3.8467862e-03\n",
            " 7.2489568e-04 1.0509171e-01 1.1998910e-03]\n",
            "[1.0000000e+00 5.9695307e-05 1.1183679e-03 1.3880440e-02 2.1009832e-03\n",
            " 2.3204328e-03 1.0665125e-02 4.7277886e-01]\n",
            "[1.0000000e+00 2.5134243e-04 6.4825529e-04 3.3353094e-02 2.2020058e-03\n",
            " 1.2691051e-03 6.1516101e-03 3.8552728e-01]\n",
            "[1.0000000e+00 1.7751525e-05 6.0864189e-03 1.1888499e-02 9.9105872e-02\n",
            " 1.2038246e-03 9.9916123e-03 1.6104216e-02]\n",
            "[1.0000000e+00 3.3331060e-05 4.4791013e-02 7.2257803e-03 6.7934499e-04\n",
            " 6.6315132e-04 7.8530022e-04 2.4028141e-03]\n",
            "[1.0000000e+00 1.9751259e-03 1.5813893e-02 6.1288389e-05 4.7567018e-04\n",
            " 1.7456280e-04 7.5631001e-04 2.3264484e-04]\n",
            "[1.0000000e+00 6.3407602e-04 4.9702302e-03 8.1116403e-04 7.2403392e-04\n",
            " 8.9110225e-04 4.3898280e-04 2.2375115e-04]\n",
            "[1.0000000e+00 1.5554589e-04 8.8275746e-03 1.8214010e-02 4.5369100e-03\n",
            " 7.7005295e-04 3.3262730e-01 1.1128951e-03]\n",
            "[2.2750981e-02 8.8762789e-07 7.6025850e-01 2.8590810e-02 1.6495854e-03\n",
            " 1.5220455e-04 2.3417263e-01 6.2186155e-04]\n",
            "[1.0000000e+00 1.1147326e-02 2.8224110e-03 5.3512892e-03 7.3188078e-04\n",
            " 2.4829123e-03 7.3404536e-03 2.0753345e-04]\n",
            "[1.0000000e+00 1.0889445e-03 3.6972284e-03 1.5225247e-03 1.4016730e-03\n",
            " 7.1553104e-03 8.2201726e-04 1.7606022e-03]\n",
            "[1.0000000e+00 3.9061927e-03 1.3485641e-02 2.3115042e-04 1.2849785e-02\n",
            " 2.6708033e-03 8.1095967e-04 2.3204515e-04]\n",
            "[1.00000000e+00 1.06322630e-04 1.57962611e-03 3.37206380e-04\n",
            " 1.11395724e-01 4.42112098e-03 3.48994532e-03 1.17591792e-03]\n",
            "[1.0000000e+00 1.2848651e-05 5.7057296e-03 2.7910052e-04 4.0123765e-03\n",
            " 5.0057555e-03 3.2120466e-04 3.0193305e-02]\n",
            "[8.9693058e-04 3.7232472e-04 9.2716347e-03 2.7820817e-03 4.5365095e-03\n",
            " 5.8448976e-01 2.7708013e-02 5.0712959e-03]\n",
            "[1.         0.01237319 0.00576964 0.05409678 0.01374543 0.01449182\n",
            " 0.00206375 0.01007728]\n",
            "[1.         0.04518995 0.01641253 0.03433174 0.02193666 0.01750259\n",
            " 0.0034645  0.00136122]\n",
            "[1.0000000e+00 1.2465595e-01 3.2173940e-03 4.7199661e-04 1.2265479e-03\n",
            " 2.5808779e-03 1.3025249e-04 1.5164844e-03]\n",
            "[1.0000000e+00 1.3346197e-05 1.5593901e-02 2.3475317e-03 3.1230683e-02\n",
            " 2.9680606e-03 2.9443929e-04 4.9265631e-02]\n",
            "[1.         0.00611036 0.00795331 0.01894365 0.00187302 0.01097158\n",
            " 0.0061059  0.03436491]\n",
            "[1.0000000e+00 6.5001391e-02 1.2825970e-02 6.9180839e-02 8.7910873e-04\n",
            " 2.8860199e-03 8.6721370e-04 8.4425526e-04]\n",
            "[1.00000000e+00 9.28847352e-04 1.96785983e-02 8.80472187e-04\n",
            " 1.55489305e-02 3.89680527e-02 4.11073124e-04 1.23459194e-02]\n",
            "[1.0000000e+00 8.4124948e-04 4.3209616e-02 2.3042876e-03 3.4462071e-03\n",
            " 4.0711593e-03 3.4926224e-03 1.6204498e-03]\n",
            "[1.0000000e+00 7.7628688e-04 1.6123518e-02 5.9732944e-03 4.7463287e-02\n",
            " 9.6781589e-03 2.1856448e-04 7.1472684e-03]\n",
            "[5.0516886e-01 7.7839143e-04 2.1420788e-02 1.1310414e-03 5.8197076e-03\n",
            " 6.3088816e-04 5.2957945e-05 5.6319740e-03]\n",
            "[1.0000000e+00 1.5967915e-05 1.6681653e-02 1.6622167e-02 1.2945493e-01\n",
            " 2.0847672e-03 2.5334032e-04 1.4811865e-02]\n",
            "[1.0000000e+00 1.0694404e-04 7.4407108e-02 5.2725755e-02 5.3862803e-02\n",
            " 1.9706562e-02 1.2168527e-03 5.4169213e-04]\n",
            "[1.0000000e+00 2.2876486e-02 4.7096238e-02 6.5374472e-03 1.8287759e-03\n",
            " 2.7188404e-02 3.4294750e-03 7.4971589e-04]\n",
            "[1.         0.00172344 0.0061146  0.00393097 0.00796669 0.00841313\n",
            " 0.00105832 0.04592391]\n",
            "[1.0000000e+00 3.4357574e-05 8.7886080e-02 6.4192794e-02 9.7943112e-02\n",
            " 2.4416358e-03 2.7686535e-04 1.2370847e-02]\n",
            "[1.0000000e+00 1.7931437e-02 2.3397154e-03 1.5513449e-02 2.6255441e-03\n",
            " 6.0588024e-03 1.5571175e-04 5.2688038e-03]\n",
            "[1.0000000e+00 2.9120711e-05 4.1253730e-03 3.2433573e-02 3.4806736e-02\n",
            " 1.2931350e-03 5.7477718e-03 2.7348134e-01]\n",
            "[1.0000000e+00 1.1984763e-05 6.2564132e-03 4.1820135e-02 3.4920827e-02\n",
            " 5.4488960e-04 2.8047659e-03 2.0504268e-02]\n",
            "[1.0000000e+00 2.3232806e-01 1.7843636e-03 3.2025473e-03 6.2589594e-03\n",
            " 3.1967863e-02 4.4707395e-04 1.0111792e-03]\n",
            "[1.0000000e+00 1.4605785e-02 1.1236466e-03 9.7056566e-04 1.8874573e-02\n",
            " 2.9543440e-03 4.6867831e-04 7.6981904e-03]\n",
            "[1.0000000e+00 3.3680268e-02 5.4714167e-03 4.6773814e-03 2.3158318e-03\n",
            " 2.5440971e-03 5.5880303e-04 2.3564964e-03]\n",
            "[1.         0.00797213 0.00198175 0.00738775 0.00269588 0.03308688\n",
            " 0.00190892 0.08153634]\n",
            "[1.0000000e+00 1.5129909e-04 6.4684898e-03 1.2933460e-02 5.1422611e-02\n",
            " 2.1253992e-03 5.2237947e-04 3.8441411e-01]\n",
            "[1.         0.03801806 0.00211779 0.00391549 0.00887363 0.0028278\n",
            " 0.00112041 0.0119772 ]\n",
            "[1.0000000e+00 3.4992360e-02 9.1546752e-02 3.5036761e-02 1.1870646e-02\n",
            " 4.5035224e-02 1.6669635e-02 4.5668412e-04]\n",
            "[1.0000000e+00 1.3466546e-01 1.0220627e-01 1.2339263e-02 4.1930027e-02\n",
            " 7.6946728e-03 8.3146514e-03 4.1160217e-04]\n",
            "[1.         0.00196554 0.02483805 0.18244329 0.214076   0.2504272\n",
            " 0.4894     0.00125536]\n",
            "[1.0000000e+00 3.8181252e-03 7.2575144e-02 3.7689716e-02 9.2109563e-03\n",
            " 2.5971739e-02 3.8144547e-01 8.9902006e-04]\n",
            "[1.0000000e+00 1.0781449e-01 8.4245183e-02 4.9464043e-02 6.1396975e-03\n",
            " 9.1849163e-02 1.2755127e-02 7.5218981e-05]\n",
            "[1.0000000e+00 8.3827674e-02 1.8884762e-01 2.2279346e-01 1.1821824e-02\n",
            " 3.1927755e-01 5.3338554e-02 3.3944845e-05]\n",
            "[1.0000000e+00 4.0552807e-03 4.7129327e-03 2.3057496e-03 4.4592958e-02\n",
            " 5.8483356e-03 6.8460364e-04 5.8829519e-03]\n",
            "[1.0000000e+00 2.7067799e-03 4.9681365e-03 1.4025882e-03 6.3337408e-02\n",
            " 5.9092036e-03 3.2130576e-04 4.1638906e-03]\n",
            "[1.         0.1737234  0.00910401 0.00203445 0.00745122 0.01801077\n",
            " 0.01545053 0.00159317]\n",
            "[1.         0.00391279 0.01656728 0.03348368 0.00372286 0.04793403\n",
            " 0.06641556 0.03743341]\n",
            "[2.4228371e-03 3.9981666e-04 5.4409089e-03 3.3751810e-03 4.5086127e-03\n",
            " 5.0121099e-01 5.9025078e-03 5.3781405e-02]\n",
            "[1.0000000e+00 7.9333746e-05 3.3238873e-02 1.1250544e-02 5.4779099e-03\n",
            " 9.2459321e-02 5.1106699e-03 9.6367918e-02]\n",
            "[1.0000000e+00 4.2292736e-03 7.6401111e-04 8.0384263e-05 2.8474718e-01\n",
            " 1.5765851e-03 4.4191470e-03 7.9736300e-02]\n",
            "[1.0000000e+00 2.9654303e-01 3.5283476e-04 1.1814967e-04 3.1746128e-03\n",
            " 4.0765982e-03 2.4998630e-03 2.4127124e-03]\n",
            "[1.0000000e+00 2.4038982e-03 1.9958192e-03 5.0790571e-03 3.7852622e-04\n",
            " 2.3292252e-03 2.4536655e-03 3.5904408e-02]\n",
            "[1.0000000e+00 9.8333275e-04 2.4069238e-03 3.9751717e-04 2.4786260e-02\n",
            " 1.5551643e-02 1.6423978e-02 2.3658108e-02]\n",
            "[1.0000000e+00 2.5300901e-02 1.6745056e-03 3.6917231e-04 2.2005247e-02\n",
            " 3.6669813e-02 5.2997384e-02 1.0143211e-02]\n",
            "[1.0000000e+00 7.6419085e-02 1.8258477e-03 4.3899877e-04 2.8372281e-03\n",
            " 6.3238568e-03 2.1156045e-02 3.1546643e-03]\n",
            "[1.0000000e+00 4.5624740e-02 1.1350852e-02 1.1678483e-02 8.4079728e-03\n",
            " 2.1391893e-02 8.1278808e-02 8.1242877e-04]\n",
            "[1.0000000e+00 9.5131027e-04 7.9420432e-03 7.8603462e-04 1.1780970e-03\n",
            " 1.4579589e-03 1.3334370e-03 2.5865337e-02]\n",
            "[1.0000000e+00 1.8056321e-04 4.2049480e-03 2.5666700e-04 9.1655441e-03\n",
            " 5.2299368e-04 5.3451946e-03 3.0638302e-02]\n",
            "[1.0000000e+00 8.3052815e-04 1.1556204e-03 2.3895542e-03 2.3234580e-03\n",
            " 1.1296498e-03 1.9861400e-02 7.6930970e-02]\n",
            "[1.0000000e+00 2.7159131e-03 2.8916437e-03 8.5873128e-04 3.1333349e-03\n",
            " 5.8159482e-04 3.2244137e-04 3.1433426e-02]\n",
            "[1.0000000e+00 6.9600769e-04 2.8552483e-03 8.0811325e-04 5.5596395e-03\n",
            " 1.6128325e-03 2.7087613e-03 3.9865933e-03]\n",
            "[1.0000000e+00 6.3564315e-02 4.9049626e-03 8.1298202e-03 1.3289184e-02\n",
            " 4.1439123e-02 1.0929971e-01 2.6288111e-04]\n",
            "[1.0000000e+00 4.4076281e-04 2.1112987e-03 7.0781616e-04 7.3460522e-03\n",
            " 7.1234535e-03 1.9825689e-02 9.7680151e-02]\n",
            "[1.0000000e+00 1.8572440e-02 3.4588132e-02 5.3743133e-03 1.1161071e-02\n",
            " 1.5110226e-01 3.3457482e-01 3.7689894e-04]\n",
            "[1.0000000e+00 2.0123620e-02 3.5207561e-04 1.6092107e-04 7.0776237e-04\n",
            " 1.7614523e-04 7.7279314e-04 1.9488031e-02]\n",
            "[1.00000000e+00 1.47470171e-04 1.53968518e-03 1.55409868e-03\n",
            " 1.35743162e-02 1.87921035e-03 1.46425946e-03 1.03959896e-01]\n",
            "[1.0000000e+00 2.2030155e-04 4.0559319e-04 1.5759081e-04 2.7630482e-02\n",
            " 1.1895730e-03 1.9955200e-03 5.2855704e-02]\n",
            "[1.0000000e+00 2.0390591e-01 2.1069951e-03 3.9239000e-03 5.8249212e-03\n",
            " 5.7770312e-03 4.2647265e-02 4.5645935e-04]\n",
            "[1.0000000e+00 5.1341761e-02 7.0095260e-04 3.2463192e-04 1.7541125e-03\n",
            " 5.9214910e-03 4.3273582e-03 4.2069298e-03]\n",
            "[1.0000000e+00 6.1627594e-03 2.7142337e-03 3.1071863e-04 1.5914672e-03\n",
            " 1.9557774e-03 4.9684099e-03 1.0817520e-02]\n",
            "[9.5598558e-03 3.4621316e-05 6.2619406e-01 1.3678983e-02 5.7061235e-03\n",
            " 2.5847955e-03 2.9365314e-02 1.5957406e-02]\n",
            "[5.8688216e-02 3.9372202e-07 1.3177936e-02 8.6047012e-01 1.1303052e-01\n",
            " 8.8042388e-04 3.0573411e-02 2.2384992e-02]\n",
            "[1.0000000e+00 6.8742549e-05 4.2936672e-03 1.2707910e-02 5.8296868e-03\n",
            " 6.3240803e-03 2.5233987e-03 6.5727546e-03]\n",
            "[1.0000000e+00 3.2784868e-05 1.5191606e-01 1.1216493e-03 7.4476907e-03\n",
            " 7.7510922e-04 2.8499318e-02 1.1689673e-02]\n",
            "[1.0000000e+00 4.3163382e-05 1.3203473e-02 9.6435873e-03 2.6199736e-03\n",
            " 1.3051217e-02 3.7236929e-02 1.0072896e-01]\n",
            "[1.0000000e+00 2.0434050e-04 2.4922999e-02 8.0979513e-03 3.8422674e-01\n",
            " 6.1358600e-03 4.6972897e-02 1.8019963e-02]\n",
            "[1.0000000e+00 1.4267919e-04 1.3096507e-02 2.3129184e-04 9.4021745e-03\n",
            " 8.4471813e-04 1.2735155e-03 2.0689424e-02]\n",
            "[1.0735014e-03 5.3495227e-05 5.4680252e-01 1.0996524e-03 5.2623311e-03\n",
            " 3.2882504e-03 4.8732753e-03 7.4575064e-03]\n",
            "[1.0000000e+00 1.2408731e-05 1.8217435e-02 5.3139213e-03 2.6329264e-02\n",
            " 9.3509043e-03 3.2216527e-03 1.3081792e-01]\n",
            "[1.0000000e+00 1.1576821e-02 9.0027001e-04 9.4501789e-05 1.2869658e-01\n",
            " 1.0548288e-03 1.8443601e-03 4.5443937e-02]\n",
            "[1.0000000e+00 1.4933631e-04 1.1548215e-02 4.9787308e-05 2.8510918e-03\n",
            " 1.7597152e-04 7.5947266e-04 7.8786723e-03]\n",
            "[1.0000000e+00 1.2151852e-01 1.4832501e-02 2.0814210e-03 6.7144319e-02\n",
            " 2.3267409e-01 2.3338367e-01 5.3933531e-05]\n",
            "[1.0000000e+00 1.2323373e-01 1.9723343e-02 1.3374252e-03 2.7157119e-03\n",
            " 3.7665173e-01 2.2788484e-02 3.5801780e-04]\n",
            "[1.0000000e+00 2.8796901e-04 1.7243719e-03 5.1770312e-05 7.1464881e-04\n",
            " 5.6548696e-04 4.5204625e-04 8.3389068e-03]\n",
            "[1.0000000e+00 7.8419231e-05 2.5617354e-02 8.5550972e-05 1.7552683e-02\n",
            " 4.8717306e-04 8.8174045e-03 1.3834835e-02]\n",
            "[1.0000000e+00 6.5273314e-04 2.8354593e-03 9.5153501e-04 6.0450040e-02\n",
            " 1.0649030e-02 2.6722632e-02 8.2495205e-02]\n",
            "[1.0000000e+00 9.3557319e-05 5.5966279e-03 2.3012901e-04 9.6773393e-03\n",
            " 3.2884120e-03 3.6753924e-03 1.5643288e-03]\n",
            "[1.0000000e+00 1.9112341e-02 4.5087250e-04 8.8114255e-05 1.0355531e-02\n",
            " 8.2160458e-03 5.8250371e-03 3.9435592e-03]\n",
            "[1.0000000e+00 4.1249772e-03 5.8194943e-04 4.1911346e-03 1.5237432e-02\n",
            " 2.6576985e-02 3.9707188e-02 2.6704498e-02]\n",
            "[1.0000000e+00 6.8098458e-04 2.3785655e-03 2.6204673e-04 5.1309010e-03\n",
            " 8.5538474e-04 1.0984457e-03 1.1633550e-03]\n",
            "[1.0000000e+00 2.9557641e-03 1.7906784e-03 4.3057441e-04 3.9323387e-03\n",
            " 1.2388405e-01 6.6408711e-03 2.7793055e-04]\n",
            "[7.8922382e-04 1.1971614e-05 5.7406998e-03 4.9689077e-03 1.2610025e-02\n",
            " 8.2184153e-04 1.5139972e-02 5.4532868e-01]\n",
            "[1.0000000e+00 5.4234765e-02 6.9382098e-03 6.5075029e-03 3.8767413e-03\n",
            " 4.1214665e-03 1.1234881e-01 1.9287448e-04]\n",
            "[1.0000000e+00 1.7145768e-01 4.3637510e-02 1.9062233e-04 1.4335390e-02\n",
            " 4.0547298e-03 8.3707841e-03 9.4051698e-05]\n",
            "[1.0000000e+00 1.2706280e-01 4.3363166e-03 2.0859069e-03 2.9254765e-03\n",
            " 8.7939501e-03 1.5233962e-02 2.8430880e-04]\n",
            "[1.0000000e+00 1.0557118e-01 1.5662769e-04 2.3550561e-05 2.9037914e-03\n",
            " 1.1920083e-03 2.4847519e-02 4.1882116e-03]\n",
            "[1.0000000e+00 1.8472891e-02 3.4757529e-03 4.2195912e-05 1.5739093e-02\n",
            " 1.9273424e-03 1.3772040e-03 5.3072564e-04]\n",
            "[1.0000000e+00 2.5751637e-04 4.2288853e-03 5.8274134e-04 9.0911575e-03\n",
            " 1.9498799e-03 1.3345886e-03 2.8047856e-02]\n",
            "[1.0000000e+00 2.5156203e-03 2.9238167e-03 1.3784038e-04 2.2042217e-02\n",
            " 1.9987945e-03 5.8680167e-04 9.1424705e-03]\n",
            "[1.0000000e+00 4.7953937e-02 1.7967972e-04 3.3449789e-05 4.2077638e-03\n",
            " 3.9422293e-03 1.2597430e-03 5.3020503e-04]\n",
            "[1.00000000e+00 4.44379868e-04 1.67708797e-03 1.02115526e-04\n",
            " 2.43300702e-02 3.76809621e-03 1.46769627e-03 3.04719666e-04]\n",
            "[1.00000000e+00 1.99129900e-05 6.96131364e-02 6.32346550e-04\n",
            " 5.77495322e-02 1.69680566e-02 1.18219005e-02 2.40656883e-02]\n",
            "[1.0000000e+00 9.1106643e-04 5.4628933e-03 2.6314752e-03 8.8407444e-03\n",
            " 1.6641585e-02 3.0487265e-02 1.4262071e-03]\n",
            "[9.5576623e-05 8.0353611e-06 1.6665067e-01 9.4154292e-01 1.5975644e-03\n",
            " 3.5981941e-03 9.3136579e-02 4.3578245e-02]\n",
            "[1.0000000e+00 7.6925911e-02 1.7993145e-02 3.7281292e-03 1.6321348e-02\n",
            " 4.0512320e-02 2.9394729e-02 2.7038431e-04]\n",
            "[1.0000000e+00 1.4824753e-02 1.0415506e-02 1.6955532e-02 2.4633668e-02\n",
            " 4.0985450e-02 2.4989045e-01 6.7503186e-04]\n",
            "[1.         0.09064753 0.00261395 0.00334244 0.01031895 0.04551247\n",
            " 0.04128258 0.00112419]\n",
            "[1.0000000e+00 2.6277464e-04 7.7801361e-04 1.1864557e-04 3.2146704e-01\n",
            " 4.8177335e-03 1.0165863e-03 1.3148343e-03]\n",
            "[1.0000000e+00 3.8862252e-03 1.7795106e-04 1.0612503e-04 9.0959221e-02\n",
            " 6.7549158e-04 1.1928964e-03 8.5686799e-03]\n",
            "[1.0000000e+00 1.8514972e-04 3.2217886e-02 1.3106790e-02 1.9570958e-02\n",
            " 2.1094061e-03 5.6595699e-04 1.2839741e-01]\n",
            "[1.8276934e-01 3.9881219e-05 1.8711752e-01 5.1172756e-02 3.6306910e-02\n",
            " 8.5751526e-04 1.6324628e-03 5.1255894e-01]\n",
            "[1.48020342e-06 4.14131969e-01 5.50395131e-01 2.46669739e-01\n",
            " 1.04667813e-01 1.08847916e-01 6.94296435e-02 1.12240459e-03]\n",
            "[9.7764811e-08 1.2045045e-02 6.2776521e-02 2.9361948e-01 5.9561327e-02\n",
            " 2.9556331e-01 8.1374127e-01 1.0033266e-01]\n",
            "[1.         0.06813704 0.04978396 0.271353   0.06766729 0.07920238\n",
            " 0.05718749 0.00345491]\n",
            "[1.1365441e-05 5.0512916e-01 6.1586276e-02 9.3405917e-02 1.6238222e-01\n",
            " 5.7099782e-02 3.9820503e-02 8.9793990e-04]\n",
            "[1.0000000e+00 5.5709686e-05 2.9551687e-02 3.8343493e-03 1.3979384e-01\n",
            " 1.8410465e-03 3.0394590e-03 1.4507324e-01]\n",
            "[1.0000000e+00 2.7606913e-04 2.6571000e-02 2.6837943e-02 4.1004965e-01\n",
            " 4.5447862e-01 1.4583199e-02 1.0816253e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kyi3lLGz7fIE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "bff01443-8b94-41f2-cd26-35af666d9e30"
      },
      "source": [
        "probabilities_combined = np.stack(arr_list, axis=0).mean(axis=0)\n",
        "predicted_labels = pd.DataFrame(probabilities_combined, columns=labels)\n",
        "predicted_labels['id'] = test_data.loc[:, 'id'].values\n",
        "predicted_labels.loc[:, 'ID'] = predicted_labels.id.apply(\n",
        "    lambda x: x.split('_')[0])\n",
        "predicted_labels_groupped = predicted_labels.groupby(\n",
        "    ['ID']).aggregate(dict(zip(labels, ['max']*(len(labels)))))\n",
        "print(type(predicted_labels_groupped))\n",
        "predicted_labels_groupped['ID'] = predicted_labels_groupped.index.values.astype(\n",
        "    int)\n",
        "predicted_labels_groupped.reset_index(drop=True, inplace=True)\n",
        "predicted_labels_groupped.sort_values('ID', inplace=True)\n",
        "predicted_labels_groupped = predicted_labels_groupped.loc[:, ['ID']+labels]\n",
        "predicted_labels_groupped.to_csv(\n",
        "    '/content/gdrive/My Drive/Colab Notebooks/odir-ivashnyov/ODIR/submit_final/clahe_vessel_forgetgate_new_epoch_18.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1653\u001b[0m                 blocks = [\n\u001b[0;32m-> 1654\u001b[0;31m                     \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1655\u001b[0m                 ]\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3053\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m   2600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2601\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    124\u001b[0m             raise ValueError(\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m                 \u001b[0;34mf\"placement implies {len(self.mgr_locs)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 1, placement implies 8",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-dded35ad8006>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprobabilities_combined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities_combined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m predicted_labels.loc[:, 'ID'] = predicted_labels.id.apply(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1662\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"values\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1664\u001b[0;31m         \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   1692\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mblock_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1694\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (32, 1), indices imply (32, 8)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSt7t9NcUYkr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9a818951-2032-438a-b804-e15620cda148"
      },
      "source": [
        "for idx in range((probabilities.shape[0])):#32\n",
        "  if all(probabilities[idx] < 0.5):\n",
        "    print(probabilities[idx])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4.1628491e-02 1.6316134e-04 5.2866463e-02 4.8119966e-03 5.8490634e-05\n",
            " 8.8020734e-02 1.1512419e-03 2.4260061e-03]\n",
            "[1.9674080e-03 7.7522993e-03 3.0436271e-03 7.2792908e-03 2.1664324e-04\n",
            " 3.7784681e-01 6.8974728e-03 7.4463210e-04]\n",
            "[3.8555430e-04 8.0106091e-03 8.5256775e-05 1.9860677e-03 5.4553780e-03\n",
            " 1.7367763e-03 4.7698678e-03 1.0894294e-02]\n",
            "[2.5963722e-05 1.7049800e-01 1.5615511e-03 1.2017510e-02 3.5965994e-03\n",
            " 4.9334257e-03 3.1994242e-02 5.7079447e-05]\n",
            "[2.6914554e-02 6.7672564e-04 1.0034190e-03 2.2619946e-02 6.7500259e-05\n",
            " 1.3488573e-04 2.1234720e-03 2.4030743e-02]\n",
            "[4.3647902e-04 8.5264684e-05 1.2379026e-03 5.7227097e-02 1.4787121e-03\n",
            " 1.2727933e-03 8.6145833e-02 3.7907790e-02]\n",
            "[2.24616632e-01 5.87351969e-04 3.00790387e-04 6.64554723e-03\n",
            " 1.77870702e-03 9.49199457e-05 8.40691268e-04 1.15386015e-02]\n",
            "[4.6114126e-01 5.7576858e-03 2.7080756e-04 3.6181763e-03 3.3660306e-04\n",
            " 5.2929803e-04 1.0146903e-03 3.5586834e-04]\n",
            "[0.00053047 0.03534866 0.00400558 0.01468179 0.00033683 0.0018258\n",
            " 0.01843734 0.00026051]\n",
            "[0.00159867 0.00426009 0.00402441 0.00321965 0.00022549 0.00027625\n",
            " 0.01133172 0.00228656]\n",
            "[1.0347219e-04 3.8383089e-03 1.8211735e-04 4.9794618e-02 9.0343245e-05\n",
            " 9.8046765e-04 2.2790864e-02 1.0377819e-01]\n",
            "[2.3010239e-04 2.4558092e-04 3.4966614e-04 3.2315186e-01 3.3591039e-04\n",
            " 2.8961428e-04 9.5772564e-02 1.3880667e-01]\n",
            "[0.06894921 0.00062405 0.00166088 0.00252682 0.00027962 0.02312029\n",
            " 0.00184311 0.00105167]\n",
            "[0.05381607 0.00373538 0.00090076 0.01542299 0.00012406 0.00075423\n",
            " 0.00357301 0.00136591]\n",
            "[2.0469254e-06 9.9333106e-03 3.9426622e-04 1.6187444e-01 4.5013585e-04\n",
            " 1.9617584e-01 1.9558053e-01 1.3768726e-03]\n",
            "[8.8570105e-06 3.4434809e-03 5.8622874e-04 2.9082876e-02 5.9332489e-04\n",
            " 2.5483745e-01 1.3723379e-01 2.1678586e-03]\n",
            "[4.9143616e-04 8.0918064e-03 4.5368820e-03 2.3660066e-03 2.9635874e-05\n",
            " 4.3924560e-04 3.3362301e-03 1.0702310e-02]\n",
            "[2.9475769e-04 1.1857269e-01 1.1109972e-03 1.2205938e-02 8.0354635e-05\n",
            " 2.6067947e-03 2.1551908e-03 4.8147951e-04]\n",
            "[3.6435344e-04 1.7994203e-01 7.2286697e-03 3.9874595e-03 6.0745740e-05\n",
            " 1.5027522e-03 9.9029923e-03 1.2322582e-04]\n",
            "[0.01356914 0.00118242 0.00191341 0.00855965 0.00011162 0.03249601\n",
            " 0.00829729 0.00329526]\n",
            "[1.9745133e-04 1.8938811e-01 2.8552421e-04 5.0863530e-03 8.9739493e-05\n",
            " 4.2837276e-03 4.0434580e-03 6.3125836e-04]\n",
            "[3.2882548e-03 7.2574783e-03 3.3542109e-04 5.1757524e-04 6.9487702e-05\n",
            " 2.2138574e-04 1.3439854e-02 6.4735785e-03]\n",
            "[0.00270311 0.07635155 0.00040297 0.00254246 0.00014639 0.0019277\n",
            " 0.00103849 0.00042846]\n",
            "[1.4842112e-03 1.6236793e-01 3.4518691e-04 3.4189527e-03 3.6528509e-05\n",
            " 1.1402697e-03 6.2799657e-04 4.8368721e-04]\n",
            "[7.3860246e-03 7.0151196e-05 1.9903835e-03 1.2344595e-02 7.0657342e-04\n",
            " 5.0620154e-05 3.7076168e-03 1.7971127e-01]\n",
            "[3.0854731e-03 1.7076190e-05 2.3633977e-03 1.2415576e-01 1.8354440e-04\n",
            " 5.8865262e-04 1.1270666e-01 2.2670105e-01]\n",
            "[0.00252955 0.00033936 0.0001219  0.00341313 0.00972383 0.00018219\n",
            " 0.00769142 0.07846936]\n",
            "[6.7671344e-02 5.6503079e-04 1.0549572e-03 1.4860667e-03 3.4360826e-04\n",
            " 7.6152428e-05 2.8101618e-03 3.9004363e-02]\n",
            "[1.8715900e-03 4.1452924e-05 3.6210020e-04 4.7481311e-03 1.4622462e-01\n",
            " 6.9425645e-05 3.0710734e-03 5.2506130e-02]\n",
            "[0.00776364 0.00082302 0.00240832 0.00773329 0.00025738 0.00064486\n",
            " 0.03014405 0.0091805 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faIF5lDIUglm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}